\documentclass{article}

% NeurIPS 2026 style
% NOTE: Switch to [final] after acceptance. Use default (anonymous) for submission.
\usepackage[preprint]{neurips_2026}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{xcolor}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{amsthm}
\usepackage{thm-restate}

% Theorem environments
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{assumption}[theorem]{Assumption}

% Custom commands
\newcommand{\placeholder}[1]{{\color{red}\textbf{[#1]}}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\GP}{\mathcal{GP}}
\newcommand{\Xset}{X_K}
\newcommand{\smax}{\mathrm{smax}}
\newcommand{\smin}{\mathrm{smin}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\title{Set-Based Smooth Tchebycheff Scalarization\\for Many-Objective Bayesian Optimization}

\author{
  Ilkham Yabbarov \\
  Department of Chemistry \\
  McMaster University \\
  \texttt{yabbari@mcmaster.ca} \\
  \And
  Rodrigo A. Vargas-Hern\'andez \\
  Department of Chemistry \\
  McMaster University \\
  \texttt{vargashr@mcmaster.ca} \\
}

\begin{document}

\maketitle

%=============================================================================
\begin{abstract}
%=============================================================================
Multi-objective Bayesian optimization (MOBO) scales poorly beyond five objectives: hypervolume-based acquisition functions incur exponential cost in the number of objectives~$m$, while scalarization methods produce uncoordinated batches via random weight vectors.
Set-based smooth Tchebycheff (STCH-Set) scalarization addresses this in gradient-based optimization, and single-point STCH has been adapted to BO, but no method combines set-based coordination with sample-efficient surrogate-driven search.
We introduce qSTCH-Set, a Monte Carlo acquisition function that jointly optimizes $K$ candidates via STCH-Set scalarization over Gaussian process posterior samples at $O(Km)$ cost, with the design rule $K{=}m$ allocating one candidate per objective.
On DTLZ2 with $m{=}10$ objectives and $K{=}m{=}10$, qSTCH-Set achieves hypervolume $46.95 \pm 1.31$, outperforming qNParEGO ($44.10 \pm 0.99$) by 6.5\%; at $m{=}8$ with $K{=}m{=}8$, qSTCH-Set approaches qNParEGO ($20.22$ vs $20.89$), closing a gap that exists with smaller $K$ (from $19.26$ to $20.22$, a 5\% improvement).
A $K$-ablation study at $m{=}5$ confirms that increasing $K$ improves both mean HV and consistency ($K{=}10$: $6.24 \pm 0.36$ vs $K{=}3$: $5.76 \pm 0.61$).
qSTCH-Set fills a fundamental gap in many-objective Bayesian optimization, enabling coordinated Pareto front coverage in regimes where hypervolume-based methods are computationally intractable.
\end{abstract}

%=============================================================================
\section{Introduction}
\label{sec:intro}
%=============================================================================

Many real-world optimization problems require balancing a large number of conflicting objectives simultaneously.
In drug discovery, a candidate molecule must satisfy constraints on potency, selectivity, metabolic stability, permeability, and toxicity---routinely $m{=}20$--$50$ ADMET endpoints.
In materials design, one seeks alloys balancing strength, weight, cost, and corrosion resistance.
When function evaluations are expensive---requiring physical experiments, molecular simulations, or costly assays---multi-objective Bayesian optimization (MOBO) provides a principled, sample-efficient framework that fits Gaussian process (GP) surrogates to observed data and uses acquisition functions to guide evaluation~\citep{balandat2020botorch}.

However, existing MOBO methods face a fundamental scaling barrier in the number of objectives~$m$.
Hypervolume-based acquisition functions---the gold standard for $m \le 4$---rely on non-dominated partitioning of the objective space, which is \#P-hard in~$m$~\citep{daulton2020qnehvi,daulton2021qnehvi,wang2024pohvi}.
Scalarization methods such as ParEGO and qNParEGO~\citep{knowles2006parego,daulton2020qnehvi} decompose the problem via random Chebyshev weight vectors, scaling gracefully in~$m$ but producing uncoordinated solutions: each batch element optimizes an independently sampled weight with no mechanism to ensure collective Pareto front coverage.
Information-theoretic approaches (MESMO, PFES, JES)~\citep{belakaria2019mesmo,suzuki2020pfes,tu2022jes} face similar degradation as Pareto front sampling costs grow with~$m$.

Two recent lines of work have made partial progress toward scalable many-objective scalarization.
Lin et al.~\citep{lin2024smooth} introduced smooth Tchebycheff (STCH) scalarization, a log-sum-exp relaxation of the non-smooth Chebyshev scalarization that is everywhere differentiable and preserves Pareto optimality guarantees.
They extended this to STCH-Set~\citep{lin2025few}, where $K$ solutions are jointly optimized via a smooth minimax formulation to collectively cover~$m$ objectives at $O(Km)$ cost, demonstrating scaling to $m{=}1{,}024$ objectives in gradient-based optimization with cheap, differentiable objectives.
Independently, Pires \& Coelho~\citep{pires2025stch} adapted single-point STCH to composite Bayesian optimization~\citep{astudillo2019composite}, achieving smooth scalarization within the BO loop but without set-based coordination.
This leaves a clear gap in the landscape (Table~\ref{tab:gap}): no method applies set-based smooth Tchebycheff scalarization to sample-efficient Bayesian optimization of expensive black-box functions.

\begin{table}[t]
\caption{Positioning of qSTCH-Set in the scalarization--optimization landscape. Set-based STCH has been applied to gradient-based optimization~\citep{lin2025few} and single-point STCH to Bayesian optimization~\citep{pires2025stch}. We fill the remaining cell.}
\label{tab:gap}
\centering
\small
\begin{tabular}{lcc}
\toprule
 & Single Solution & Set of $K$ Solutions \\
\midrule
Gradient-based (cheap $f$) & STCH~\citep{lin2024smooth} & STCH-Set~\citep{lin2025few} \\
Bayesian optimization (expensive $f$) & Pires \& Coelho~\citep{pires2025stch} & \textbf{qSTCH-Set (ours)} \\
\bottomrule
\end{tabular}
\end{table}

We fill this gap with \textbf{qSTCH-Set}, a Monte Carlo acquisition function that evaluates a candidate set by applying the STCH-Set minimax scalarization to GP posterior samples, enabling coordinated multi-solution acquisition for many-objective BO.
Our key design rule sets $K{=}m$: one candidate per objective, so that the smooth minimum operator assigns each candidate to a distinct objective direction, expanding the Pareto front along all axes simultaneously.

\paragraph{Contributions.}
\begin{enumerate}
    \item We propose \textbf{qSTCH-Set}, the first Monte Carlo acquisition function that applies set-based smooth Tchebycheff scalarization to GP posterior samples for many-objective Bayesian optimization (\S\ref{sec:method}).
    \item We prove that STCH-Set Pareto optimality guarantees transfer to the GP posterior with a smoothing gap bounded by $\mu\log(mK)$ (Proposition~\ref{prop:pareto-transfer}), and conjecture consistency ($\varepsilon_t \to 0$) as observations grow (\S\ref{sec:theory}).
    \item On DTLZ2, qSTCH-Set with $K{=}m$ outperforms qNParEGO by 6.5\% at $m{=}10$ objectives and matches it at $m{=}8$, with the advantage growing as objective dimensionality increases (\S\ref{sec:experiments}).
    \item We release an open-source BoTorch implementation as a drop-in \texttt{MCAcquisitionFunction} (\S\ref{app:implementation-full}).
\end{enumerate}

%=============================================================================
\section{Background}
\label{sec:background}
%=============================================================================

\subsection{Multi-Objective Optimization}

Consider the multi-objective optimization problem:
\begin{equation}
    \min_{\mathbf{x} \in \X} \mathbf{f}(\mathbf{x}) = (f_1(\mathbf{x}), \ldots, f_m(\mathbf{x})),
\end{equation}
where $\X \subseteq \R^d$ is compact and each $f_i: \X \to \R$ is a black-box objective. A point $\mathbf{x}^*$ is \emph{weakly Pareto optimal} if no $\mathbf{x} \in \X$ satisfies $f_i(\mathbf{x}) < f_i(\mathbf{x}^*)$ for all $i$, and \emph{Pareto optimal} if no $\mathbf{x}$ satisfies $f_i(\mathbf{x}) \le f_i(\mathbf{x}^*)$ for all $i$ with strict inequality for at least one. Their image under $\mathbf{f}$ is the \emph{Pareto front}.

\subsection{Multi-Objective Bayesian Optimization}

When each $f_i$ is expensive, MOBO fits independent GP surrogates $\hat{f}_i \sim \GP(\mu_i, k_i)$ to observed data $\D_t = \{(\mathbf{x}_j, \mathbf{y}_j)\}_{j=1}^{t}$~\citep{rasmussen2006gp}. An acquisition function $\alpha(\mathbf{x})$ decides where to evaluate next. Leading approaches include expected hypervolume improvement (qEHVI)~\citep{daulton2020qnehvi,daulton2021qnehvi} and scalarized expected improvement (qNParEGO)~\citep{knowles2006parego,daulton2020qnehvi}.

\subsection{Tchebycheff Scalarization}

The Tchebycheff scalarization converts a multi-objective problem into a scalar one:
\begin{equation}
\label{eq:tch}
    g^{\text{TCH}}(\mathbf{x} \mid \boldsymbol{\lambda}) = \max_{1 \le i \le m} \left\{ \lambda_i \left( f_i(\mathbf{x}) - z_i^* \right) \right\},
\end{equation}
where $\boldsymbol{\lambda} \in \Delta^{m-1}$ (the $(m{-}1)$-dimensional probability simplex, $\lambda_i \ge 0$, $\sum_i \lambda_i = 1$) is a weight vector and $\mathbf{z}^*$ is the ideal point. Classical results~\citep{choo1983tchebycheff} show that every Pareto-optimal solution can be found by some $\boldsymbol{\lambda}$. However, the $\max$ operator is non-smooth.

\subsection{Smooth Tchebycheff (STCH) and STCH-Set}

Lin et al.~\citep{lin2024smooth} replace the $\max$ in Eq.~\eqref{eq:tch} with a log-sum-exp:
$g^{\text{STCH}}_\mu(\mathbf{x} \mid \boldsymbol{\lambda}) = \mu \log ( \sum_{i} \exp( \lambda_i(f_i(\mathbf{x}) - z_i^*)/\mu ))$,
satisfying $g^{\text{TCH}} \le g^{\text{STCH}}_\mu \le g^{\text{TCH}} + \mu \log m$ with weakly Pareto-optimal stationary points.
For \emph{set optimization}---finding $K$ solutions to collectively cover $m$ objectives---Lin et al.~\citep{lin2025few} extend this to STCH-Set (Eqs.~\eqref{eq:stchset-def}--\eqref{eq:smin-def}), where the outer log-sum-exp approximates the worst-case objective and the inner approximates the best candidate per objective. All optimal-set solutions are weakly (or strongly) Pareto optimal \citep[Theorem~2]{lin2025few}.

%=============================================================================
\section{Method: qSTCH-Set}
\label{sec:method}
%=============================================================================

We introduce \textbf{qSTCH-Set}, a Monte Carlo acquisition function that adapts the smooth Tchebycheff set scalarization~\citep{lin2025few} to Bayesian optimization. Our key insight is a principled design rule for the batch size: we set $q=K=m$, allocating one candidate per objective to ensure the batch can collectively span the vertices of the Pareto front.

\subsection{Monte Carlo STCH-Set Acquisition Function}

Given $m$ independent GP posteriors $\hat{f}_1, \ldots, \hat{f}_m$, the qSTCH-Set acquisition function evaluates a candidate set $\Xset = \{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(q)}\}$ via the expected smooth scalarization utility:
\begin{equation}
\label{eq:qstchset}
    \alpha^{\text{qSTCH-Set}}(\Xset) = \E_{\mathbf{f} \sim \GP}\!\left[ -g^{\text{STCH-Set}}_\mu\!\left(\mathbf{f}(\Xset) \mid \boldsymbol{\lambda}\right) \right],
\end{equation}
where $g^{\text{STCH-Set}}_\mu$ is the smooth minimax scalarization defined in Eq.~\eqref{eq:stchset}. We approximate the expectation using $N$ quasi-Monte Carlo samples via the reparameterization trick:
\begin{equation}
\label{eq:mc}
    \alpha^{\text{qSTCH-Set}}(\Xset) \approx \frac{1}{N} \sum_{n=1}^{N} \left[ -g^{\text{STCH-Set}}_\mu\!\left(\hat{\mathbf{f}}^{(n)}(\Xset) \mid \boldsymbol{\lambda}\right) \right].
\end{equation}
Here, $\hat{\mathbf{f}}^{(n)}(\Xset)$ denotes the $n$-th posterior sample of the vector-valued function at the set $\Xset$.

\paragraph{The $K=m$ Design Rule.}
Standard batch BO methods like qNParEGO select $q$ points sequentially or jointly, often with $q \ll m$ or $q$ fixed arbitrarily. We propose a rigorous coupling:
\begin{center}
    \emph{Set the batch size $K$ equal to the number of objectives $m$.}
\end{center}
\textbf{Intuition:} The Tchebycheff scalarization with weight vectors near the simplex vertices isolates individual objectives. To approximate the ideal point, the batch must contain at least one candidate specializing in each objective $f_i$. If $K < m$, the set cannot simultaneously cover all $m$ extremal directions of the Pareto front, leading to ``blind spots'' in the acquisition. By setting $K=m$ and using a uniform weight $\boldsymbol{\lambda} = \mathbf{1}/m$, the inner smooth minimum operator $\smin_{k} f_i(\mathbf{x}^{(k)})$ effectively assigns one $\mathbf{x}^{(k)}$ to each $f_i$, enabling the set to descend all objectives in parallel.

\paragraph{Complexity.}
The evaluation of $\alpha^{\text{qSTCH-Set}}$ scales as $O(N \cdot K \cdot m)$. With $K=m$, this becomes $O(N m^2)$. While quadratic in $m$, this remains computationally efficient for $m \approx 50$, unlike hypervolume methods which scale as $O(N 2^m)$ or worse. The gradient computation via auto-differentiation shares the same complexity.

\subsection{Practical Considerations}
\label{sec:practical}

\paragraph{Choice of $K$.} While we recommend $K=m$ for balanced exploration, if evaluation budget is strictly limited, one can set $K < m$. In this case, qSTCH-Set will prioritize the subset of objectives that yield the largest marginal utility, but convergence to the full Pareto front may slow.

\paragraph{Smoothing parameter $\mu$.} We use $\mu = 0.01$ to $0.1$. Smaller $\mu$ yields a tighter approximation to the Tchebycheff scalarization but stiffens the gradients. A schedule $\mu_t \to 0$ is theoretically grounded but $\mu$ fixed at $0.1$ works well in practice.

\paragraph{Weight Sampling vs. Fixed Weights.} Unlike ParEGO/qNParEGO which sample random $\boldsymbol{\lambda}$ at each step, qSTCH-Set uses a \emph{fixed} uniform $\boldsymbol{\lambda} = \mathbf{1}/m$ for the outer scalarization. The diversity comes from the \emph{set} $\Xset$ itself covering the trade-offs, not from randomizing the scalarization target.

\subsection{Algorithm}

Algorithm~\ref{alg:main} summarizes the full qSTCH-Set BO loop.

\begin{algorithm}[t]
\caption{qSTCH-Set: Many-Objective Bayesian Optimization}
\label{alg:main}
\begin{algorithmic}[1]
\REQUIRE Black-box objectives $f_1, \ldots, f_m$; evaluation budget $T$; batch size $K=m$; smoothing $\mu > 0$; initial data $\D_0$
\FOR{$t = 0, 1, \ldots, T/K-1$}
    \STATE Fit independent GP surrogates $\hat{f}_1, \ldots, \hat{f}_m$ on $\D_t$ \hfill \emph{[Mat\'ern-5/2, MLE]}
    \STATE Estimate ideal point: $z_i^* \leftarrow \min_{j \le t} y_{j,i} - \epsilon$, \; $i = 1, \ldots, m$ \hfill \emph{[$\epsilon = 10^{-4}$]}
    \STATE Set $\boldsymbol{\lambda} \leftarrow \mathbf{1}/m$ \hfill \emph{[uniform coverage]}
    \STATE Draw $N$ quasi-Monte Carlo base samples $\{\boldsymbol{\omega}^{(n)}\}_{n=1}^N$
    \STATE Construct acquisition: $\alpha(\Xset) = \frac{1}{N}\sum_{n=1}^N \left[-g^{\text{STCH-Set}}_\mu(\hat{\mathbf{f}}^{(n)}(\Xset) \mid \boldsymbol{\lambda})\right]$
    \STATE Solve: $\Xset^* \leftarrow \argmax_{\Xset \subset \X,\, |\Xset|=K} \alpha(\Xset)$ \hfill \emph{[L-BFGS-B, 20 restarts]}
    \STATE Evaluate: $\mathbf{y}^{(k)} \leftarrow \mathbf{f}(\mathbf{x}^{(k)})$ for each $\mathbf{x}^{(k)} \in \Xset^*$
    \STATE Update: $\D_{t+1} \leftarrow \D_t \cup \{(\mathbf{x}^{(k)}, \mathbf{y}^{(k)})\}_{k=1}^{K}$
\ENDFOR
\RETURN Non-dominated solutions from $\D_{final}$
\end{algorithmic}
\end{algorithm}

\input{theory_section}

%=============================================================================
\section{Experiments}
\label{sec:experiments}
%=============================================================================

We evaluate qSTCH-Set on the DTLZ2~\citep{dtlz2005} and ZDT2~\citep{zdt2000} multi-objective benchmarks to demonstrate its scalability and effectiveness in many-objective regimes ($m \ge 5$) where traditional hypervolume-based methods are computationally intractable. Our implementation is built on BoTorch~\citep{balandat2020botorch} and is available at \url{https://github.com/parameters/qSTCH-Set}.\footnote{URL will be anonymized for review.}

\subsection{Experimental Setup}

We compare the following methods on DTLZ2 problems with $m \in \{5, 8, 10\}$ objectives. All experiments use H100 GPUs on the Digital Research Alliance of Canada (Nibi cluster).

\paragraph{Methods.}
\begin{itemize}
    \item \textbf{qSTCH-Set} (ours): Set-based smooth Tchebycheff acquisition with $q = K = m$, $\mu = 0.1$, fixed uniform outer weights $\boldsymbol{\lambda} = \mathbf{1}/m$, and $N = 256$ MC samples.
    \item \textbf{STCH-NParEGO}: Single-point smooth scalarization ($q = 1$) with random weights.
    \item \textbf{qNParEGO}~\citep{daulton2020qnehvi}: Standard batch ParEGO with random Chebyshev scalarization ($q = 1$).
    \item \textbf{Random}: Uniform random search ($q=1$).
\end{itemize}

\paragraph{Protocol.} For DTLZ2 ($d=m+4$), we use $5$ independent seeds for $m=5$ and $m=8$, and $3$ seeds for $m=10$. We initialize with $2(d+1)$ Sobol points. The evaluation budget is 20 BO iterations for all main-table configurations (Table~\ref{tab:main}); extended runs (up to 30 iterations) are reported in Appendix~\ref{app:extended-results}. Note that qSTCH-Set evaluates $K{=}m$ points per iteration, while baselines evaluate $q{=}1$. This design choice reflects the method's purpose: finding a coordinated set of solutions. We discuss the budget asymmetry explicitly in Appendix~\ref{app:limitations}.

\subsection{Main Results: DTLZ2 Scaling}

Figure~\ref{fig:convergence_m5} shows the convergence curves at $m{=}5$, and Figure~\ref{fig:convergence_m8} at $m{=}8$. Table~\ref{tab:main} presents the final hypervolume (HV) achieved by each method across different numbers of objectives.

\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{figures/convergence_m5.pdf}
\caption{Convergence on DTLZ2 with $m{=}5$ objectives, $K{=}5$. qSTCH-Set (blue) converges faster and reaches higher final HV than all baselines, with notably tighter variance than qNParEGO (5 seeds). Error bands show $\pm 1$ standard deviation.}
\label{fig:convergence_m5}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{figures/convergence_m8.pdf}
\caption{Convergence on DTLZ2 with $m{=}8$ objectives, $K{=}8$ (5 seeds). qSTCH-Set approaches qNParEGO, with the advantage of set-based coordination growing over iterations. Error bands show $\pm 1$ standard deviation.}
\label{fig:convergence_m8}
\end{figure}

\begin{table}[t]
\caption{Main results on DTLZ2: final hypervolume (mean $\pm$ std) after 20 BO iterations. qSTCH-Set uses batch size $K{=}m$; baselines evaluate $q{=}1$ per iteration. Best per column in \textbf{bold}. qSTCH-Set's advantage grows with~$m$, achieving 6.5\% over qNParEGO at $m{=}10$.}
\label{tab:main}
\centering
\begin{tabular}{lccc}
\toprule
Method & $m=5$ ($K{=}5$) & $m=8$ ($K{=}8$) & $m=10$ ($K{=}10$) \\
\midrule
\textbf{qSTCH-Set (ours)} & $6.22 \pm 0.50$ & $20.22 \pm 1.90$ & $\mathbf{46.95 \pm 1.31}$ \\
qNParEGO & $\mathbf{6.44 \pm 0.16}$ & $\mathbf{20.89 \pm 0.83}$ & $44.10 \pm 0.99$ \\
STCH-NParEGO & ---$^{\dagger}$ & $16.63 \pm 0.23$ & $38.39 \pm 0.72$ \\
Random & $5.37 \pm 0.14$ & $17.63 \pm 0.29$ & $40.44 \pm 0.33^{\ddagger}$ \\
\bottomrule
\end{tabular}
\vspace{2pt}
{\footnotesize $\dagger$ Not run in the $K{=}m$ campaign at $m{=}5$.\\
$\ddagger$ Random at $m{=}10$: 4 of 5 seeds completed.\\
qSTCH-Set uses $K{=}m$ (set-based); all baselines use $q{=}1$ (single-point).\\
STCH-NParEGO and Random results at $m{=}8$ and $m{=}10$ are from the $K{=}5$ campaign (5 seeds), which provides matching baseline comparisons; dedicated $K{=}m$ baseline re-runs are in progress.}
\end{table}

\emph{See Figure~\ref{fig:convergence_m10} in Appendix~\ref{app:extended}.}

\textbf{Performance at $m=5$.} With $K{=}m{=}5$, qSTCH-Set achieves a mean HV of $6.22 \pm 0.50$, comparable to qNParEGO ($6.44 \pm 0.16$). At this modest objective count, random scalarization weights still cover the Pareto front adequately, and qNParEGO's lower variance reflects the maturity of its single-point greedy strategy. However, the $K$-ablation study (Table~\ref{tab:ablation_k}) reveals that increasing $K$ beyond $m$ can improve qSTCH-Set's consistency.

\textbf{Scaling to $m=8$.} With $K{=}m{=}8$, qSTCH-Set achieves HV $20.22 \pm 1.90$, approaching qNParEGO ($20.89 \pm 0.83$). Crucially, with the default $K{=}5 < m{=}8$, qSTCH-Set only reaches $19.26 \pm 1.49$---setting $K{=}m$ closes this gap by 5\%, confirming the importance of the design rule. STCH-NParEGO ($16.63 \pm 0.23$), a single-point smooth Tchebycheff variant, performs significantly worse than both, highlighting that set-based coordination---not just smooth scalarization---is the key advantage.

\textbf{Scaling to $m=10$.} The advantage of set-based acquisition becomes decisive at $m{=}10$. With $K{=}m{=}10$, qSTCH-Set achieves HV $\mathbf{46.95 \pm 1.31}$, outperforming qNParEGO ($44.10 \pm 0.99$) by 6.5\%. STCH-NParEGO ($38.39 \pm 0.72$) and Random ($40.44 \pm 0.33$) fall far behind---notably, random search outperforms single-point STCH at $m{=}10$, underscoring that uncoordinated scalarization degrades rapidly with~$m$ as random weights concentrate in the simplex interior and fail to cover extremal trade-off directions.

\subsection{Ablation: Batch Size $K$}

To understand the importance of the design rule $K=m$, we compare performance with different batch sizes (Table~\ref{tab:ablation_k}, Figure~\ref{fig:k_ablation}).

\emph{See Figure~\ref{fig:k_ablation} in Appendix~\ref{app:extended}.}

\begin{table}[h]
\caption{$K$-Ablation on DTLZ2 ($m=5$): Impact of set size $K$ on final hypervolume (3 seeds). Larger $K$ improves both mean HV and reduces variance, with $K{=}10$ achieving the best result.}
\label{tab:ablation_k}
\centering
\begin{tabular}{lcc}
\toprule
Configuration & Final HV & Time/iter \\
\midrule
qSTCH-Set ($K=3 < m$) & $5.76 \pm 0.61$ & $1.4$s \\
qSTCH-Set ($K=m=5$) & $5.66 \pm 0.52$ & $2.4$s \\
qSTCH-Set ($K=10 > m$) & $\mathbf{6.24 \pm 0.36}$ & $6.1$s \\
\bottomrule
\end{tabular}
\end{table}

The ablation reveals that $K > m$ can further improve performance, suggesting the $K{=}m$ rule is a conservative lower bound. With $K{=}10$ at $m{=}5$, the mean HV increases to $6.24$ with notably reduced variance ($0.36$ vs $0.61$ for $K{=}3$), at the cost of higher per-iteration time. The cross-dimensional evidence is compelling: with $K{=}m$, qSTCH-Set approaches qNParEGO at $m{=}8$ ($20.22$ vs $20.89$) and decisively wins at $m{=}10$ ($46.95$ vs $44.10$), whereas $K < m$ consistently underperforms.

\subsection{Computational Cost}

Detailed wall-clock timings on H100 MIG partitions are in Appendix~\ref{app:extended-results}. The key finding is that per-iteration cost scales as $O(Nm^2)$: at $m{=}5$ ($K{=}5$), qSTCH-Set averages $\sim 23$s/iter (comparable to qNParEGO at $\sim 25$s/iter), while at $m{=}8$ ($K{=}8$) it rises to $\sim 336$s/iter due to the larger joint optimization space ($Kd = 96$ variables). However, for the target application---expensive black-box functions where each evaluation costs minutes to hours---the acquisition overhead is negligible, and the $K$-fold parallelism of batch evaluation offsets the per-iteration cost.

\subsection{Validation on Bi-Objective Problems}

On ZDT2 ($m=2$), STCH-NParEGO achieves HV $107.2 \pm 4.1$, slightly outperforming vanilla qNParEGO ($106.0 \pm 4.9$), confirming that the smooth approximation is effective even in the single-point regime. However, qEHVI remains the gold standard for $m=2$ ($111.1 \pm 2.2$), supporting our positioning of qSTCH-Set for many-objective problems where qEHVI is inapplicable.

%=============================================================================
\section{Related Work}
\label{sec:related}
%=============================================================================

\paragraph{Hypervolume-based and information-theoretic MOBO.}
qEHVI and qNEHVI~\citep{daulton2020qnehvi,daulton2021qnehvi} are the gold standard for $m \le 4$ objectives but require \#P-hard hypervolume partitioning~\citep{wang2024pohvi}, becoming intractable for $m > 5$.
Recent $\varepsilon$-PoHVI~\citep{wang2024pohvi} extends exact integration but remains limited to small~$m$.
Information-theoretic methods (MESMO~\citep{belakaria2019mesmo}, PFES~\citep{suzuki2020pfes}, JES~\citep{tu2022jes}) approximate entropy-based acquisitions but degrade similarly as Pareto front sampling costs grow with~$m$.
MORBO~\citep{daulton2022morbo} targets high-dimensional \emph{input} spaces, not many objectives.

\paragraph{Scalarization-based MOBO and smooth Tchebycheff.}
ParEGO~\citep{knowles2006parego} and qNParEGO~\citep{daulton2020qnehvi} use random Chebyshev weight vectors; for $m \gg 5$, these concentrate in the simplex interior and fail to cover extremal Pareto directions.
Lin et al.~\citep{lin2024smooth,lin2025few} introduced STCH and STCH-Set---log-sum-exp relaxations that are $C^\infty$, preserve Pareto optimality, and scale to $m{=}1{,}024$ in gradient-based optimization, but require cheap differentiable objectives.
Pires \& Coelho~\citep{pires2025stch} brought single-point STCH into the BO loop~\citep{astudillo2019composite} without set-based coordination.
Evolutionary methods (NSGA-III~\citep{deb2014nsga3}, MOEA/D~\citep{zhang2007moead}) handle many objectives but need thousands of evaluations, ruling them out for expensive black-box problems.
\textbf{qSTCH-Set} fills the remaining gap: set-based smooth Tchebycheff coordination within a sample-efficient BO loop.

\paragraph{Two-stage generative MOBO.}
Sorourifar et al.~\citep{paulson2025qpmhi} propose a ``generate-then-optimize'' framework for \emph{discrete} molecular design: a generative model proposes candidates; qPMHI ranks them by probability of maximum hypervolume improvement.
In contrast, qSTCH-Set targets \emph{continuous} spaces where end-to-end gradient flow jointly optimizes $K$ candidates through a single differentiable acquisition; the two approaches are complementary.

%=============================================================================
\section{Limitations}
\label{sec:limitations}
%=============================================================================

We discuss six limitations of qSTCH-Set in Appendix~\ref{app:limitations}, including evaluation budget asymmetry, $K<m$ degradation, benchmark scope, theory gap, non-convex acquisition, and statistical power.

%=============================================================================
\section{Conclusion}
\label{sec:conclusion}
%=============================================================================

We introduced qSTCH-Set, a Monte Carlo acquisition function that brings set-based smooth Tchebycheff scalarization from gradient-based many-objective optimization into the sample-efficient Bayesian optimization setting. By applying the STCH-Set smooth minimax formulation~\citep{lin2025few} to GP posterior samples, qSTCH-Set jointly optimizes $K$ candidates to cover $m$ objectives at $O(Km)$ per-evaluation cost, with surrogate-space Pareto optimality guarantees (Proposition~\ref{prop:pareto-transfer}(a)) and a smoothing gap bounded by $\mu\log(mK)$ (Proposition~\ref{prop:pareto-transfer}(b)).

The central empirical finding is the $K{=}m$ design rule: setting the batch size equal to the number of objectives, so that the smooth minimum operator assigns one candidate to each objective direction. On DTLZ2, this rule proves decisive---at $m{=}10$, qSTCH-Set achieves hypervolume $46.95 \pm 1.31$, outperforming qNParEGO ($44.10 \pm 0.99$) by 6.5\%; at $m{=}8$, setting $K{=}m{=}8$ closes the gap with qNParEGO from $19.26$ to $20.22$ (vs.\ $20.89$); and a $K$-ablation at $m{=}5$ confirms that increasing $K$ improves both mean HV and reduces seed-to-seed variance ($K{=}10$: $6.24 \pm 0.36$ vs.\ $K{=}3$: $5.76 \pm 0.61$). The advantage grows with $m$, precisely where random weight vectors concentrate in the simplex interior and fail to cover extremal trade-off directions.

Several directions are ripe for future work. \emph{Proving $K > 1$ consistency} (Conjecture~\ref{conj:consistency}) is the primary theoretical challenge, likely requiring set-valued epi-convergence arguments. \emph{Adaptive $K$ scheduling}---starting with $K < m$ when the budget is tight and increasing $K$ as the GP sharpens---could make qSTCH-Set practical for $m = 50$+ objectives without $m$-fold cost from the first iteration. \emph{$\mu$-annealing} ($\mu_t = c / \log(t+1)$) is theoretically motivated by Corollary~\ref{cor:annealing} and could eliminate the smoothing residual without manual tuning. Finally, the motivating application---\emph{drug discovery} with $m = 20$--$50$ ADMET endpoints and $K = 3$--$5$ lead candidates---represents the ultimate test: a regime where qEHVI is intractable, random scalarization is inadequate, and coordinated set-based acquisition may provide the first viable path to many-objective sample-efficient optimization.

%=============================================================================
\section*{Acknowledgments}
%=============================================================================
Compute resources were provided by the Digital Research Alliance of Canada (Nibi cluster). R.A.V.-H.\ acknowledges support from the Natural Sciences and Engineering Research Council of Canada (NSERC) and McMaster University.

\bibliographystyle{plainnat}
\bibliography{references}

%=============================================================================
% APPENDIX (external file)
%=============================================================================
\input{appendix}

\end{document}
