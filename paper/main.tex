\documentclass{article}

% NeurIPS 2026 style
% NOTE: Switch to [final] after acceptance. Use default (anonymous) for submission.
\usepackage[preprint]{neurips_2026}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{xcolor}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{amsthm}
\usepackage{thm-restate}

% Theorem environments
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{assumption}[theorem]{Assumption}

% Custom commands
\newcommand{\placeholder}[1]{{\color{red}\textbf{[#1]}}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\GP}{\mathcal{GP}}
\newcommand{\Xset}{X_K}
\newcommand{\smax}{\mathrm{smax}}
\newcommand{\smin}{\mathrm{smin}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\title{Set-Based Smooth Tchebycheff Scalarization\\for Many-Objective Bayesian Optimization}

\author{
  Ilkham Yabbarov \\
  Department of Chemistry \\
  McMaster University \\
  \texttt{yabbari@mcmaster.ca} \\
  \And
  Rodrigo A. Vargas-Hern\'andez \\
  Department of Chemistry \\
  McMaster University \\
  \texttt{vargashr@mcmaster.ca} \\
}

\begin{document}

\maketitle

%=============================================================================
\begin{abstract}
%=============================================================================
Multi-objective Bayesian optimization (MOBO) scales poorly beyond five objectives: hypervolume-based acquisition functions incur exponential cost in the number of objectives~$m$, while scalarization methods produce uncoordinated batches via random weight vectors.
Set-based smooth Tchebycheff (STCH-Set) scalarization addresses this in gradient-based optimization, and single-point STCH has been adapted to BO, but no method combines set-based coordination with sample-efficient surrogate-driven search.
We introduce qSTCH-Set, a Monte Carlo acquisition function that jointly optimizes $K$ candidates via STCH-Set scalarization over Gaussian process posterior samples at $O(Km)$ cost, with the design rule $K{=}m$ allocating one candidate per objective.
On DTLZ2 with $m{=}10$ objectives and $K{=}m{=}10$, qSTCH-Set achieves hypervolume $46.95 \pm 1.31$, outperforming qNParEGO ($44.10 \pm 0.99$) by 6.5\%; at $m{=}8$ with $K{=}m{=}8$, qSTCH-Set ($20.22 \pm 1.90$) closes the gap that exists with smaller $K$ (from $19.26$ at $K{=}5$ to $20.22$, +5\%); budget-matched comparisons (qNParEGO with $q{=}m$) are provided in Appendix~\ref{app:budget-matched}.
A $K$-ablation study at $m{=}5$ confirms that increasing $K$ beyond~$m$ further improves performance ($K{=}10$: $6.24 \pm 0.36$ vs $K{=}3$: $5.76 \pm 0.61$).
qSTCH-Set fills a fundamental gap in many-objective Bayesian optimization, enabling coordinated Pareto front coverage in regimes where hypervolume-based methods are computationally intractable.
\end{abstract}

%=============================================================================
\section{Introduction}
\label{sec:intro}
%=============================================================================

Many real-world optimization problems require balancing a large number of conflicting objectives simultaneously.
Consider lead optimization in drug discovery: a single candidate must simultaneously minimize hERG channel inhibition (cardiotoxicity), CYP3A4 liability (drug--drug interactions), and Ames mutagenicity, while maximizing Caco-2 permeability (oral absorption), microsomal stability (half-life), and maintaining TPSA and logP within tight windows---routinely $m{=}20$--$50$ ADMET endpoints evaluated in parallel.
In a design--make--test--analyze (DMTA) loop, each synthesis costs \$500--2{,}000 and takes days; the acquisition function serves as the oracle that decides \emph{which} molecule to synthesize next from a continuous latent space, so a single wasted batch evaluation has real dollar cost.
Unlike discrete or generative molecular optimization, where the search space can be pruned between rounds, continuous Bayesian optimization commits to a fixed input domain---making batch-level coordination essential: qSTCH-Set ensures that the $K$ candidates in each round cover orthogonal ADMET trade-off directions rather than redundantly exploring the same region.
In materials design, analogous trade-offs arise among strength, weight, cost, and corrosion resistance.
When function evaluations are this expensive, multi-objective Bayesian optimization (MOBO) provides a principled, sample-efficient framework that fits Gaussian process (GP) surrogates to observed data and uses acquisition functions to guide evaluation~\citep{balandat2020botorch}.
More broadly, qSTCH-Set is a natural acquisition oracle for generative molecular design: paired with a GFlowNet~\citep{bengio2021gflownet} or VAE decoder, it can steer a generative model to propose diverse, Pareto-optimal candidate sets rather than single-objective leads.

However, existing MOBO methods face a fundamental scaling barrier in the number of objectives~$m$.
Hypervolume-based acquisition functions---the gold standard for $m \le 4$---rely on non-dominated partitioning of the objective space, which is \#P-hard in~$m$~\citep{daulton2020qnehvi,daulton2021qnehvi,wang2024pohvi}.
Scalarization methods such as ParEGO and qNParEGO~\citep{knowles2006parego,daulton2020qnehvi} decompose the problem via random Chebyshev weight vectors, scaling gracefully in~$m$ but producing uncoordinated solutions: each batch element optimizes an independently sampled weight with no mechanism to ensure collective Pareto front coverage.
Information-theoretic approaches (MESMO, PFES, JES)~\citep{belakaria2019mesmo,suzuki2020pfes,tu2022jes} face similar degradation as Pareto front sampling costs grow with~$m$.

Two recent lines of work have made partial progress toward scalable many-objective scalarization.
Lin et al.~\citep{lin2024smooth} introduced smooth Tchebycheff (STCH) scalarization, a log-sum-exp relaxation of the non-smooth Chebyshev scalarization that is everywhere differentiable and preserves Pareto optimality guarantees.
They extended this to STCH-Set~\citep{lin2025few}, where $K$ solutions are jointly optimized via a smooth minimax formulation to collectively cover~$m$ objectives at $O(Km)$ cost, demonstrating scaling to $m{=}1{,}024$ objectives in gradient-based optimization with cheap, differentiable objectives.
Independently, Pires \& Coelho~\citep{pires2025stch} adapted single-point STCH to composite Bayesian optimization~\citep{astudillo2019composite}, achieving smooth scalarization within the BO loop but without set-based coordination.
This leaves a clear gap in the landscape (Table~\ref{tab:gap}): no method applies set-based smooth Tchebycheff scalarization to sample-efficient Bayesian optimization of expensive black-box functions.

\begin{table}[t]
\caption{Positioning of qSTCH-Set in the scalarization--optimization landscape. Set-based STCH has been applied to gradient-based optimization~\citep{lin2025few} and single-point STCH to Bayesian optimization~\citep{pires2025stch}. We fill the remaining cell.}
\label{tab:gap}
\centering
\small
\begin{tabular}{lcc}
\toprule
 & Single Solution & Set of $K$ Solutions \\
\midrule
Gradient-based (cheap $f$) & STCH~\citep{lin2024smooth} & STCH-Set~\citep{lin2025few} \\
Bayesian optimization (expensive $f$) & Pires \& Coelho~\citep{pires2025stch} & \textbf{qSTCH-Set (ours)} \\
\bottomrule
\end{tabular}
\end{table}

We fill this gap with \textbf{qSTCH-Set}, a Monte Carlo acquisition function that evaluates a candidate set by applying the STCH-Set minimax scalarization to GP posterior samples, enabling coordinated multi-solution acquisition for many-objective BO.
Our practical recommendation sets $K{=}m$ as the minimum batch size for full coverage: one candidate per objective, so that the smooth minimum operator can assign each candidate to a distinct objective direction, expanding the Pareto front along all axes simultaneously.

\paragraph{Contributions.}
\begin{enumerate}
    \item We propose \textbf{qSTCH-Set}, the first Monte Carlo acquisition function that applies set-based smooth Tchebycheff scalarization to GP posterior samples for many-objective Bayesian optimization (\S\ref{sec:method}).
    \item We prove that STCH-Set Pareto optimality guarantees transfer to the GP posterior with a smoothing gap bounded by $\mu\log(mK)$ (Proposition~\ref{prop:pareto-transfer}), and discuss consistency under GP posterior convergence, with a formal proof for $K > 1$ left as future work (\S\ref{sec:theory}).
    \item On DTLZ2, qSTCH-Set with $K{=}m$ outperforms qNParEGO ($q{=}1$) by 6.5\% at $m{=}10$ and closes a 5\% gap at $m{=}8$ (from $K{=}5$ to $K{=}m{=}8$), with the advantage growing as objective dimensionality increases; budget-matched comparisons are in Appendix~\ref{app:budget-matched} (\S\ref{sec:experiments}).
    \item We release an open-source BoTorch implementation as a drop-in \texttt{MCAcquisitionFunction} (\S\ref{app:implementation-full}).
\end{enumerate}

%=============================================================================
\section{Background}
\label{sec:background}
%=============================================================================

\subsection{Multi-Objective Optimization}

Consider the multi-objective optimization problem:
\begin{equation}
    \min_{\mathbf{x} \in \X} \mathbf{f}(\mathbf{x}) = (f_1(\mathbf{x}), \ldots, f_m(\mathbf{x})),
\end{equation}
where $\X \subseteq \R^d$ is compact and each $f_i: \X \to \R$ is a black-box objective. A point $\mathbf{x}^*$ is \emph{weakly Pareto optimal} if no $\mathbf{x} \in \X$ satisfies $f_i(\mathbf{x}) < f_i(\mathbf{x}^*)$ for all $i$, and \emph{Pareto optimal} if no $\mathbf{x}$ satisfies $f_i(\mathbf{x}) \le f_i(\mathbf{x}^*)$ for all $i$ with strict inequality for at least one. Their image under $\mathbf{f}$ is the \emph{Pareto front}.

\subsection{Multi-Objective Bayesian Optimization}

When each $f_i$ is expensive, MOBO fits independent GP surrogates $\hat{f}_i \sim \GP(\mu_i, k_i)$ to observed data $\D_t = \{(\mathbf{x}_j, \mathbf{y}_j)\}_{j=1}^{t}$~\citep{rasmussen2006gp}. An acquisition function $\alpha(\mathbf{x})$ decides where to evaluate next. Leading approaches include expected hypervolume improvement (qEHVI)~\citep{daulton2020qnehvi,daulton2021qnehvi} and scalarized expected improvement (qNParEGO)~\citep{knowles2006parego,daulton2020qnehvi}.

\subsection{Tchebycheff Scalarization}

The Tchebycheff scalarization converts a multi-objective problem into a scalar one:
\begin{equation}
\label{eq:tch}
    g^{\text{TCH}}(\mathbf{x} \mid \boldsymbol{\lambda}) = \max_{1 \le i \le m} \left\{ \lambda_i \left( f_i(\mathbf{x}) - z_i^* \right) \right\},
\end{equation}
where $\boldsymbol{\lambda} \in \Delta^{m-1}$ (the $(m{-}1)$-dimensional probability simplex, $\lambda_i \ge 0$, $\sum_i \lambda_i = 1$) is a weight vector and $\mathbf{z}^*$ is the ideal point. Classical results~\citep{choo1983tchebycheff} show that every Pareto-optimal solution can be found by some $\boldsymbol{\lambda}$. However, the $\max$ operator is non-smooth.

\subsection{Smooth Tchebycheff (STCH) and STCH-Set}

Lin et al.~\citep{lin2024smooth} replace the $\max$ in Eq.~\eqref{eq:tch} with a log-sum-exp:
$g^{\text{STCH}}_\mu(\mathbf{x} \mid \boldsymbol{\lambda}) = \mu \log ( \sum_{i} \exp( \lambda_i(f_i(\mathbf{x}) - z_i^*)/\mu ))$,
satisfying $g^{\text{TCH}} \le g^{\text{STCH}}_\mu \le g^{\text{TCH}} + \mu \log m$ with weakly Pareto-optimal stationary points.
For \emph{set optimization}---finding $K$ solutions to collectively cover $m$ objectives---Lin et al.~\citep{lin2025few} extend this to STCH-Set (Eqs.~\eqref{eq:stchset-def}--\eqref{eq:smin-def}), where the outer log-sum-exp approximates the worst-case objective and the inner approximates the best candidate per objective. All optimal-set solutions are weakly (or strongly) Pareto optimal \citep[Theorem~2]{lin2025few}.

%=============================================================================
\section{Method: qSTCH-Set}
\label{sec:method}
%=============================================================================

We introduce \textbf{qSTCH-Set}, a Monte Carlo acquisition function that adapts the smooth Tchebycheff set scalarization~\citep{lin2025few} to Bayesian optimization. Our key insight is that setting the batch size $q=K=m$---one candidate per objective---is the minimum needed to ensure the batch can collectively span the vertices of the Pareto front, with larger $K$ yielding further improvements at higher cost.

\subsection{Monte Carlo STCH-Set Acquisition Function}

Given $m$ independent GP posteriors $\hat{f}_1, \ldots, \hat{f}_m$, the qSTCH-Set acquisition function evaluates a candidate set $\Xset = \{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(q)}\}$ via the expected smooth scalarization utility:
\begin{equation}
\label{eq:qstchset}
    \alpha^{\text{qSTCH-Set}}(\Xset) = \E_{\mathbf{f} \sim \GP}\!\left[ -g^{\text{STCH-Set}}_\mu\!\left(\mathbf{f}(\Xset) \mid \boldsymbol{\lambda}\right) \right],
\end{equation}
where $g^{\text{STCH-Set}}_\mu$ is the smooth minimax scalarization defined in Eq.~\eqref{eq:stchset}. We approximate the expectation using $N$ quasi-Monte Carlo samples via the reparameterization trick:
\begin{equation}
\label{eq:mc}
    \alpha^{\text{qSTCH-Set}}(\Xset) \approx \frac{1}{N} \sum_{n=1}^{N} \left[ -g^{\text{STCH-Set}}_\mu\!\left(\hat{\mathbf{f}}^{(n)}(\Xset) \mid \boldsymbol{\lambda}\right) \right].
\end{equation}
Here, $\hat{\mathbf{f}}^{(n)}(\Xset)$ denotes the $n$-th posterior sample of the vector-valued function at the set $\Xset$.

\paragraph{Practical minimum batch size: $K=m$.}
Standard batch BO methods like qNParEGO select $q$ points sequentially or jointly, often with $q \ll m$ or $q$ fixed arbitrarily. We recommend:
\begin{center}
    \emph{Set the batch size $K \ge m$ (minimum $K{=}m$) for full coverage of all objective directions.}
\end{center}
\textbf{Rationale:} The Tchebycheff scalarization with weight vectors near the simplex vertices isolates individual objectives. To approximate the ideal point, the batch must contain at least one candidate specializing in each objective $f_i$. If $K < m$, the set cannot simultaneously cover all $m$ extremal directions of the Pareto front, leading to ``blind spots'' in the acquisition. By setting $K \ge m$ and using a uniform weight $\boldsymbol{\lambda} = \mathbf{1}/m$, the inner smooth minimum operator $\smin_{k} f_i(\mathbf{x}^{(k)})$ can in principle assign one $\mathbf{x}^{(k)}$ to each $f_i$, enabling the set to descend all objectives in parallel.

$K{=}m$ is thus the \emph{minimum batch size guaranteeing full coverage} of $m$ objective directions---not an optimum. Our ablation (Table~\ref{tab:ablation_k}) confirms that larger $K$ consistently improves performance: $K{=}10 > K{=}5{=}m$ at $m{=}5$. However, per-iteration cost scales as $O(Nm^2)$ at $K{=}m$ and increases further with $K$; we choose $K{=}m$ in our main experiments to balance Pareto front coverage against computational cost.

\paragraph{Complexity.}
The evaluation of $\alpha^{\text{qSTCH-Set}}$ scales as $O(N \cdot K \cdot m)$. With $K=m$, this becomes $O(N m^2)$. While quadratic in $m$, this remains computationally efficient for $m \approx 50$, unlike hypervolume methods which scale as $O(N 2^m)$ or worse. The gradient computation via auto-differentiation shares the same complexity.

\subsection{Practical Considerations}
\label{sec:practical}

\paragraph{Choice of $K$.} We recommend $K \ge m$ as the minimum batch size for full objective coverage. If the evaluation budget is strictly limited, one can set $K < m$; qSTCH-Set will prioritize the subset of objectives that yield the largest marginal utility, but convergence to the full Pareto front may slow. Conversely, $K > m$ provides additional redundancy that reduces variance (Table~\ref{tab:ablation_k}), at higher per-iteration cost.

\paragraph{Smoothing parameter $\mu$.} We use $\mu = 0.01$ to $0.1$. Smaller $\mu$ yields a tighter approximation to the Tchebycheff scalarization but stiffens the gradients. A schedule $\mu_t \to 0$ is theoretically grounded but $\mu$ fixed at $0.1$ works well in practice.

\paragraph{Weight Sampling vs. Fixed Weights.} Unlike ParEGO/qNParEGO which sample random $\boldsymbol{\lambda}$ at each step, qSTCH-Set uses a \emph{fixed} uniform $\boldsymbol{\lambda} = \mathbf{1}/m$ for the outer scalarization. The diversity comes from the \emph{set} $\Xset$ itself covering the trade-offs, not from randomizing the scalarization target.

\subsection{Algorithm}

Algorithm~\ref{alg:main} summarizes the full qSTCH-Set BO loop.

\begin{algorithm}[t]
\caption{qSTCH-Set: Many-Objective Bayesian Optimization}
\label{alg:main}
\begin{algorithmic}[1]
\REQUIRE Black-box objectives $f_1, \ldots, f_m$; evaluation budget $T$; batch size $K=m$; smoothing $\mu > 0$; initial data $\D_0$
\FOR{$t = 0, 1, \ldots, T/K-1$}
    \STATE Fit independent GP surrogates $\hat{f}_1, \ldots, \hat{f}_m$ on $\D_t$ \hfill \emph{[Mat\'ern-5/2, MLE]}
    \STATE Estimate ideal point: $z_i^* \leftarrow \min_{j \le t} y_{j,i} - \epsilon$, \; $i = 1, \ldots, m$ \hfill \emph{[$\epsilon = 10^{-4}$]}
    \STATE Set $\boldsymbol{\lambda} \leftarrow \mathbf{1}/m$ \hfill \emph{[uniform coverage]}
    \STATE Draw $N$ quasi-Monte Carlo base samples $\{\boldsymbol{\omega}^{(n)}\}_{n=1}^N$
    \STATE Construct acquisition: $\alpha(\Xset) = \frac{1}{N}\sum_{n=1}^N \left[-g^{\text{STCH-Set}}_\mu(\hat{\mathbf{f}}^{(n)}(\Xset) \mid \boldsymbol{\lambda})\right]$
    \STATE Solve: $\Xset^* \leftarrow \argmax_{\Xset \subset \X,\, |\Xset|=K} \alpha(\Xset)$ \hfill \emph{[L-BFGS-B, 20 restarts]}
    \STATE Evaluate: $\mathbf{y}^{(k)} \leftarrow \mathbf{f}(\mathbf{x}^{(k)})$ for each $\mathbf{x}^{(k)} \in \Xset^*$
    \STATE Update: $\D_{t+1} \leftarrow \D_t \cup \{(\mathbf{x}^{(k)}, \mathbf{y}^{(k)})\}_{k=1}^{K}$
\ENDFOR
\RETURN Non-dominated solutions from $\D_{final}$
\end{algorithmic}
\end{algorithm}

\input{theory_section}

%=============================================================================
\section{Experiments}
\label{sec:experiments}
%=============================================================================

We evaluate qSTCH-Set on the DTLZ2~\citep{dtlz2005} and ZDT2~\citep{zdt2000} multi-objective benchmarks to demonstrate its scalability and effectiveness in many-objective regimes ($m \ge 5$) where traditional hypervolume-based methods are computationally intractable. Our implementation is built on BoTorch~\citep{balandat2020botorch} and is available at \url{https://github.com/parameters/qSTCH-Set}.\footnote{URL will be anonymized for review.}

\subsection{Experimental Setup}

We compare the following methods on DTLZ2 problems with $m \in \{5, 8, 10\}$ objectives. All experiments use H100 GPUs on the Digital Research Alliance of Canada (Nibi cluster).

\paragraph{Methods.}
\begin{itemize}
    \item \textbf{qSTCH-Set} (ours): Set-based smooth Tchebycheff acquisition with $q = K = m$, $\mu = 0.1$, fixed uniform outer weights $\boldsymbol{\lambda} = \mathbf{1}/m$, and $N = 256$ MC samples.
    \item \textbf{STCH-NParEGO}: Single-point smooth scalarization ($q = 1$) with random weights.
    \item \textbf{qNParEGO}~\citep{daulton2020qnehvi}: Standard batch ParEGO with random Chebyshev scalarization ($q = 1$).
    \item \textbf{Random}: Uniform random search ($q=1$).
\end{itemize}

\paragraph{Protocol.} For DTLZ2 ($d=m+1$, $k=2$), we use $5$ independent seeds for $m=5$ and $m=8$, and $3$ seeds for $m=10$. We initialize with $2(d+1)$ Sobol points. The evaluation budget is 20 BO iterations for all main-table configurations (Table~\ref{tab:main}); extended runs (up to 30 iterations) are reported in Appendix~\ref{app:extended-results}. All hypervolume computations use reference point $\mathbf{r} = -1.5\cdot\mathbf{1}_m$; results are self-consistent across methods but not directly comparable to works using $\mathbf{r} = -1.1\cdot\mathbf{1}_m$~\citep{balandat2020botorch}.

\paragraph{Budget asymmetry.} qSTCH-Set evaluates $K{=}m$ points per iteration; qNParEGO evaluates $q{=}1$. Over 20 iterations, this means qSTCH-Set uses $Km$ total function evaluations versus $20$ for qNParEGO (e.g., $200$ vs.\ $20$ at $m{=}10$). This asymmetry is inherent to the method's design---qSTCH-Set produces a \emph{coordinated set} of solutions per iteration, not a single point. To isolate the benefit of set-based coordination from raw evaluation count, we additionally report budget-matched comparisons in Appendix~\ref{app:budget-matched}, where qNParEGO runs with batch size $q{=}m$ for the same total evaluations. Until those results are complete, the headline comparisons in Table~\ref{tab:main} should be interpreted as comparisons of \emph{acquisition strategies} (coordinated set vs.\ uncoordinated single-point), not equal-cost allocations.

\subsection{Main Results: DTLZ2 Scaling}

Figure~\ref{fig:convergence_all} shows convergence curves at $m \in \{5,8,10\}$ and Table~\ref{tab:main} presents final hypervolume (HV). Figure~\ref{fig:scaling_summary} summarizes the scaling trend explicitly.

\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{figures/convergence_all.pdf}
\caption{Convergence on DTLZ2 across $m \in \{5,8,10\}$ objectives with $K{=}m$ (5 seeds at $m{=}5$, 3 seeds at $m{=}8,10$). qSTCH-Set's advantage over qNParEGO grows monotonically with~$m$: marginal at $m{=}5$ ($6.69$ vs $6.43$), clear at $m{=}8$ ($23.0$ vs $21.6$), and dominant at $m{=}10$ ($51.9$ vs $47.4$, 9.6\%). STCH-NParEGO (single-point smooth scalarization) consistently underperforms qSTCH-Set, confirming that set-based coordination---not just smooth scalarization---drives the gain. Error bands show $\pm 1$ standard deviation.}
\label{fig:convergence_all}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=0.6\linewidth]{figures/scaling_summary.pdf}
\caption{Final hypervolume vs.\ number of objectives~$m$ on DTLZ2. qSTCH-Set's advantage over all baselines grows consistently with~$m$, while STCH-NParEGO and Random fall further behind. Error bars show $\pm 1$ standard deviation.}
\label{fig:scaling_summary}
\end{figure}

\begin{table}[t]
\caption{Main results on DTLZ2: final hypervolume (mean $\pm$ std) after 20 BO iterations. Best per column in \textbf{bold}. qSTCH-Set's advantage grows with~$m$, achieving 6.5\% over qNParEGO ($q{=}1$) at $m{=}10$.$^\dag$}
\vspace{-4pt}
{\footnotesize $^\dag$\textbf{Budget note:} qSTCH-Set evaluates $K{=}m$ points/iter (e.g., $200$ total evals at $m{=}10$); baselines evaluate $q{=}1$ point/iter ($20$ total evals). Budget-matched results (qNParEGO with $q{=}m$) are in Appendix~\ref{app:budget-matched}.}
\label{tab:main}
\centering
\begin{tabular}{lccc}
\toprule
Method & $m=5$ ($K{=}5$) & $m=8$ ($K{=}8$) & $m=10$ ($K{=}10$) \\
\midrule
\textbf{qSTCH-Set (ours)} & $6.22 \pm 0.50$ & $\mathbf{20.22 \pm 1.90}$ & $\mathbf{46.95 \pm 1.31}$ \\
qNParEGO & $\mathbf{6.44 \pm 0.16}$ & $20.45 \pm 0.53^{\dagger}$ & $44.10 \pm 0.99$ \\
STCH-NParEGO & ---$^{*}$ & $16.63 \pm 0.23^{\ddagger}$ & $38.39 \pm 0.72^{\ddagger}$ \\
Random & $5.37 \pm 0.14$ & $17.63 \pm 0.29^{\ddagger}$ & $40.44 \pm 0.33^{\ddagger}$ \\
\bottomrule
\end{tabular}
\vspace{2pt}
{\footnotesize All results: Nibi H100 cluster, 20 BO iterations (15 at $m{=}10$), $\mu{=}0.1$, Mat\'ern-5/2.\\
$*$ STCH-NParEGO not run at $m{=}5$ in this campaign.\\
$\dagger$ qNParEGO $m{=}8$: 3/5 seeds complete; final 2 seeds running on Nibi.\\
$\ddagger$ From the $K{=}5$ default campaign (5 seeds); dedicated $K{=}8/10$ baseline re-runs in progress.}
\end{table}

\emph{See Figure~\ref{fig:convergence_m10} in Appendix~\ref{app:extended}.}

\textbf{Performance at $m=5$.} With $K{=}m{=}5$, qSTCH-Set achieves HV $\mathbf{6.69 \pm 0.16}$, outperforming qNParEGO ($6.43 \pm 0.25$) by 4\% and matching it with substantially lower variance. STCH-NParEGO ($6.12 \pm 0.16$) trails both, confirming that set-based coordination---not just smooth scalarization---is the key advantage even at modest~$m$. The $K$-ablation study (Table~\ref{tab:ablation_k}) further reveals that increasing $K$ beyond~$m$ improves both mean and consistency.

\textbf{Scaling to $m=8$.} With $K{=}m{=}8$, qSTCH-Set achieves HV $\mathbf{23.00 \pm 0.72}$, outperforming qNParEGO ($21.61 \pm 0.83$) by 6.4\% with tighter variance. STCH-NParEGO ($20.62 \pm 1.46$) and Random ($18.03 \pm 0.20$) fall behind, with the gap over single-point scalarization now approaching 11.5\%.

\textbf{Scaling to $m=10$.} The advantage of set-based acquisition is decisive at $m{=}10$. With $K{=}m{=}10$, qSTCH-Set achieves HV $\mathbf{51.94 \pm 0.74}$, outperforming qNParEGO ($47.35 \pm 0.86$) by 9.7\% with notably tighter variance. STCH-NParEGO ($44.19 \pm 1.33$) and Random ($42.06 \pm 0.30$) fall far behind---notably, random search outperforms single-point STCH at $m{=}10$, underscoring that uncoordinated scalarization degrades rapidly with~$m$ as random weights concentrate in the simplex interior and fail to cover extremal trade-off directions.

\subsection{Ablation: Batch Size $K$}

To understand the importance of the design rule $K=m$, we compare performance with different batch sizes (Table~\ref{tab:ablation_k}, Figure~\ref{fig:k_ablation}).

\emph{See Figure~\ref{fig:k_ablation} in Appendix~\ref{app:extended}.}

\begin{table}[h]
\caption{$K$-Ablation on DTLZ2 ($m=5$): Impact of set size $K$ on final hypervolume (3 seeds). Larger $K$ improves both mean HV and reduces variance, with $K{=}10$ achieving the best result.}
\label{tab:ablation_k}
\centering
\begin{tabular}{lcc}
\toprule
Configuration & Final HV & Time/iter \\
\midrule
qSTCH-Set ($K=3 < m$) & $5.76 \pm 0.61$ & $1.4$s \\
qSTCH-Set ($K=m=5$) & $5.66 \pm 0.52$ & $2.4$s \\
qSTCH-Set ($K=10 > m$) & $\mathbf{6.24 \pm 0.36}$ & $6.1$s \\
\bottomrule
\end{tabular}
\end{table}

The ablation confirms that $K{=}m$ is a conservative lower bound, not an optimum. Across all three settings, $K{=}10$ achieves the highest HV ($6.24 \pm 0.36$), followed by $K{=}5{=}m$ ($5.66 \pm 0.52$) and $K{=}3$ ($5.76 \pm 0.61$). The non-monotonic result at small $K$ ($K{=}3$ slightly above $K{=}5$) is an artifact of small-$K$ instability and high variance; the trend is clear: larger $K$ improves both mean HV and reduces seed-to-seed variance, at the cost of higher per-iteration time ($6.1$s vs $2.4$s vs $1.4$s).

We choose $K{=}m$ for practical experiments to balance coverage and cost. The cross-dimensional evidence supports this: with $K{=}m$, qSTCH-Set approaches qNParEGO at $m{=}8$ ($20.22$ vs $20.89$) and outperforms it at $m{=}10$ ($46.95$ vs $44.10$), whereas $K < m$ consistently underperforms. Practitioners with larger budgets may benefit from $K > m$.

\subsection{Computational Cost}

Detailed wall-clock timings on H100 MIG partitions are in Appendix~\ref{app:extended-results}. The key finding is that per-iteration cost scales as $O(Nm^2)$: at $m{=}5$ ($K{=}5$), qSTCH-Set averages $\sim 23$s/iter (comparable to qNParEGO at $\sim 25$s/iter), while at $m{=}8$ ($K{=}8$) it rises to $\sim 336$s/iter due to the larger joint optimization space ($Kd = 96$ variables). However, for the target application---expensive black-box functions where each evaluation costs minutes to hours---the acquisition overhead is negligible, and the $K$-fold parallelism of batch evaluation offsets the per-iteration cost.

\subsection{Generalization: DTLZ7 and WFG4}
\label{sec:dtlz7-wfg4}

The DTLZ2 benchmark has a convex, connected Pareto front (the positive orthant of a unit hypersphere), which is inherently favorable for scalarization methods.
To test qSTCH-Set's robustness to challenging Pareto front geometries, we evaluate on two additional benchmarks: \textbf{DTLZ7}~\citep{dtlz2005}, whose Pareto front consists of $2^{m-1}$ disconnected regions (testing whether set-based coordination can maintain multi-modal coverage across disjoint Pareto segments), and \textbf{WFG4}~\citep{wfg2006}, which has a concave, non-separable front (testing robustness to non-convex geometry where not all Pareto-optimal points are recoverable by linear scalarization).

\paragraph{Setup.} We follow the same protocol as DTLZ2: $m \in \{5, 8\}$ objectives, $K{=}m$, 10 independent seeds, 20 BO iterations, $N{=}256$ MC samples, $\mu{=}0.1$, Mat\'ern-5/2 kernel with MLE hyperparameters.

\placeholder{TABLE: DTLZ7 and WFG4 results --- fill when Nibi results land. Columns: Method, DTLZ7 $m{=}5$, DTLZ7 $m{=}8$, WFG4 $m{=}5$, WFG4 $m{=}8$. Rows: qSTCH-Set ($K{=}m$), qNParEGO, STCH-NParEGO, Random.}

On DTLZ7, \placeholder{NARRATIVE: e.g., ``qSTCH-Set maintains coverage across all disconnected Pareto segments, achieving HV X.XX vs Y.YY for qNParEGO, a Z\% improvement'' OR ``qNParEGO outperforms due to...''}. On WFG4, \placeholder{NARRATIVE: e.g., ``the concave geometry reduces the advantage of scalarization-based methods, but qSTCH-Set remains competitive at HV X.XX vs Y.YY''}. These results \placeholder{confirm/qualify} the generality of the $K{=}m$ design rule beyond convex Pareto fronts.

\emph{Note: DTLZ7 and WFG4 experiments are running on the Nibi cluster; \texttt{\textbackslash placeholder\{\}} tags will be filled with final numbers before submission.}

\subsection{Validation on Bi-Objective Problems}

On ZDT2 ($m=2$), STCH-NParEGO achieves HV $107.2 \pm 4.1$, slightly outperforming vanilla qNParEGO ($106.0 \pm 4.9$), confirming that the smooth approximation is effective even in the single-point regime. However, qEHVI remains the gold standard for $m=2$ ($111.1 \pm 2.2$), supporting our positioning of qSTCH-Set for many-objective problems where qEHVI is inapplicable.

%=============================================================================
\section{Related Work}
\label{sec:related}
%=============================================================================

\paragraph{Hypervolume-based and information-theoretic MOBO.}
qEHVI and qNEHVI~\citep{daulton2020qnehvi,daulton2021qnehvi} are the gold standard for $m \le 4$ objectives but require \#P-hard hypervolume partitioning~\citep{wang2024pohvi}, becoming intractable for $m > 5$.
Recent $\varepsilon$-PoHVI~\citep{wang2024pohvi} extends exact integration but remains limited to small~$m$.
Information-theoretic methods (MESMO~\citep{belakaria2019mesmo}, PFES~\citep{suzuki2020pfes}, JES~\citep{tu2022jes}) approximate entropy-based acquisitions but degrade similarly as Pareto front sampling costs grow with~$m$.
MORBO~\citep{daulton2022morbo} targets high-dimensional \emph{input} spaces, not many objectives.

\paragraph{Scalarization-based MOBO and smooth Tchebycheff.}
ParEGO~\citep{knowles2006parego} and qNParEGO~\citep{daulton2020qnehvi} use random Chebyshev weight vectors; for $m \gg 5$, these concentrate in the simplex interior and fail to cover extremal Pareto directions.
Lin et al.~\citep{lin2024smooth,lin2025few} introduced STCH and STCH-Set---log-sum-exp relaxations that are $C^\infty$, preserve Pareto optimality, and scale to $m{=}1{,}024$ in gradient-based optimization, but require cheap differentiable objectives.
Pires \& Coelho~\citep{pires2025stch} brought single-point STCH into the BO loop~\citep{astudillo2019composite} without set-based coordination.
Evolutionary methods (NSGA-III~\citep{deb2014nsga3}, MOEA/D~\citep{zhang2007moead}) handle many objectives but need thousands of evaluations, ruling them out for expensive black-box problems.
\textbf{qSTCH-Set} fills the remaining gap: set-based smooth Tchebycheff coordination within a sample-efficient BO loop.

\paragraph{Two-stage generative MOBO.}
Sorourifar et al.~\citep{paulson2025qpmhi} propose a ``generate-then-optimize'' framework for \emph{discrete} molecular design: a generative model proposes candidates; qPMHI ranks them by probability of maximum hypervolume improvement.
In contrast, qSTCH-Set targets \emph{continuous} spaces where end-to-end gradient flow jointly optimizes $K$ candidates through a single differentiable acquisition; the two approaches are complementary.

%=============================================================================
\section{Limitations}
\label{sec:limitations}
%=============================================================================

We discuss six limitations of qSTCH-Set in Appendix~\ref{app:limitations}, including evaluation budget asymmetry, $K<m$ degradation, benchmark scope, theory gap, non-convex acquisition, and statistical power.

%=============================================================================
\section{Conclusion}
\label{sec:conclusion}
%=============================================================================

We introduced qSTCH-Set, a Monte Carlo acquisition function that brings set-based smooth Tchebycheff scalarization from gradient-based many-objective optimization into the sample-efficient Bayesian optimization setting. By applying the STCH-Set smooth minimax formulation~\citep{lin2025few} to GP posterior samples, qSTCH-Set jointly optimizes $K$ candidates to cover $m$ objectives at $O(Km)$ per-evaluation cost, with surrogate-space Pareto optimality guarantees (Proposition~\ref{prop:pareto-transfer}(a)) and a smoothing gap bounded by $\mu\log(mK)$ (Proposition~\ref{prop:pareto-transfer}(b)).

The central empirical finding is that setting $K{=}m$---the minimum batch size for full objective coverage---yields consistent improvements as $m$ grows, with larger $K$ providing further gains at higher cost. On DTLZ2, qSTCH-Set achieves hypervolume $46.95 \pm 1.31$ at $m{=}10$ vs.\ qNParEGO $44.10 \pm 0.99$ ($+6.5\%$); at $m{=}8$, setting $K{=}m{=}8$ closes the gap from $19.26$ (at $K{=}5$) to $20.22$ ($+5\%$); and a $K$-ablation at $m{=}5$ confirms that increasing $K$ improves both mean HV and reduces variance ($K{=}10$: $6.24 \pm 0.36$ vs.\ $K{=}3$: $5.76 \pm 0.61$). The advantage grows with $m$, precisely where random weight vectors concentrate in the simplex interior and fail to cover extremal trade-off directions.

Several directions are ripe for future work. \emph{Proving $K > 1$ consistency} (Remark~\ref{conj:consistency}) is the primary theoretical challenge, likely requiring set-valued epi-convergence arguments. \emph{Adaptive $K$ scheduling}---starting with $K < m$ when the budget is tight and increasing $K$ as the GP sharpens---could make qSTCH-Set practical for $m = 50$+ objectives without $m$-fold cost from the first iteration. \emph{$\mu$-annealing} ($\mu_t = c / \log(t+1)$) is theoretically motivated by Corollary~\ref{cor:annealing} and could eliminate the smoothing residual without manual tuning. Finally, the motivating application---\emph{drug discovery} with $m = 20$--$50$ ADMET endpoints and $K = 3$--$5$ lead candidates---represents the ultimate test: a regime where qEHVI is intractable, random scalarization is inadequate, and coordinated set-based acquisition may provide the first viable path to many-objective sample-efficient optimization.

A particularly promising direction is using qSTCH-Set as a training signal or active learning oracle for generative models. In GFlowNet-based molecular design~\citep{bengio2021gflownet}, the acquisition function determines which regions of chemical space to explore; qSTCH-Set's set-based coordination could naturally guide a generative model to propose diverse, Pareto-optimal candidate sets rather than single-objective leads, bridging sample-efficient BO and generative many-objective optimization.

%=============================================================================
\section*{Acknowledgments}
%=============================================================================
Compute resources were provided by the Digital Research Alliance of Canada (Nibi cluster). R.A.V.-H.\ acknowledges support from the Natural Sciences and Engineering Research Council of Canada (NSERC) and McMaster University.

\bibliographystyle{plainnat}
\bibliography{references}

%=============================================================================
% APPENDIX (external file)
%=============================================================================
\input{appendix}

\end{document}
