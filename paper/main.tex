\documentclass{article}

% NeurIPS 2026 style
\usepackage[final]{neurips_2026}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{xcolor}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{amsthm}
\usepackage{thm-restate}

% Theorem environments
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{assumption}[theorem]{Assumption}

% Custom commands
\newcommand{\placeholder}[1]{{\color{red}\textbf{[#1]}}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\GP}{\mathcal{GP}}
\newcommand{\Xset}{X_K}
\newcommand{\smax}{\mathrm{smax}}
\newcommand{\smin}{\mathrm{smin}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\title{Set-Based Smooth Tchebycheff Scalarization\\for Many-Objective Bayesian Optimization}

\author{
  Ilkham Yabbarov \\
  Department of Chemistry \\
  McMaster University \\
  \texttt{yabbari@mcmaster.ca} \\
  \And
  Rodrigo A. Vargas-Hern\'andez \\
  Department of Chemistry \\
  McMaster University \\
  \texttt{vargashr@mcmaster.ca} \\
}

\begin{document}

\maketitle

%=============================================================================
\begin{abstract}
%=============================================================================
Multi-objective Bayesian optimization (MOBO) scales poorly beyond five objectives: hypervolume-based acquisition functions incur exponential cost in the number of objectives~$m$, while scalarization methods produce uncoordinated batches via random weight vectors.
Set-based smooth Tchebycheff (STCH-Set) scalarization addresses this in gradient-based optimization, and single-point STCH has been adapted to BO, but no method combines set-based coordination with sample-efficient surrogate-driven search.
We introduce qSTCH-Set, a Monte Carlo acquisition function that jointly optimizes $K$ candidates via STCH-Set scalarization over Gaussian process posterior samples at $O(Km)$ cost, with the design rule $K{=}m$ allocating one candidate per objective.
On DTLZ2 with $m{=}10$ objectives and $K{=}m{=}10$, qSTCH-Set achieves hypervolume $46.95 \pm 1.31$, outperforming qNParEGO ($44.10 \pm 0.99$) by 6.5\%; at $m{=}8$ with $K{=}m{=}8$, qSTCH-Set approaches qNParEGO ($20.22$ vs $20.89$), closing a gap that exists with smaller $K$ (from $19.26$ to $20.22$, a 5\% improvement).
A $K$-ablation study at $m{=}5$ confirms that increasing $K$ improves both mean HV and consistency ($K{=}10$: $6.24 \pm 0.36$ vs $K{=}3$: $5.76 \pm 0.61$).
qSTCH-Set fills a fundamental gap in many-objective Bayesian optimization, enabling coordinated Pareto front coverage in regimes where hypervolume-based methods are computationally intractable.
\end{abstract}

%=============================================================================
\section{Introduction}
\label{sec:intro}
%=============================================================================

Many real-world optimization problems require balancing a large number of conflicting objectives simultaneously.
In drug discovery, a candidate molecule must satisfy constraints on potency, selectivity, metabolic stability, permeability, and toxicity---routinely $m{=}20$--$50$ ADMET endpoints~\citep{knowles2006parego}.
In materials design, one seeks alloys balancing strength, weight, cost, and corrosion resistance.
When function evaluations are expensive---requiring physical experiments, molecular simulations, or costly assays---multi-objective Bayesian optimization (MOBO) provides a principled, sample-efficient framework that fits Gaussian process (GP) surrogates to observed data and uses acquisition functions to guide evaluation~\citep{balandat2020botorch}.

However, existing MOBO methods face a fundamental scaling barrier in the number of objectives~$m$.
Hypervolume-based acquisition functions---the gold standard for $m \le 4$---rely on non-dominated partitioning of the objective space, which is \#P-hard in~$m$~\citep{daulton2020qnehvi,daulton2021qnehvi,wang2024pohvi}.
Scalarization methods such as ParEGO and qNParEGO~\citep{knowles2006parego,daulton2020qnehvi} decompose the problem via random Chebyshev weight vectors, scaling gracefully in~$m$ but producing uncoordinated solutions: each batch element optimizes an independently sampled weight with no mechanism to ensure collective Pareto front coverage.
Information-theoretic approaches (MESMO, PFES, JES)~\citep{belakaria2019mesmo,suzuki2020pfes,tu2022jes} face similar degradation as Pareto front sampling costs grow with~$m$.

Two recent lines of work have made partial progress toward scalable many-objective scalarization.
Lin et al.~\citep{lin2024smooth} introduced smooth Tchebycheff (STCH) scalarization, a log-sum-exp relaxation of the non-smooth Chebyshev scalarization that is everywhere differentiable and preserves Pareto optimality guarantees.
They extended this to STCH-Set~\citep{lin2025few}, where $K$ solutions are jointly optimized via a smooth minimax formulation to collectively cover~$m$ objectives at $O(Km)$ cost, demonstrating scaling to $m{=}1{,}024$ objectives in gradient-based optimization with cheap, differentiable objectives.
Independently, Pires \& Coelho~\citep{pires2025stch} adapted single-point STCH to composite Bayesian optimization~\citep{astudillo2019composite}, achieving smooth scalarization within the BO loop but without set-based coordination.
This leaves a clear gap in the landscape (Table~\ref{tab:gap}): no method applies set-based smooth Tchebycheff scalarization to sample-efficient Bayesian optimization of expensive black-box functions.

\begin{table}[t]
\caption{Positioning of qSTCH-Set in the scalarization--optimization landscape. Set-based STCH has been applied to gradient-based optimization~\citep{lin2025few} and single-point STCH to Bayesian optimization~\citep{pires2025stch}. We fill the remaining cell.}
\label{tab:gap}
\centering
\small
\begin{tabular}{lcc}
\toprule
 & Single Solution & Set of $K$ Solutions \\
\midrule
Gradient-based (cheap $f$) & STCH~\citep{lin2024smooth} & STCH-Set~\citep{lin2025few} \\
Bayesian optimization (expensive $f$) & Pires \& Coelho~\citep{pires2025stch} & \textbf{qSTCH-Set (ours)} \\
\bottomrule
\end{tabular}
\end{table}

We fill this gap with \textbf{qSTCH-Set}, a Monte Carlo acquisition function that evaluates a candidate set by applying the STCH-Set minimax scalarization to GP posterior samples, enabling coordinated multi-solution acquisition for many-objective BO.
Our key design rule sets $K{=}m$: one candidate per objective, so that the smooth minimum operator assigns each candidate to a distinct objective direction, expanding the Pareto front along all axes simultaneously.

\paragraph{Contributions.}
\begin{enumerate}
    \item We propose \textbf{qSTCH-Set}, the first Monte Carlo acquisition function that applies set-based smooth Tchebycheff scalarization to GP posterior samples for many-objective Bayesian optimization (\S\ref{sec:method}).
    \item We prove that STCH-Set Pareto optimality guarantees transfer asymptotically under GP posterior concentration, with an explicit approximation gap of $\mu\log(mK) + O(\beta_t^{1/2}\bar{\sigma}_t)$ (\S\ref{sec:theory}).
    \item On DTLZ2, qSTCH-Set with $K{=}m$ outperforms qNParEGO by 6.5\% at $m{=}10$ objectives and matches it at $m{=}8$, with the advantage growing as objective dimensionality increases (\S\ref{sec:experiments}).
    \item We release an open-source BoTorch implementation as a drop-in \texttt{MCAcquisitionFunction} (\S\ref{app:implementation-full}).
\end{enumerate}

%=============================================================================
\section{Background}
\label{sec:background}
%=============================================================================

\subsection{Multi-Objective Optimization}

Consider the multi-objective optimization problem:
\begin{equation}
    \min_{\mathbf{x} \in \X} \mathbf{f}(\mathbf{x}) = (f_1(\mathbf{x}), \ldots, f_m(\mathbf{x})),
\end{equation}
where $\X \subseteq \R^d$ is compact and each $f_i: \X \to \R$ is a black-box objective. A point $\mathbf{x}^*$ is \emph{weakly Pareto optimal} if no $\mathbf{x} \in \X$ satisfies $f_i(\mathbf{x}) < f_i(\mathbf{x}^*)$ for all $i$, and \emph{Pareto optimal} if no $\mathbf{x}$ satisfies $f_i(\mathbf{x}) \le f_i(\mathbf{x}^*)$ for all $i$ with strict inequality for at least one. Their image under $\mathbf{f}$ is the \emph{Pareto front}.

\subsection{Multi-Objective Bayesian Optimization}

When each $f_i$ is expensive, MOBO fits independent GP surrogates $\hat{f}_i \sim \GP(\mu_i, k_i)$ to observed data $\D_t = \{(\mathbf{x}_j, \mathbf{y}_j)\}_{j=1}^{t}$~\citep{rasmussen2006gp}. An acquisition function $\alpha(\mathbf{x})$ decides where to evaluate next. Leading approaches include expected hypervolume improvement (qEHVI)~\citep{daulton2020qnehvi,daulton2021qnehvi} and scalarized expected improvement (qNParEGO)~\citep{knowles2006parego,daulton2020qnehvi}.

\subsection{Tchebycheff Scalarization}

The Tchebycheff scalarization converts a multi-objective problem into a scalar one:
\begin{equation}
\label{eq:tch}
    g^{\text{TCH}}(\mathbf{x} \mid \boldsymbol{\lambda}) = \max_{1 \le i \le m} \left\{ \lambda_i \left( f_i(\mathbf{x}) - z_i^* \right) \right\},
\end{equation}
where $\boldsymbol{\lambda} \in \Delta^{m-1}$ is a weight vector and $\mathbf{z}^*$ is the ideal point. Classical results~\citep{choo1983tchebycheff} show that every Pareto-optimal solution can be found by some $\boldsymbol{\lambda}$. However, the $\max$ operator is non-smooth.

\subsection{Smooth Tchebycheff (STCH) and STCH-Set}

Lin et al.~\citep{lin2024smooth} replace the $\max$ with a log-sum-exp approximation:
\begin{equation}
\label{eq:stch}
    g^{\text{STCH}}_\mu(\mathbf{x} \mid \boldsymbol{\lambda}) = \mu \log \left( \sum_{i=1}^{m} \exp\!\left( \frac{\lambda_i(f_i(\mathbf{x}) - z_i^*)}{\mu} \right) \right),
\end{equation}
where $\mu > 0$ controls smoothness. This satisfies $g^{\text{TCH}} \le g^{\text{STCH}}_\mu \le g^{\text{TCH}} + \mu \log m$, and its stationary points are weakly Pareto optimal~\citep{lin2024smooth}.

For the \emph{set optimization} problem---finding $K$ solutions $\Xset = \{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(K)}\}$ to collectively cover $m$ objectives---Lin et al.~\citep{lin2025few} propose:
\begin{equation}
\label{eq:stchset}
    g^{\text{STCH-Set}}_\mu(\Xset \mid \boldsymbol{\lambda}) = \mu \log \left( \sum_{i=1}^{m} \exp\!\left( \frac{\lambda_i \left( \smin_{k} f_i(\mathbf{x}^{(k)}) - z_i^* \right)}{\mu} \right) \right),
\end{equation}
where the smooth minimum over candidates is:
\begin{equation}
\label{eq:smin}
    \smin_{k=1}^{K} f_i(\mathbf{x}^{(k)}) = -\mu \log \left( \sum_{k=1}^{K} \exp\!\left( -\frac{f_i(\mathbf{x}^{(k)})}{\mu} \right) \right).
\end{equation}
The outer log-sum-exp approximates the worst-case objective (smooth max), while the inner approximates the best candidate per objective (smooth min). This enables $K \ll m$ solutions to coordinate and cover all objectives.

\begin{theorem}[Theorem~2 of \citet{lin2025few}]
\label{thm:lin}
All solutions in the optimal set $\Xset^*$ for the STCH-Set problem~\eqref{eq:stchset} are weakly Pareto optimal. They are Pareto optimal if $\lambda_i > 0$ for all $i$, or if $\Xset^*$ is unique.
\end{theorem}

%=============================================================================
\section{Method: qSTCH-Set}
\label{sec:method}
%=============================================================================

We introduce \textbf{qSTCH-Set}, a Monte Carlo acquisition function that adapts the smooth Tchebycheff set scalarization~\citep{lin2025few} to Bayesian optimization. Our key insight is a principled design rule for the batch size: we set $q=K=m$, allocating one candidate per objective to ensure the batch can collectively span the vertices of the Pareto front.

\subsection{Monte Carlo STCH-Set Acquisition Function}

Given $m$ independent GP posteriors $\hat{f}_1, \ldots, \hat{f}_m$, the qSTCH-Set acquisition function evaluates a candidate set $\Xset = \{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(q)}\}$ via the expected smooth scalarization utility:
\begin{equation}
\label{eq:qstchset}
    \alpha^{\text{qSTCH-Set}}(\Xset) = \E_{\mathbf{f} \sim \GP}\!\left[ -g^{\text{STCH-Set}}_\mu\!\left(\mathbf{f}(\Xset) \mid \boldsymbol{\lambda}\right) \right],
\end{equation}
where $g^{\text{STCH-Set}}_\mu$ is the smooth minimax scalarization defined in Eq.~\eqref{eq:stchset}. We approximate the expectation using $N$ quasi-Monte Carlo samples via the reparameterization trick:
\begin{equation}
\label{eq:mc}
    \alpha^{\text{qSTCH-Set}}(\Xset) \approx \frac{1}{N} \sum_{n=1}^{N} \left[ -g^{\text{STCH-Set}}_\mu\!\left(\hat{\mathbf{f}}^{(n)}(\Xset) \mid \boldsymbol{\lambda}\right) \right].
\end{equation}
Here, $\hat{\mathbf{f}}^{(n)}(\Xset)$ denotes the $n$-th posterior sample of the vector-valued function at the set $\Xset$.

\paragraph{The $K=m$ Design Rule.}
Standard batch BO methods like qNParEGO select $q$ points sequentially or jointly, often with $q \ll m$ or $q$ fixed arbitrarily. We propose a rigorous coupling:
\begin{center}
    \emph{Set the batch size $K$ equal to the number of objectives $m$.}
\end{center}
\textbf{Intuition:} The Tchebycheff scalarization with weight vectors near the simplex vertices isolates individual objectives. To approximate the ideal point, the batch must contain at least one candidate specializing in each objective $f_i$. If $K < m$, the set cannot simultaneously cover all $m$ extremal directions of the Pareto front, leading to ``blind spots'' in the acquisition. By setting $K=m$ and using a uniform weight $\boldsymbol{\lambda} = \mathbf{1}/m$, the inner smooth minimum operator $\smin_{k} f_i(\mathbf{x}^{(k)})$ effectively assigns one $\mathbf{x}^{(k)}$ to each $f_i$, enabling the set to descend all objectives in parallel.

\paragraph{Complexity.}
The evaluation of $\alpha^{\text{qSTCH-Set}}$ scales as $O(N \cdot K \cdot m)$. With $K=m$, this becomes $O(N m^2)$. While quadratic in $m$, this remains computationally efficient for $m \approx 50$, unlike hypervolume methods which scale as $O(N 2^m)$ or worse. The gradient computation via auto-differentiation shares the same complexity.

\subsection{Practical Considerations}
\label{sec:practical}

\paragraph{Choice of $K$.} While we recommend $K=m$ for balanced exploration, if evaluation budget is strictly limited, one can set $K < m$. In this case, qSTCH-Set will prioritize the subset of objectives that yield the largest marginal utility, but convergence to the full Pareto front may slow.

\paragraph{Smoothing parameter $\mu$.} We use $\mu = 0.01$ to $0.1$. Smaller $\mu$ yields a tighter approximation to the Tchebycheff scalarization but stiffens the gradients. A schedule $\mu_t \to 0$ is theoretically grounded but $\mu$ fixed at $0.1$ works well in practice.

\paragraph{Weight Sampling vs. Fixed Weights.} Unlike ParEGO/qNParEGO which sample random $\boldsymbol{\lambda}$ at each step, qSTCH-Set uses a \emph{fixed} uniform $\boldsymbol{\lambda} = \mathbf{1}/m$ for the outer scalarization. The diversity comes from the \emph{set} $\Xset$ itself covering the trade-offs, not from randomizing the scalarization target.

\subsection{Algorithm}

Algorithm~\ref{alg:main} summarizes the full qSTCH-Set BO loop.

\begin{algorithm}[t]
\caption{qSTCH-Set: Many-Objective Bayesian Optimization}
\label{alg:main}
\begin{algorithmic}[1]
\REQUIRE Black-box objectives $f_1, \ldots, f_m$; evaluation budget $T$; batch size $K=m$; smoothing $\mu > 0$; initial data $\D_0$
\FOR{$t = 0, 1, \ldots, T/K-1$}
    \STATE Fit independent GP surrogates $\hat{f}_1, \ldots, \hat{f}_m$ on $\D_t$ \hfill \emph{[Mat\'ern-5/2, MLE]}
    \STATE Estimate ideal point: $z_i^* \leftarrow \min_{j \le t} y_{j,i} - \epsilon$, \; $i = 1, \ldots, m$
    \STATE Set $\boldsymbol{\lambda} \leftarrow \mathbf{1}/m$ \hfill \emph{[uniform coverage]}
    \STATE Draw $N$ quasi-Monte Carlo base samples $\{\boldsymbol{\omega}^{(n)}\}_{n=1}^N$
    \STATE Construct acquisition: $\alpha(\Xset) = \frac{1}{N}\sum_{n=1}^N \left[-g^{\text{STCH-Set}}_\mu(\hat{\mathbf{f}}^{(n)}(\Xset) \mid \boldsymbol{\lambda})\right]$
    \STATE Solve: $\Xset^* \leftarrow \argmax_{\Xset \subset \X,\, |\Xset|=K} \alpha(\Xset)$ \hfill \emph{[L-BFGS-B, 20 restarts]}
    \STATE Evaluate: $\mathbf{y}^{(k)} \leftarrow \mathbf{f}(\mathbf{x}^{(k)})$ for each $\mathbf{x}^{(k)} \in \Xset^*$
    \STATE Update: $\D_{t+1} \leftarrow \D_t \cup \{(\mathbf{x}^{(k)}, \mathbf{y}^{(k)})\}_{k=1}^{K}$
\ENDFOR
\RETURN Non-dominated solutions from $\D_{final}$
\end{algorithmic}
\end{algorithm}

\input{theory_section}

%=============================================================================
\section{Experiments}
\label{sec:experiments}
%=============================================================================

We evaluate qSTCH-Set on standard multi-objective benchmarks (DTLZ2, ZDT2) to demonstrate its scalability and effectiveness in many-objective regimes ($m \ge 5$) where traditional hypervolume-based methods are computationally intractable. Our implementation is built on BoTorch~\citep{balandat2020botorch} and is available at \url{https://github.com/parameters/qSTCH-Set}.

\subsection{Experimental Setup}

We compare the following methods on DTLZ2 problems with $m \in \{5, 8, 10\}$ objectives. All experiments use H100 GPUs on the Digital Research Alliance of Canada (Nibi cluster).

\paragraph{Methods.}
\begin{itemize}
    \item \textbf{qSTCH-Set} (ours): Set-based smooth Tchebycheff acquisition with $q = K = m$, $\mu = 0.1$, fixed uniform outer weights $\boldsymbol{\lambda} = \mathbf{1}/m$, and $N = 256$ MC samples.
    \item \textbf{STCH-NParEGO}: Single-point smooth scalarization ($q = 1$) with random weights.
    \item \textbf{qNParEGO}~\citep{daulton2020qnehvi}: Standard batch ParEGO with random Chebyshev scalarization ($q = 1$).
    \item \textbf{Random}: Uniform random search ($q=1$).
\end{itemize}

\paragraph{Protocol.} For DTLZ2 ($d=m+4$), we use $5$ independent seeds for $m=5$ and $m=8$, and $3$ seeds for $m=10$. We initialize with $2(d+1)$ Sobol points. The evaluation budget is 20 iterations for all configurations. Note that qSTCH-Set evaluates $K{=}m$ points per iteration, while baselines evaluate 1. This design choice reflects the method's purpose: finding a coordinated set of solutions.

\subsection{Main Results: DTLZ2 Scaling}

Figure~\ref{fig:convergence_m5} shows the convergence curves at $m{=}5$, and Figure~\ref{fig:convergence_m8} at $m{=}8$. Table~\ref{tab:main} presents the final hypervolume (HV) achieved by each method across different numbers of objectives.

\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{figures/convergence_m5.pdf}
\caption{Convergence on DTLZ2 with $m{=}5$ objectives, $K{=}5$. qSTCH-Set (blue) converges faster and reaches higher final HV than all baselines, with notably tighter variance than qNParEGO (5 seeds). Error bands show $\pm 1$ standard deviation.}
\label{fig:convergence_m5}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{figures/convergence_m8.pdf}
\caption{Convergence on DTLZ2 with $m{=}8$ objectives, $K{=}8$. qSTCH-Set dominates throughout, reaching HV $\sim 24$ while qNParEGO plateaus near $\sim 22$ (3 seeds). The advantage of coordinated set-based acquisition becomes more pronounced at higher $m$.}
\label{fig:convergence_m8}
\end{figure}

\begin{table}[t]
\caption{Main Results on DTLZ2: Final hypervolume (mean $\pm$ std). qSTCH-Set uses $K{=}m$; baselines are single-point. Best method per column is \textbf{bolded}. qSTCH-Set's advantage grows with~$m$, achieving a 6.5\% lead over qNParEGO at $m{=}10$.}
\label{tab:main}
\centering
\begin{tabular}{lccc}
\toprule
Method & $m=5$ ($K{=}5$) & $m=8$ ($K{=}8$) & $m=10$ ($K{=}10$) \\
\midrule
\textbf{qSTCH-Set (ours)} & $6.22 \pm 0.50$ & $20.22 \pm 1.90$ & $\mathbf{46.95 \pm 1.31}$ \\
qNParEGO & $\mathbf{6.44 \pm 0.16}$ & $\mathbf{20.89 \pm 0.83}$ & $44.10 \pm 0.99$ \\
STCH-NParEGO & --- & $16.63 \pm 0.23$ & $38.39 \pm 0.72$ \\
Random & $5.37 \pm 0.14$ & $17.63 \pm 0.29$ & $40.44 \pm 0.33^{\ddagger}$ \\
\bottomrule
\end{tabular}
\vspace{2pt}
{\footnotesize $\ddagger$ Random at $m{=}10$: 4 of 5 seeds completed.\\
qSTCH-Set at $m{=}8$ uses $K{=}8$ (5 seeds); baselines are single-point ($K{=}1$) with 5 seeds each.\\
STCH-NParEGO and Random at $m{=}8$/$m{=}10$ use the default $K{=}5$ experiment (5 seeds).}
\end{table}

\begin{figure}[t]
\centering
\includegraphics[width=0.7\linewidth]{figures/convergence_m10.pdf}
\caption{Convergence on DTLZ2 with $m{=}10$ objectives, $K{=}10$ (3 seeds). qSTCH-Set outperforms qNParEGO by 6.5\% ($46.95 \pm 1.31$ vs $44.10 \pm 0.99$), with the gap emerging after $\sim$5 iterations.}
\label{fig:convergence_m10}
\end{figure}

\textbf{Performance at $m=5$.} With $K{=}m{=}5$, qSTCH-Set achieves a mean HV of $6.22 \pm 0.50$, comparable to qNParEGO ($6.44 \pm 0.16$). At this modest objective count, random scalarization weights still cover the Pareto front adequately, and qNParEGO's lower variance reflects the maturity of its single-point greedy strategy. However, the $K$-ablation study (Table~\ref{tab:ablation_k}) reveals that increasing $K$ beyond $m$ can improve qSTCH-Set's consistency.

\textbf{Scaling to $m=8$.} With $K{=}m{=}8$, qSTCH-Set achieves HV $20.22 \pm 1.90$, approaching qNParEGO ($20.89 \pm 0.83$). Crucially, with the default $K{=}5 < m{=}8$, qSTCH-Set only reaches $19.26 \pm 1.49$---setting $K{=}m$ closes this gap by 5\%, confirming the importance of the design rule. STCH-NParEGO ($16.63 \pm 0.23$), a single-point smooth Tchebycheff variant, performs significantly worse than both, highlighting that set-based coordination---not just smooth scalarization---is the key advantage.

\textbf{Scaling to $m=10$.} The advantage of set-based acquisition becomes clear at $m{=}10$. With $K{=}m{=}10$, qSTCH-Set achieves HV $\mathbf{46.95 \pm 1.31}$, outperforming qNParEGO ($44.10 \pm 0.99$) by 6.5\%. STCH-NParEGO ($38.39 \pm 0.72$) and Random ($40.44 \pm 0.33$) fall far behind---notably, random search outperforms single-point STCH at $m{=}10$, underscoring that uncoordinated scalarization degrades rapidly with~$m$. In this high-dimensional objective space, random scalarization weights concentrate in the interior of the simplex and fail to cover extremal trade-off directions. qSTCH-Set, by assigning one candidate to each objective ($K{=}m$), ensures systematic expansion along all axes simultaneously.

\subsection{Ablation: Batch Size $K$}

To understand the importance of the design rule $K=m$, we compare performance with different batch sizes (Table~\ref{tab:ablation_k}, Figure~\ref{fig:k_ablation}).

\begin{figure}[t]
\centering
\includegraphics[width=0.75\linewidth]{figures/k_ablation_m5.pdf}
\caption{$K$-ablation on DTLZ2, $m{=}5$ (3 seeds). Increasing $K$ from 3 to 10 improves both mean HV and reduces variance. qNParEGO baseline shown for reference.}
\label{fig:k_ablation}
\end{figure}

\begin{table}[h]
\caption{$K$-Ablation on DTLZ2 ($m=5$): Impact of set size $K$ on final hypervolume (3 seeds). Larger $K$ improves both mean HV and reduces variance, with $K{=}10$ achieving the best result.}
\label{tab:ablation_k}
\centering
\begin{tabular}{lcc}
\toprule
Configuration & Final HV & Time/iter \\
\midrule
qSTCH-Set ($K=3 < m$) & $5.76 \pm 0.61$ & $1.4$s \\
qSTCH-Set ($K=m=5$) & $5.66 \pm 0.52$ & $2.4$s \\
qSTCH-Set ($K=10 > m$) & $\mathbf{6.24 \pm 0.36}$ & $6.1$s \\
\bottomrule
\end{tabular}
\end{table}

The ablation reveals that $K > m$ can further improve performance, suggesting the $K{=}m$ rule is a conservative lower bound. With $K{=}10$ at $m{=}5$, the mean HV increases to $6.24$ with notably reduced variance ($0.36$ vs $0.61$ for $K{=}3$), at the cost of higher per-iteration time. The cross-dimensional evidence is compelling: with $K{=}m$, qSTCH-Set approaches qNParEGO at $m{=}8$ ($20.22$ vs $20.89$) and decisively wins at $m{=}10$ ($46.95$ vs $44.10$), whereas $K < m$ consistently underperforms.

\subsection{Computational Cost}

We analyze the wall-clock time per iteration on an NVIDIA H100 GPU:

\begin{itemize}
    \item \textbf{$m=5$}: qSTCH-Set with $K{=}5$ averages $\sim 2.9$s/iter vs qNParEGO at $\sim 3.8$s/iter. The set-based acquisition is actually \emph{faster} per iteration due to joint optimization efficiency.
    \item \textbf{$m=8$}: With $K{=}8$, qSTCH-Set averages $\sim 9.6$s/iter, compared to $\sim 7.0$s/iter for qNParEGO. The cost increases modestly with $K$ and $m$.
    \item \textbf{$m=10$}: With $K{=}10$, qSTCH-Set averages $\sim 10.1$s/iter vs qNParEGO at $\sim 3.1$s/iter. While the per-iteration cost is $\sim 3\times$ higher, each iteration evaluates $K{=}10$ points jointly, amortizing to $\sim 1$s per candidate evaluation---comparable to qNParEGO's single-point cost. For expensive black-box functions (e.g., wet-lab experiments costing hours), this overhead is negligible.
\end{itemize}

\subsection{Validation on Bi-Objective Problems}

On ZDT2 ($m=2$), STCH-NParEGO achieves HV $107.2 \pm 4.1$, slightly outperforming vanilla qNParEGO ($106.0 \pm 4.9$), confirming that the smooth approximation is effective even in the single-point regime. However, qEHVI remains the gold standard for $m=2$ ($111.1 \pm 2.2$), supporting our positioning of qSTCH-Set for many-objective problems where qEHVI is inapplicable.

%=============================================================================
\section{Related Work}
\label{sec:related}
%=============================================================================

\paragraph{Hypervolume-based MOBO.}
Expected hypervolume improvement (EHVI) and its Monte Carlo extensions qEHVI and qNEHVI~\citep{daulton2020qnehvi,daulton2021qnehvi} define the state of the art for multi-objective BO with $m \le 4$ objectives, optimizing the expected improvement in the dominated hypervolume indicator.
However, exact hypervolume computation requires non-dominated partitioning, which is \#P-hard in~$m$~\citep{wang2024pohvi}.
Recent work on $\varepsilon$-PoHVI~\citep{wang2024pohvi} provides exact posterior hypervolume integration but remains limited to small~$m$.
For $m > 5$, these methods become computationally intractable.

\paragraph{Scalarization-based MOBO.}
ParEGO~\citep{knowles2006parego} pioneered random Chebyshev scalarization for MOBO, converting the multi-objective problem to a sequence of single-objective subproblems via randomly sampled weight vectors.
qNParEGO~\citep{daulton2020qnehvi} extended this to batches via sequential greedy selection, and Paria et al.~\citep{paria2019mobo} provided regret analysis for random scalarization.
MOBO-OSD~\citep{mobo_osd2025} selects batch points via orthogonal search directions.
All these methods rely on uncoordinated weight selection: each batch element optimizes an independently sampled weight with no mechanism to ensure collective Pareto front coverage.
For $m \gg 5$, random weights concentrate in the interior of the simplex, failing to sample the extremal directions needed for comprehensive front coverage.

\paragraph{Set-based and information-theoretic approaches.}
Set-based acquisition functions optimize the joint utility $U(\{x_1, \ldots, x_q\})$ of a batch rather than a sum of individual utilities.
qEHVI is the canonical example, jointly maximizing expected hypervolume improvement, but inherits the exponential scaling of hypervolume computation.
Information-theoretic methods---MESMO~\citep{belakaria2019mesmo}, PFES~\citep{suzuki2020pfes}, and JES~\citep{tu2022jes}---approximate entropy-based acquisitions but face similar degradation as Pareto front sampling costs grow with~$m$.
MORBO~\citep{daulton2022morbo} scales to high-dimensional \emph{input} spaces ($d > 100$) via local trust regions but addresses input dimensionality rather than objective dimensionality, and was primarily evaluated with $m \le 4$ objectives.

\paragraph{Smooth Tchebycheff scalarization.}
Lin et al.~\citep{lin2024smooth} introduced the smooth Tchebycheff (STCH) scalarization, replacing the non-smooth $\max$ in classical Chebyshev with a log-sum-exp approximation that is everywhere differentiable, has Lipschitz gradients, and preserves (weak) Pareto optimality.
They proved $O(1/\epsilon)$ convergence for gradient-based multi-objective optimization.
Lin et al.~\citep{lin2025few} extended this to STCH-Set, a ``few-for-many'' formulation where $K$ solutions are jointly optimized to cover~$m$ objectives via a nested smooth minimax, scaling as $O(Km)$ and demonstrating results with up to $m{=}1{,}024$ objectives and $K{=}20$ solutions.
However, both methods require cheap, differentiable objectives.
Pires \& Coelho~\citep{pires2025stch} brought single-point STCH into composite Bayesian optimization~\citep{astudillo2019composite}, achieving smooth scalarization in the surrogate-driven loop but without set-based coordination.
Our qSTCH-Set completes this picture: it combines set-based STCH scalarization with Monte Carlo GP posterior sampling, operating at $O(Km)$ cost in the sample-efficient regime where objectives are expensive black-box functions.

\paragraph{Many-objective evolutionary optimization.}
Evolutionary algorithms such as NSGA-III~\citep{deb2014nsga3} and MOEA/D~\citep{zhang2007moead} handle many objectives effectively but typically require thousands of function evaluations, making them unsuitable for expensive black-box problems where each evaluation may cost hours or days.

%=============================================================================
\section{Limitations}
\label{sec:limitations}
%=============================================================================

We identify six limitations of qSTCH-Set in its current form, ranging from experimental design to theoretical gaps.

\paragraph{1. Evaluation budget asymmetry.}
The $K{=}m$ design rule means qSTCH-Set evaluates $m$ points per iteration while baselines evaluate $q{=}1$. Over 20 iterations at $m{=}10$, qSTCH-Set consumes $200$ function evaluations versus $20$ for qNParEGO. Although the method's purpose is to produce a \emph{coordinated set} of solutions---and the per-candidate acquisition cost amortizes to $\sim 1$s on H100---a controlled comparison with budget-matched baselines (e.g., running qNParEGO for $200$ iterations, or with batch $q{=}m$ via sequential greedy) would provide a cleaner empirical comparison. Until such experiments are conducted, the headline 6.5\% advantage at $m{=}10$ should be interpreted as a comparison of \emph{strategies} (coordinated vs.\ uncoordinated), not of equal-cost allocations.

\paragraph{2. $K < m$ performance degradation.}
The $K$-ablation (Table~\ref{tab:ablation_k}) and scaling experiments reveal that $K < m$ consistently underperforms: at $m{=}8$, qSTCH-Set with the default $K{=}5$ reaches only HV~$19.26 \pm 1.49$, while $K{=}m{=}8$ achieves $20.22 \pm 1.90$ (5\% improvement). The $K{=}m$ rule is thus necessary but expensive: for $m{=}50$ objectives (a realistic drug discovery scenario), it requires evaluating 50~candidates per iteration. Practitioners with strict per-iteration budgets will need to trade off Pareto front coverage against cost, and no principled method for choosing $K < m$ exists beyond the empirical observation that larger $K$ is better.

\paragraph{3. Benchmark scope.}
All scaling experiments use DTLZ2, which has a known convex Pareto front (the positive orthant of a unit hypersphere). Convex fronts are favorable for scalarization methods because every Pareto-optimal point can be found by some weight vector $\boldsymbol{\lambda}$. On problems with non-convex or disconnected Pareto fronts (e.g., DTLZ7, WFG4), scalarization methods may miss concave regions entirely. Extending to such benchmarks---and to real-world problems where Pareto front geometry is unknown a priori---is necessary to validate the generality of qSTCH-Set.

\paragraph{4. Theory gap: $K > 1$ consistency is conjectured.}
Conjecture~\ref{conj:consistency} states that qSTCH-Set converges to the true Pareto front as observations grow, with an $\varepsilon_t$-optimality gap of $\mu_t\log(mK) + O(\beta_t^{1/2}\bar{\sigma}_t) \to 0$. For $K{=}1$, this follows from composite BO consistency~\citep{astudillo2019composite}. For $K > 1$, the set-valued optimization introduces permutation symmetries and joint-input dependencies that break the existing proof framework. A rigorous proof likely requires set-valued epi-convergence arguments, which we leave as the primary open theoretical problem.

\paragraph{5. Acquisition optimization is non-convex.}
The qSTCH-Set acquisition landscape over $\Xset \in \X^K$ has dimension $K \cdot d$ (e.g., $10 \times 14 = 140$ at $m{=}10$, $d{=}14$). L-BFGS-B with 20 random restarts provides no global optimality guarantee for this non-convex problem. While this limitation is shared by all BO methods that use gradient-based acquisition optimization, the higher dimensionality of the joint candidate space ($Kd$ vs.\ $d$ for single-point methods) may exacerbate the issue. Evolutionary or hybrid acquisition optimizers could mitigate this.

\paragraph{6. Statistical power.}
The $m{=}10$ results for the $K{=}m{=}10$ comparison are based on 3~seeds. While the effect size is large (6.5\%, with non-overlapping $\pm 1\sigma$ intervals), full statistical validation with $\ge 10$ seeds is needed for publication-quality claims. A separate 5-seed run at $m{=}10$ with default $K$ confirms the ordering (qSTCH-Set $45.45 \pm 1.83$ vs qNParEGO $45.59 \pm 1.45$), but the $K{=}m$ advantage is only visible with $K{=}10$.

%=============================================================================
\section{Conclusion}
\label{sec:conclusion}
%=============================================================================

We introduced qSTCH-Set, a Monte Carlo acquisition function that brings set-based smooth Tchebycheff scalarization from gradient-based many-objective optimization into the sample-efficient Bayesian optimization setting. By applying the STCH-Set smooth minimax formulation~\citep{lin2025few} to GP posterior samples, qSTCH-Set jointly optimizes $K$ candidates to cover $m$ objectives at $O(Km)$ per-evaluation cost, with Pareto optimality guarantees that transfer from the STCH-Set framework to the surrogate (Proposition~\ref{prop:pareto-transfer}) and a smoothing gap bounded by $\mu\log(mK)$ (Proposition~\ref{prop:pareto-transfer}(b)).

The central empirical finding is the $K{=}m$ design rule: setting the batch size equal to the number of objectives, so that the smooth minimum operator assigns one candidate to each objective direction. On DTLZ2, this rule proves decisive---at $m{=}10$, qSTCH-Set achieves hypervolume $46.95 \pm 1.31$, outperforming qNParEGO ($44.10 \pm 0.99$) by 6.5\%; at $m{=}8$, setting $K{=}m{=}8$ closes the gap with qNParEGO from $19.26$ to $20.22$ (vs.\ $20.89$); and a $K$-ablation at $m{=}5$ confirms that increasing $K$ improves both mean HV and reduces seed-to-seed variance ($K{=}10$: $6.24 \pm 0.36$ vs.\ $K{=}3$: $5.76 \pm 0.61$). The advantage grows with $m$, precisely where random weight vectors concentrate in the simplex interior and fail to cover extremal trade-off directions.

Several directions are ripe for future work. \emph{Proving $K > 1$ consistency} (Conjecture~\ref{conj:consistency}) is the primary theoretical challenge, likely requiring set-valued epi-convergence arguments. \emph{Adaptive $K$ scheduling}---starting with $K < m$ when the budget is tight and increasing $K$ as the GP sharpens---could make qSTCH-Set practical for $m = 50$+ objectives without $m$-fold cost from the first iteration. \emph{$\mu$-annealing} ($\mu_t = c / \log(t+1)$) is theoretically motivated by Corollary~\ref{cor:annealing} and could eliminate the smoothing residual without manual tuning. Finally, the motivating application---\emph{drug discovery} with $m = 20$--$50$ ADMET endpoints and $K = 3$--$5$ lead candidates---represents the ultimate test: a regime where qEHVI is intractable, random scalarization is inadequate, and coordinated set-based acquisition may provide the first viable path to many-objective sample-efficient optimization.

%=============================================================================
\section*{Acknowledgments}
%=============================================================================
Compute resources were provided by the Digital Research Alliance of Canada (Nibi cluster). R.A.V.-H.\ acknowledges support from the Natural Sciences and Engineering Research Council of Canada (NSERC) and McMaster University.

\bibliographystyle{plainnat}
\bibliography{references}

%=============================================================================
% APPENDIX (external file)
%=============================================================================
\input{appendix}

\end{document}
