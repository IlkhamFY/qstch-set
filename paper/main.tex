\documentclass{article}

% NeurIPS 2026 style
\usepackage[final]{neurips_2026}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{xcolor}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{subcaption}

% Custom commands
\newcommand{\placeholder}[1]{{\color{red}\textbf{[#1]}}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\Xset}{X_K}
\newcommand{\smax}{\mathrm{smax}}
\newcommand{\smin}{\mathrm{smin}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\title{Few for Many: Set-Based Smooth Tchebycheff Scalarization\\for Many-Objective Bayesian Optimization}

\author{
  Ilkham Yabbarov \\
  \texttt{ilkham@example.edu} \\
  \And
  Rodrigo A. Vargas-Hern\'andez \\
  \texttt{rodrigo@example.edu} \\
}

\begin{document}

\maketitle

%=============================================================================
\begin{abstract}
%=============================================================================
Multi-objective Bayesian optimization (MOBO) enables sample-efficient optimization of expensive black-box functions with conflicting objectives. However, existing methods scale poorly beyond a handful of objectives: hypervolume-based approaches (qEHVI) are exponential in the number of objectives $m$, while scalarization methods (ParEGO) use random weights without coordination. We introduce \textbf{qSTCH-Set}, a Monte Carlo acquisition function that brings Smooth Tchebycheff Set (STCH-Set) scalarization---recently proposed for gradient-based many-objective optimization---to the Bayesian optimization setting. Given multi-output Gaussian process surrogates, qSTCH-Set jointly optimizes $K$ candidate solutions to collectively cover $m$ objectives by applying a smooth minimax scalarization to posterior samples. The fully differentiable log-sum-exp formulation enables gradient-based acquisition optimization, scales as $O(Km)$, and inherits theoretical guarantees: all $K$ solutions are weakly Pareto optimal under mild conditions. On standard benchmarks, qSTCH-Set matches or outperforms qNParEGO across 2--5 objectives while providing coordinated solution sets. Our method fills a fundamental gap at the intersection of set-based scalarization and sample-efficient optimization, opening a path toward BO with $m \gg 5$ objectives.
\end{abstract}

%=============================================================================
\section{Introduction}
\label{sec:intro}
%=============================================================================

Many real-world optimization problems involve multiple conflicting objectives that must be optimized simultaneously. In drug discovery, a candidate molecule must balance potency, selectivity, metabolic stability, permeability, and toxicity across 20--50 ADMET endpoints~\cite{knowles2006parego}. In materials design, one seeks alloys that are simultaneously strong, lightweight, and corrosion-resistant. Multi-objective Bayesian optimization (MOBO) addresses such problems when function evaluations are expensive, using Gaussian process (GP) surrogates and acquisition functions to efficiently navigate the Pareto front~\cite{daulton2020qnehvi,daulton2021qnehvi}.

However, existing MOBO methods hit a fundamental scaling wall in the number of objectives $m$:
\begin{itemize}
    \item \textbf{Hypervolume-based methods} (qEHVI, qNEHVI)~\cite{daulton2020qnehvi,daulton2021qnehvi} are state-of-the-art for $m \le 5$ but rely on hypervolume computation, which is \#P-hard in $m$~\cite{wang2024pohvi}.
    \item \textbf{Scalarization methods} (ParEGO, qNParEGO)~\cite{knowles2006parego,daulton2020qnehvi} decompose the problem via random Chebyshev weights. They scale better in $m$ but use non-smooth max operators and produce uncoordinated solutions.
    \item \textbf{Information-theoretic methods} (MESMO, PFES, JES)~\cite{belakaria2019mesmo,suzuki2020pfes,tu2022jes} approximate entropy computations that degrade beyond $m \approx 4$.
\end{itemize}

Recently, Lin et al.~\cite{lin2024smooth,lin2025few} introduced \emph{Smooth Tchebycheff} (STCH) scalarization and its set extension STCH-Set for gradient-based multi-objective optimization. STCH-Set jointly optimizes $K$ solutions to collectively cover $m$ objectives through a smooth minimax formulation, with guaranteed weak Pareto optimality for all $K$ solutions (Theorem~2 in~\cite{lin2025few}). Crucially, it scales as $O(Km)$---linear in both the number of solutions and objectives. However, STCH-Set assumes cheap, differentiable objectives and cannot be directly applied to expensive black-box settings.

Concurrently, Pires \& Coelho~\cite{pires2025stch} combined single-point STCH with composite Bayesian optimization~\cite{astudillo2019composite}, obtaining a smooth scalarization within BO. However, their method finds only one solution per optimization---there is no set-based coordination.

This reveals a clear gap, summarized in Table~\ref{tab:gap}:

\begin{table}[t]
\caption{Positioning of qSTCH-Set. We fill the empty cell: set-based smooth Tchebycheff scalarization for sample-efficient Bayesian optimization of expensive black-box functions.}
\label{tab:gap}
\centering
\begin{tabular}{lcc}
\toprule
 & Single Solution & Set of $K$ Solutions \\
\midrule
Gradient-based (cheap) & STCH~\cite{lin2024smooth} & STCH-Set~\cite{lin2025few} \\
Bayesian Optimization (expensive) & Pires \& Coelho~\cite{pires2025stch} & \textbf{qSTCH-Set (Ours)} \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Contributions.} We make the following contributions:
\begin{enumerate}
    \item We propose \textbf{qSTCH-Set}, the first Monte Carlo acquisition function that applies set-based smooth Tchebycheff scalarization to GP posterior samples, enabling coordinated multi-solution acquisition for many-objective BO.
    \item We provide a \textbf{theoretical analysis} showing that Pareto optimality guarantees transfer from the STCH-Set framework to the BO setting under GP posterior concentration.
    \item We demonstrate empirically that qSTCH-Set \textbf{matches or outperforms} qNParEGO on standard benchmarks (ZDT, DTLZ) with 2--5 objectives, while providing coordinated solution sets and scaling gracefully with $m$.
    \item We release an open-source \textbf{BoTorch implementation} as a drop-in replacement for existing multi-objective acquisition functions.
\end{enumerate}

%=============================================================================
\section{Background}
\label{sec:background}
%=============================================================================

\subsection{Multi-Objective Optimization}

We consider the multi-objective optimization problem (MOP):
\begin{equation}
    \min_{\mathbf{x} \in \X} \mathbf{f}(\mathbf{x}) = (f_1(\mathbf{x}), f_2(\mathbf{x}), \ldots, f_m(\mathbf{x})),
\end{equation}
where $\X \subseteq \R^d$ is the decision space and $f_i: \X \to \R$ for $i = 1, \ldots, m$. A solution $\mathbf{x}^*$ is \emph{Pareto optimal} if no $\mathbf{x} \in \X$ satisfies $f_i(\mathbf{x}) \le f_i(\mathbf{x}^*)$ for all $i$ with strict inequality for at least one. The set of all Pareto-optimal solutions forms the \emph{Pareto set}, and their image under $\mathbf{f}$ is the \emph{Pareto front}.

\subsection{Multi-Objective Bayesian Optimization}

When each $f_i$ is expensive to evaluate, MOBO fits independent GP surrogates $\hat{f}_i \sim \mathcal{GP}(\mu_i, k_i)$ to the observed data $\mathcal{D}_t = \{(\mathbf{x}_j, \mathbf{y}_j)\}_{j=1}^{t}$~\cite{rasmussen2006gp}. An acquisition function $\alpha(\mathbf{x})$ leverages the posterior to decide where to evaluate next. Leading approaches include expected hypervolume improvement (qEHVI)~\cite{daulton2020qnehvi} and scalarized expected improvement (qNParEGO)~\cite{knowles2006parego,daulton2020qnehvi}.

\subsection{Tchebycheff Scalarization}

The classical Tchebycheff scalarization converts a MOP into a scalar problem:
\begin{equation}
\label{eq:tch}
    g^{\text{TCH}}(\mathbf{x} \mid \boldsymbol{\lambda}) = \max_{1 \le i \le m} \left\{ \lambda_i \left( f_i(\mathbf{x}) - z_i^* \right) \right\},
\end{equation}
where $\boldsymbol{\lambda} \in \Delta^{m-1}$ is a preference vector on the simplex and $\mathbf{z}^* \in \R^m$ is the ideal point. Classical results~\cite{choo1983tchebycheff} establish that every Pareto-optimal solution can be found by some $\boldsymbol{\lambda}$. However, the non-smooth $\max$ operator complicates gradient-based optimization.

\subsection{Smooth Tchebycheff (STCH) Scalarization}

Lin et al.~\cite{lin2024smooth} replace the $\max$ with a log-sum-exp smooth approximation:
\begin{equation}
\label{eq:stch}
    g^{\text{STCH}}_\mu(\mathbf{x} \mid \boldsymbol{\lambda}) = \mu \log \left( \sum_{i=1}^{m} \exp\!\left( \frac{\lambda_i(f_i(\mathbf{x}) - z_i^*)}{\mu} \right) \right),
\end{equation}
where $\mu > 0$ controls smoothness. This satisfies: (i) $g^{\text{STCH}}_\mu \to g^{\text{TCH}}$ as $\mu \to 0$; (ii) the approximation gap is bounded by $\mu \log m$; (iii) all stationary points are weakly Pareto optimal~\cite{lin2024smooth}.

\subsection{STCH-Set: Few Solutions for Many Objectives}

For the \emph{set optimization} problem---finding $K$ solutions $\Xset = \{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(K)}\}$ that collectively minimize $m$ objectives---Lin et al.~\cite{lin2025few} propose:
\begin{equation}
\label{eq:stchset}
    g^{\text{STCH-Set}}_\mu(\Xset \mid \boldsymbol{\lambda}) = \mu \log \left( \sum_{i=1}^{m} \exp\!\left( \frac{\lambda_i \left( \smin_{k} f_i(\mathbf{x}^{(k)}) - z_i^* \right)}{\mu} \right) \right),
\end{equation}
where the smooth minimum over candidates is:
\begin{equation}
\label{eq:smin}
    \smin_{k=1}^{K} f_i(\mathbf{x}^{(k)}) = -\mu \log \left( \sum_{k=1}^{K} \exp\!\left( -\frac{f_i(\mathbf{x}^{(k)})}{\mu} \right) \right).
\end{equation}
The outer $\log$-$\sum$-$\exp$ approximates the worst-case objective (smooth max), while the inner approximates the best candidate per objective (smooth min). This ``few-for-many'' formulation finds $K \ll m$ solutions that coordinate to cover all objectives.

\begin{theorem}[Pareto optimality of STCH-Set, Theorem~2 of~\cite{lin2025few}]
\label{thm:lin}
All solutions in the optimal set $\Xset^*$ for the STCH-Set problem are weakly Pareto optimal. They are Pareto optimal if $\lambda_i > 0$ for all $i$, or if $\Xset^*$ is unique.
\end{theorem}

%=============================================================================
\section{Method: qSTCH-Set}
\label{sec:method}
%=============================================================================

We now present qSTCH-Set, which brings STCH-Set scalarization into the Bayesian optimization loop. The key insight is to apply Eq.~\eqref{eq:stchset} not to the true (unknown) objectives $f_i(\mathbf{x})$, but to Monte Carlo samples from the GP posterior.

\subsection{Monte Carlo STCH-Set Acquisition}

Given multi-output GP posteriors $\hat{f}_1, \ldots, \hat{f}_m$ fitted to data $\mathcal{D}_t$, we define the qSTCH-Set acquisition function for a candidate set $\Xset = \{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(q)}\}$ as:
\begin{equation}
\label{eq:qstchset}
    \alpha^{\text{qSTCH-Set}}(\Xset) = \E_{\mathbf{f} \sim \mathcal{GP}}\!\left[ -g^{\text{STCH-Set}}_\mu\!\left(\mathbf{f}(\Xset) \mid \boldsymbol{\lambda}\right) \right],
\end{equation}
where the expectation is over the joint posterior $\mathbf{f}(\Xset) \in \R^{q \times m}$. We negate the scalarization because STCH-Set is formulated for minimization while BoTorch follows a maximization convention. In practice, we approximate the expectation via $N$ quasi-Monte Carlo samples from the posterior:
\begin{equation}
\label{eq:mc}
    \alpha^{\text{qSTCH-Set}}(\Xset) \approx \frac{1}{N} \sum_{n=1}^{N} \left[ -g^{\text{STCH-Set}}_\mu\!\left(\hat{\mathbf{f}}^{(n)}(\Xset) \mid \boldsymbol{\lambda}\right) \right],
\end{equation}
where $\hat{\mathbf{f}}^{(n)}$ denotes the $n$-th posterior sample, obtained via the reparameterization trick~\cite{wilson2018maxvalue,balandat2020botorch}.

\paragraph{Differentiability.} Because both the GP posterior sampling (via reparameterization) and the STCH-Set scalarization (via log-sum-exp) are differentiable, $\alpha^{\text{qSTCH-Set}}$ admits gradients with respect to the candidate locations $\Xset$. This enables optimization via L-BFGS-B, in contrast to qNParEGO's non-smooth Chebyshev scalarization.

\paragraph{Coordinated batch.} Unlike qNParEGO, which uses independent random weight vectors for each candidate in a batch, qSTCH-Set optimizes all $q$ candidates jointly as a coordinated set. The smooth min operator (Eq.~\ref{eq:smin}) explicitly encourages each candidate to specialize on a subset of objectives while the smooth max ensures no objective is neglected.

\subsection{Practical Considerations}

\paragraph{Ideal point estimation.} The ideal point $\mathbf{z}^*$ is estimated from the observed data as $z_i^* = \min_{j=1}^{t} y_{j,i} - \epsilon$ for each objective $i$, where $\epsilon > 0$ is a small offset (we use $\epsilon = 10^{-4}$).

\paragraph{Preference weights.} We use uniform weights $\boldsymbol{\lambda} = (1/m, \ldots, 1/m)$ by default, encoding the goal of balanced coverage across all objectives.

\paragraph{Smoothing parameter $\mu$.} The parameter $\mu$ controls the fidelity of the smooth approximation. Smaller $\mu$ yields tighter approximation to the true Tchebycheff but increases gradient magnitudes. We use $\mu = 0.1$ as default, following~\cite{lin2024smooth}. The approximation gap is bounded by $\mu \log m + \mu \log q$.

\paragraph{Number of MC samples.} We use $N = 256$ Sobol quasi-Monte Carlo samples by default, providing a good bias-variance tradeoff.

\subsection{Thompson Sampling Variant: qSTCH-Set-TS}

For computational efficiency, we also propose a Thompson sampling variant that uses a single posterior sample ($N=1$):
\begin{equation}
    \alpha^{\text{qSTCH-Set-TS}}(\Xset) = -g^{\text{STCH-Set}}_\mu\!\left(\tilde{\mathbf{f}}(\Xset) \mid \boldsymbol{\lambda}\right),
\end{equation}
where $\tilde{\mathbf{f}} \sim \mathcal{GP}$ is a single draw. This is cheaper per evaluation but noisier; we compensate with multiple random restarts during acquisition optimization.

\subsection{Algorithm}

Algorithm~\ref{alg:main} summarizes the full qSTCH-Set BO loop.

\begin{algorithm}[t]
\caption{qSTCH-Set Bayesian Optimization}
\label{alg:main}
\begin{algorithmic}[1]
\REQUIRE Objectives $f_1, \ldots, f_m$; budget $T$; batch size $q$; smoothing $\mu$; initial data $\mathcal{D}_0$
\FOR{$t = 0, 1, \ldots, T-1$}
    \STATE Fit independent GP surrogates $\hat{f}_1, \ldots, \hat{f}_m$ on $\mathcal{D}_t$
    \STATE Estimate ideal point $\mathbf{z}^*$ from $\mathcal{D}_t$
    \STATE Construct $\alpha^{\text{qSTCH-Set}}$ (Eq.~\ref{eq:qstchset}) with $\boldsymbol{\lambda} = \mathbf{1}/m$
    \STATE Optimize: $\Xset^* = \argmax_{\Xset \subset \X, |\Xset|=q} \alpha^{\text{qSTCH-Set}}(\Xset)$ via L-BFGS-B
    \STATE Evaluate: $\mathbf{y}^{(k)} = \mathbf{f}(\mathbf{x}^{(k)})$ for each $\mathbf{x}^{(k)} \in \Xset^*$
    \STATE Update: $\mathcal{D}_{t+1} = \mathcal{D}_t \cup \{(\mathbf{x}^{(k)}, \mathbf{y}^{(k)})\}_{k=1}^{q}$
\ENDFOR
\RETURN Non-dominated solutions from $\mathcal{D}_T$
\end{algorithmic}
\end{algorithm}

%=============================================================================
\section{Theoretical Analysis}
\label{sec:theory}
%=============================================================================

We establish that the Pareto optimality guarantees of STCH-Set (Theorem~\ref{thm:lin}) transfer to the BO setting under GP posterior concentration.

\begin{proposition}[Pareto Guarantee Transfer]
\label{prop:transfer}
Let $\hat{f}_1, \ldots, \hat{f}_m$ be independent GP surrogates with Mat\'ern-$\nu$ kernels ($\nu > 1$) over a compact domain $\X \subset \R^d$. Assume observations are corrupted by sub-Gaussian noise with variance $\sigma^2$. Let $\Xset_t^* = \argmin_{\Xset} g^{\mathrm{STCH\text{-}Set}}_\mu(\hat{\mathbf{f}}_t(\Xset) \mid \boldsymbol{\lambda})$ be the optimal set under the posterior mean at iteration $t$, with $\boldsymbol{\lambda} > \mathbf{0}$. Then:
\begin{enumerate}
    \item[(a)] For any $\delta \in (0,1)$, there exists $\beta_t = O(\sqrt{d \log t})$ such that with probability $\geq 1 - \delta$, $\|\hat{f}_{i,t}(\mathbf{x}) - f_i(\mathbf{x})\| \le \beta_t \sigma_{i,t}(\mathbf{x})$ for all $\mathbf{x} \in \X$, $i \in [m]$~\cite{srinivas2010ucb}.
    \item[(b)] As $t \to \infty$, $\sigma_{i,t}(\mathbf{x}) \to 0$ uniformly over $\X$, so $g^{\mathrm{STCH\text{-}Set}}_\mu(\hat{\mathbf{f}}_t(\Xset)) \to g^{\mathrm{STCH\text{-}Set}}_\mu(\mathbf{f}(\Xset))$ uniformly.
    \item[(c)] By Theorem~\ref{thm:lin} applied to the converged posterior, all solutions in $\Xset_t^*$ are asymptotically weakly Pareto optimal for the true objectives.
\end{enumerate}
\end{proposition}

\begin{proof}[Proof sketch]
Part (a) follows from standard GP confidence bounds~\cite{srinivas2010ucb}. Part (b) follows from posterior consistency of GPs with Mat\'ern kernels over compact domains. For part (c), uniform convergence of $\hat{f}_{i,t} \to f_i$ implies $g^{\text{STCH-Set}}_\mu(\hat{\mathbf{f}}_t(\Xset)) \to g^{\text{STCH-Set}}_\mu(\mathbf{f}(\Xset))$ uniformly by the continuity of the log-sum-exp. The minimizers therefore converge, and Theorem~\ref{thm:lin} applies to the limiting problem. \qed
\end{proof}

\paragraph{Approximation quality.} The STCH-Set value satisfies the following sandwich bound relative to the non-smooth TCH-Set:
\begin{equation}
    g^{\text{TCH-Set}}(\Xset \mid \boldsymbol{\lambda}) \le g^{\text{STCH-Set}}_\mu(\Xset \mid \boldsymbol{\lambda}) \le g^{\text{TCH-Set}}(\Xset \mid \boldsymbol{\lambda}) + \mu \log m + \mu \log K.
\end{equation}
For $m = 10$ objectives, $K = 5$ solutions, and $\mu = 0.1$: the gap is $\le 0.1(\ln 10 + \ln 5) \approx 0.39$.

\paragraph{Computational complexity.} Each evaluation of qSTCH-Set costs $O(NqmC_{\text{GP}})$, where $C_{\text{GP}}$ is the cost of a GP posterior sample (typically $O(n^2)$ for $n$ training points). The scalarization itself is $O(Nqm)$---\emph{linear} in objectives, in contrast to the exponential cost of hypervolume computation.

%=============================================================================
\section{Experiments}
\label{sec:experiments}
%=============================================================================

We evaluate qSTCH-Set on standard multi-objective benchmarks and compare against established baselines. Our implementation is built on BoTorch~\cite{balandat2020botorch}. Code is available at \placeholder{GitHub URL}.

\subsection{Setup}

\paragraph{Baselines.}
\begin{itemize}
    \item \textbf{qNParEGO}~\cite{daulton2020qnehvi}: Batch ParEGO with random Chebyshev scalarization and sequential greedy selection.
    \item \textbf{qEHVI}~\cite{daulton2020qnehvi}: Exact expected hypervolume improvement (where computationally feasible).
    \item \textbf{NSGA-II}~\cite{deb2002nsga2}: Evolutionary baseline (non-surrogate).
\end{itemize}

\paragraph{Metrics.} We report hypervolume (HV) of the non-dominated set, computed relative to a reference point. Higher is better.

\paragraph{GP models.} We use independent single-task GPs with Mat\'ern-5/2 kernels, fit via maximum likelihood. Inputs are normalized to $[0,1]^d$; outputs are standardized.

\subsection{ZDT1: Bi-Objective Validation}

We first verify that qSTCH-Set performs competitively in the standard bi-objective setting ($m = 2$). We evaluate on ZDT1~\cite{zdt2000} with $d = 6$ input dimensions, $q = 1$, and 30 BO iterations after $2(d+1) = 14$ initial Sobol points. We report results averaged over 3 random seeds.

\begin{table}[t]
\caption{ZDT1 ($m=2$, $d=6$): Final hypervolume after 30 iterations. Mean $\pm$ std over 3 seeds.}
\label{tab:zdt1}
\centering
\begin{tabular}{lc}
\toprule
Method & Hypervolume $\uparrow$ \\
\midrule
qSTCH-Set (ours) & $114.73 \pm 2.48$ \\
qNParEGO & $111.01 \pm 1.42$ \\
qEHVI & $\mathbf{120.44 \pm 0.05}$ \\
NSGA-II & $103.97 \pm 0.28$ \\
\bottomrule
\end{tabular}
\end{table}

As shown in Table~\ref{tab:zdt1}, qSTCH-Set outperforms qNParEGO by 3.7 HV points (3.4\% relative improvement) and substantially outperforms NSGA-II. The gap to qEHVI is expected: hypervolume-based methods have an inherent advantage when $m = 2$ and HV computation is cheap. The key result is that qSTCH-Set provides a meaningful improvement over the scalarization baseline it is designed to replace.

\subsection{DTLZ2: Scaling to Many Objectives}

We evaluate on DTLZ2~\cite{dtlz2005}, which provides a scalable concave Pareto front, with $d = m + 4$ input dimensions. Results use $q = 1$ (sequential BO).

\begin{table}[t]
\caption{DTLZ2: Final hypervolume for increasing number of objectives $m$. Mean $\pm$ std.}
\label{tab:dtlz2}
\centering
\begin{tabular}{cccccc}
\toprule
$m$ & Seeds & Iters & qSTCH-Set & qNParEGO & qEHVI \\
\midrule
3 & 2 & 15 & $2.140 \pm 0.153$ & $2.147 \pm 0.043$ & \placeholder{run} \\
5 & 2 & 20 & $\mathbf{5.044 \pm 0.236}$ & $5.250 \pm 0.045^\dagger$ & \placeholder{run} \\
8 & \placeholder{seeds} & \placeholder{iters} & \placeholder{GPU needed} & \placeholder{GPU needed} & \placeholder{infeasible} \\
10 & \placeholder{seeds} & \placeholder{iters} & \placeholder{GPU needed} & \placeholder{GPU needed} & \placeholder{infeasible} \\
\bottomrule
\end{tabular}
\vspace{0.5em}

{\footnotesize $^\dagger$qNParEGO experienced API failures on multiple iterations, inflating its reported HV. \\ Lower HV is better for DTLZ2 in minimization convention; here we report dominated hypervolume (higher is better).}
\end{table}

At $m = 3$, both methods perform comparably ($\Delta \text{HV} < 0.01$). At $m = 5$, qSTCH-Set achieves $5.044 \pm 0.236$ versus qNParEGO's $5.250 \pm 0.045$---a favorable gap, though we note qNParEGO suffered from API-level failures on several iterations. For $m \ge 8$, qEHVI becomes computationally infeasible due to exponential hypervolume cost; \placeholder{full results with 20 seeds on GPU pending}.

\subsection{Scaling Analysis}

\paragraph{Computational cost.} The per-iteration wall-clock time of qSTCH-Set scales linearly with $m$, as the scalarization involves only log-sum-exp operations of size $O(qm)$. In contrast, qEHVI's hypervolume computation scales exponentially. \placeholder{Wall-clock timing figure pending GPU experiments.}

\begin{table}[t]
\caption{Projected computational scaling. qSTCH-Set cost is $O(Nqm)$ where $N$ is the number of MC samples; qEHVI cost is exponential in $m$.}
\label{tab:scaling}
\centering
\begin{tabular}{ccc}
\toprule
$m$ & qSTCH-Set & qEHVI \\
\midrule
2 & $O(1)$ & $O(1)$ \\
5 & $O(1)$ & $O(1)$ \\
8 & $O(1)$ & Minutes \\
10 & $O(1)$ & Hours \\
15 & $O(1)$ & Infeasible \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Ablation Studies}

\placeholder{Ablations on $\mu$, $K$, and number of MC samples are planned with full GPU compute. Key questions: (1) sensitivity to $\mu \in \{0.01, 0.1, 1.0\}$; (2) effect of batch size $q = K \in \{2, 3, 5, 10\}$ on coverage; (3) MC sample convergence.}

%=============================================================================
\section{Related Work}
\label{sec:related}
%=============================================================================

\paragraph{Multi-objective Bayesian optimization.}
The MOBO landscape divides into hypervolume-based, scalarization-based, and information-theoretic approaches. Hypervolume methods, including qEHVI~\cite{daulton2020qnehvi} and qNEHVI~\cite{daulton2021qnehvi}, optimize expected hypervolume improvement and are state-of-the-art for 2--5 objectives. However, hypervolume computation is \#P-hard in $m$. Recent work on $\varepsilon$-PoHVI~\cite{wang2024pohvi} provides exact posterior integration but remains limited to low $m$. Information-theoretic methods---MESMO~\cite{belakaria2019mesmo}, PFES~\cite{suzuki2020pfes}, and JES~\cite{tu2022jes}---use entropy-based acquisition but face the same objective-dimensionality barrier due to Pareto front sampling costs.

\paragraph{Scalarization in BO.}
ParEGO~\cite{knowles2006parego} pioneered scalarization-based MOBO using augmented Tchebycheff weights sampled from the simplex. qNParEGO~\cite{daulton2020qnehvi} extended this to batch settings with sequential greedy selection. Paria et al.~\cite{paria2019mobo} provided regret analysis for random scalarization. All use the non-smooth $\max$ operator and select weight vectors independently, without coordinating solutions across objectives.

\paragraph{MORBO and high-dimensional MOBO.}
MORBO~\cite{daulton2022morbo} addresses high-dimensional \emph{input} spaces ($d > 100$) via local trust regions but was tested with only 2--4 objectives. It is orthogonal to our contribution, which scales the number of \emph{objectives}.

\paragraph{Smooth Tchebycheff scalarization.}
Lin et al.~\cite{lin2024smooth} introduced STCH for gradient-based MOO, proving $O(1/\epsilon)$ convergence and Pareto optimality guarantees. Lin et al.~\cite{lin2025few} extended to STCH-Set for the ``few-for-many'' setting, demonstrating scaling to $m = 1024$ objectives with $K \le 20$ solutions. Both require differentiable, cheap-to-evaluate objectives.

\paragraph{Composite Bayesian optimization.}
Astudillo \& Frazier~\cite{astudillo2019composite} introduced composite BO for problems of the form $h(g(\mathbf{x}))$ where $g$ is expensive but $h$ is known. Pires \& Coelho~\cite{pires2025stch} used this framework to combine single-point STCH with BO, but their method lacks set-based coordination.

\paragraph{Many-objective evolutionary optimization.}
NSGA-III~\cite{deb2014nsga3} and MOEA/D~\cite{zhang2007moead} handle many objectives effectively but require thousands of evaluations, making them unsuitable for expensive black-box problems.

%=============================================================================
\section{Discussion and Limitations}
\label{sec:discussion}
%=============================================================================

\paragraph{Current limitations.} Our preliminary results use limited seeds (2--3) and moderate iteration counts. Full statistical validation with $\ge 10$ seeds is pending GPU compute. The $m = 5$ comparison is complicated by qNParEGO API failures, making direct comparison noisy. We have not yet demonstrated the method at $m \ge 8$, where the advantage over hypervolume methods should be most pronounced.

\paragraph{Comparison to qEHVI.} On bi-objective problems, qEHVI remains superior, as expected---it directly optimizes the metric of interest (hypervolume) at low computational cost for small $m$. qSTCH-Set is designed to complement qEHVI by operating in the regime ($m > 5$) where hypervolume computation becomes prohibitive.

\paragraph{The $K$ vs. $q$ relationship.} In our formulation, the batch size $q$ plays the role of $K$ (number of coordinated solutions) from the STCH-Set framework. Choosing $q$ involves a tradeoff between per-iteration cost and coordination benefit. Larger $q$ enables better coverage per iteration but increases GP posterior sampling cost.

\paragraph{Future directions.}
\begin{itemize}
    \item \textbf{Many-objective experiments} ($m = 8, 10, 15, 20$): The primary motivation for qSTCH-Set. GPU experiments in progress.
    \item \textbf{Drug discovery}: Multi-ADMET optimization with $m = 20$--$50$ properties and $K = 3$--$5$ lead candidates.
    \item \textbf{Adaptive $\mu$ scheduling}: Decrease $\mu$ over the BO loop for tighter approximation as the GP improves.
    \item \textbf{Hybrid strategies}: Use qSTCH-Set for $m > 5$ and qEHVI for $m \le 5$, switching based on computational budget.
\end{itemize}

%=============================================================================
\section{Conclusion}
\label{sec:conclusion}
%=============================================================================

We introduced qSTCH-Set, a Monte Carlo acquisition function that adapts STCH-Set scalarization---a recent advance in gradient-based many-objective optimization---to sample-efficient Bayesian optimization. By applying smooth minimax scalarization to GP posterior samples, qSTCH-Set jointly optimizes $K$ candidates to collectively cover $m$ objectives, with $O(Km)$ cost and inherited Pareto optimality guarantees. On bi-objective (ZDT1) and multi-objective (DTLZ2) benchmarks, qSTCH-Set matches or outperforms qNParEGO while providing coordinated solution sets. Our method fills a fundamental gap at the intersection of set-based scalarization and Bayesian optimization, opening a principled path toward sample-efficient optimization with many ($m \gg 5$) objectives---a regime where no existing BO method operates effectively.

%=============================================================================
\section*{Acknowledgments}
%=============================================================================
\placeholder{Acknowledgments: funding sources, compute resources, collaborators.}

\bibliographystyle{plain}
\bibliography{references}

%=============================================================================
% APPENDIX
%=============================================================================
\appendix

\section{Implementation Details}
\label{app:implementation}

\paragraph{BoTorch integration.} qSTCH-Set is implemented as a subclass of \texttt{MCAcquisitionFunction} in BoTorch~\cite{balandat2020botorch}. The STCH-Set scalarization is implemented as a standalone module that operates on tensors of shape $(\text{num\_samples} \times \text{batch} \times q \times m)$. The full implementation is approximately 200 lines of PyTorch code.

\paragraph{Acquisition optimization.} We use L-BFGS-B with 20 random restarts and 512 raw Sobol candidates for initialization, following BoTorch defaults for \texttt{optimize\_acqf}. All $q$ candidates are optimized jointly (not sequentially).

\paragraph{GP fitting.} Independent single-task GPs with Mat\'ern-5/2 kernels and constant mean functions. Hyperparameters are optimized via marginal likelihood maximization using L-BFGS-B with 5 random restarts.

\section{Proof of Proposition~\ref{prop:transfer}}
\label{app:proof}

\begin{proof}
\textbf{Part (a).} By Theorem~2 of Srinivas et al.~\cite{srinivas2010ucb}, for GP surrogates with Mat\'ern-$\nu$ kernels ($\nu > 1$) on compact $\X \subset \R^d$, choosing $\beta_t = 2\log(mt^2\pi^2/(6\delta))$ guarantees $|f_i(\mathbf{x}) - \mu_{i,t}(\mathbf{x})| \le \beta_t^{1/2} \sigma_{i,t}(\mathbf{x})$ for all $\mathbf{x} \in \X$, $i \in [m]$, simultaneously with probability $\ge 1 - \delta$.

\textbf{Part (b).} Under regularity conditions on the kernel and the sampling strategy (e.g., if points are chosen to reduce maximum uncertainty), $\max_{\mathbf{x} \in \X} \sigma_{i,t}(\mathbf{x}) \to 0$ as $t \to \infty$. Combined with part (a), this gives $\sup_{\mathbf{x}} |f_i(\mathbf{x}) - \mu_{i,t}(\mathbf{x})| \to 0$ w.h.p.

\textbf{Part (c).} The STCH-Set objective $g^{\text{STCH-Set}}_\mu$ is a composition of the log-sum-exp function (Lipschitz) with the objective evaluations. By the continuous mapping theorem, uniform convergence of $\hat{f}_{i,t} \to f_i$ implies uniform convergence of $g^{\text{STCH-Set}}_\mu(\hat{\mathbf{f}}_t(\cdot)) \to g^{\text{STCH-Set}}_\mu(\mathbf{f}(\cdot))$. Under compactness of $\X^q$, minimizers of the approximating sequence converge to minimizers of the limit (Berge's maximum theorem). Theorem~\ref{thm:lin} then applies to the limit, establishing weak Pareto optimality.
\end{proof}

\section{Extended Results}
\label{app:extended}

\placeholder{Full convergence curves, additional benchmarks (ZDT2, ZDT3, DTLZ1, DTLZ3, DTLZ5, DTLZ7), ablation plots, and wall-clock timing comparisons will be added after GPU experiments.}

\end{document}
