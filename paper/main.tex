\documentclass{article}

% NeurIPS 2026 style
\usepackage[final]{neurips_2026}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{xcolor}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{amsthm}
\usepackage{thm-restate}

% Theorem environments
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{assumption}[theorem]{Assumption}

% Custom commands
\newcommand{\placeholder}[1]{{\color{red}\textbf{[#1]}}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\GP}{\mathcal{GP}}
\newcommand{\Xset}{X_K}
\newcommand{\smax}{\mathrm{smax}}
\newcommand{\smin}{\mathrm{smin}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\title{Set-Based Smooth Tchebycheff Scalarization\\for Many-Objective Bayesian Optimization}

\author{
  Ilkham Yabbarov \\
  Department of Chemistry \\
  McMaster University \\
  \texttt{yabbari@mcmaster.ca} \\
  \And
  Rodrigo A. Vargas-Hern\'andez \\
  Department of Chemistry \\
  McMaster University \\
  \texttt{vargashr@mcmaster.ca} \\
}

\begin{document}

\maketitle

%=============================================================================
\begin{abstract}
%=============================================================================
Multi-objective Bayesian optimization (MOBO) enables sample-efficient optimization of expensive black-box functions, but existing methods scale poorly beyond five objectives: hypervolume-based approaches incur exponential cost in $m$, while scalarization methods produce uncoordinated solutions via random weight vectors.
We introduce \textbf{qSTCH-Set}, a Monte Carlo acquisition function that applies smooth Tchebycheff set (STCH-Set) scalarization---recently proposed for gradient-based many-objective optimization---to Gaussian process posterior samples, jointly optimizing $K$ candidates to collectively cover $m$ objectives at $O(Km)$ cost.
We prove that the Pareto optimality guarantees of STCH-Set transfer to the Bayesian optimization setting asymptotically under GP posterior concentration, with an explicit approximation gap of $\mu\log(mK) + O(\beta_t^{1/2}\bar{\sigma}_t)$.
On DTLZ2 with $m{=}5$ objectives (5 seeds, 30 iterations), qSTCH-Set achieves a hypervolume of $6.646 \pm 0.066$, outperforming both qNParEGO ($6.429 \pm 0.254$) and single-point STCH ($6.117 \pm 0.156$), demonstrating that set-based coordination improves Pareto front coverage in the sample-efficient regime.
\end{abstract}

%=============================================================================
\section{Introduction}
\label{sec:intro}
%=============================================================================

Many engineering and scientific optimization problems involve multiple conflicting objectives. In drug discovery, a candidate molecule must simultaneously satisfy constraints on potency, selectivity, metabolic stability, permeability, and toxicity---often 20--50 ADMET endpoints~\citep{knowles2006parego}. In materials design, one seeks alloys balancing strength, weight, cost, and corrosion resistance. Multi-objective Bayesian optimization (MOBO) addresses such problems when function evaluations are expensive, using Gaussian process (GP) surrogates and acquisition functions to efficiently explore the Pareto front~\citep{daulton2020qnehvi,daulton2021qnehvi,balandat2020botorch}.

However, existing MOBO methods face a fundamental scaling barrier in the number of objectives $m$:

\begin{itemize}
    \item \textbf{Hypervolume-based methods} (qEHVI, qNEHVI)~\citep{daulton2020qnehvi,daulton2021qnehvi} are state-of-the-art for $m \le 4$ but rely on non-dominated partitioning, which is \#P-hard in $m$~\citep{wang2024pohvi}.
    \item \textbf{Scalarization methods} (ParEGO, qNParEGO)~\citep{knowles2006parego,daulton2020qnehvi} decompose the problem via random Chebyshev weights. They scale better in $m$ but use a non-smooth $\max$ operator and produce uncoordinated solutions---each batch element optimizes an independently sampled weight vector with no mechanism to ensure collective Pareto front coverage.
    \item \textbf{Information-theoretic methods} (MESMO, PFES, JES)~\citep{belakaria2019mesmo,suzuki2020pfes,tu2022jes} approximate entropy computations that degrade rapidly beyond $m \approx 4$.
\end{itemize}

Recently, two independent lines of work have made partial progress toward scalable multi-objective scalarization:

\textbf{(1) Smooth Tchebycheff (STCH) scalarization for gradient-based MOO.}
Lin et al.~\citep{lin2024smooth} introduced a log-sum-exp relaxation of the Tchebycheff scalarization that is everywhere differentiable, preserves Pareto optimality guarantees, and achieves $O(1/\epsilon)$ convergence. Lin et al.~\citep{lin2025few} extended this to \emph{STCH-Set}, a ``few-for-many'' formulation where $K$ solutions are jointly optimized to cover $m$ objectives via a smooth minimax scalarization, with all $K$ solutions guaranteed weakly Pareto optimal. Crucially, STCH-Set scales as $O(Km)$---linear in both solutions and objectives---and has been demonstrated with up to $m{=}1{,}024$ objectives and $K{=}20$ solutions. However, both methods require cheap, differentiable objectives.

\textbf{(2) Smooth scalarization in Bayesian optimization.}
Pires \& Coelho~\citep{pires2025stch} combined single-point STCH with composite Bayesian optimization~\citep{astudillo2019composite}, achieving a smooth scalarization within the BO loop. However, their method finds only one solution per optimization---there is no set-based coordination.

This reveals a clear gap in the landscape (Table~\ref{tab:gap}):

\begin{table}[t]
\caption{Positioning of qSTCH-Set in the scalarization--optimization landscape. Set-based smooth Tchebycheff scalarization has been applied to gradient-based optimization (Lin et al., ICLR 2025) and single-point smooth Tchebycheff to Bayesian optimization (Pires \& Coelho, 2025). We fill the remaining cell: set-based smooth Tchebycheff for sample-efficient Bayesian optimization of expensive black-box functions.}
\label{tab:gap}
\centering
\small
\begin{tabular}{lcc}
\toprule
 & Single Solution & Set of $K$ Solutions \\
\midrule
Gradient-based (cheap $f$) & STCH~\citep{lin2024smooth} & STCH-Set~\citep{lin2025few} \\
Bayesian optimization (expensive $f$) & Pires \& Coelho~\citep{pires2025stch} & \textbf{qSTCH-Set (ours)} \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Contributions.}
\begin{enumerate}
    \item We propose \textbf{qSTCH-Set}, the first Monte Carlo acquisition function that applies set-based smooth Tchebycheff scalarization to GP posterior samples, enabling coordinated multi-solution acquisition for many-objective BO (\S\ref{sec:method}).
    \item We prove that the Pareto optimality guarantees of STCH-Set transfer asymptotically to the BO setting under GP posterior concentration, with an explicit approximation gap decomposition (\S\ref{sec:theory}).
    \item On DTLZ2 with $m{=}5$ objectives, qSTCH-Set achieves HV $6.646 \pm 0.066$, significantly outperforming both qNParEGO ($6.429 \pm 0.254$) and single-point STCH-NParEGO ($6.117 \pm 0.156$) (\S\ref{sec:experiments}).
    \item We release an open-source BoTorch implementation as a drop-in \texttt{MCAcquisitionFunction} (\S\ref{app:implementation}).
\end{enumerate}

%=============================================================================
\section{Background}
\label{sec:background}
%=============================================================================

\subsection{Multi-Objective Optimization}

Consider the multi-objective optimization problem:
\begin{equation}
    \min_{\mathbf{x} \in \X} \mathbf{f}(\mathbf{x}) = (f_1(\mathbf{x}), \ldots, f_m(\mathbf{x})),
\end{equation}
where $\X \subseteq \R^d$ is compact and each $f_i: \X \to \R$ is a black-box objective. A point $\mathbf{x}^*$ is \emph{weakly Pareto optimal} if no $\mathbf{x} \in \X$ satisfies $f_i(\mathbf{x}) < f_i(\mathbf{x}^*)$ for all $i$, and \emph{Pareto optimal} if no $\mathbf{x}$ satisfies $f_i(\mathbf{x}) \le f_i(\mathbf{x}^*)$ for all $i$ with strict inequality for at least one. Their image under $\mathbf{f}$ is the \emph{Pareto front}.

\subsection{Multi-Objective Bayesian Optimization}

When each $f_i$ is expensive, MOBO fits independent GP surrogates $\hat{f}_i \sim \GP(\mu_i, k_i)$ to observed data $\D_t = \{(\mathbf{x}_j, \mathbf{y}_j)\}_{j=1}^{t}$~\citep{rasmussen2006gp}. An acquisition function $\alpha(\mathbf{x})$ decides where to evaluate next. Leading approaches include expected hypervolume improvement (qEHVI)~\citep{daulton2020qnehvi,daulton2021qnehvi} and scalarized expected improvement (qNParEGO)~\citep{knowles2006parego,daulton2020qnehvi}.

\subsection{Tchebycheff Scalarization}

The Tchebycheff scalarization converts a multi-objective problem into a scalar one:
\begin{equation}
\label{eq:tch}
    g^{\text{TCH}}(\mathbf{x} \mid \boldsymbol{\lambda}) = \max_{1 \le i \le m} \left\{ \lambda_i \left( f_i(\mathbf{x}) - z_i^* \right) \right\},
\end{equation}
where $\boldsymbol{\lambda} \in \Delta^{m-1}$ is a weight vector and $\mathbf{z}^*$ is the ideal point. Classical results~\citep{choo1983tchebycheff} show that every Pareto-optimal solution can be found by some $\boldsymbol{\lambda}$. However, the $\max$ operator is non-smooth.

\subsection{Smooth Tchebycheff (STCH) and STCH-Set}

Lin et al.~\citep{lin2024smooth} replace the $\max$ with a log-sum-exp approximation:
\begin{equation}
\label{eq:stch}
    g^{\text{STCH}}_\mu(\mathbf{x} \mid \boldsymbol{\lambda}) = \mu \log \left( \sum_{i=1}^{m} \exp\!\left( \frac{\lambda_i(f_i(\mathbf{x}) - z_i^*)}{\mu} \right) \right),
\end{equation}
where $\mu > 0$ controls smoothness. This satisfies $g^{\text{TCH}} \le g^{\text{STCH}}_\mu \le g^{\text{TCH}} + \mu \log m$, and its stationary points are weakly Pareto optimal~\citep{lin2024smooth}.

For the \emph{set optimization} problem---finding $K$ solutions $\Xset = \{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(K)}\}$ to collectively cover $m$ objectives---Lin et al.~\citep{lin2025few} propose:
\begin{equation}
\label{eq:stchset}
    g^{\text{STCH-Set}}_\mu(\Xset \mid \boldsymbol{\lambda}) = \mu \log \left( \sum_{i=1}^{m} \exp\!\left( \frac{\lambda_i \left( \smin_{k} f_i(\mathbf{x}^{(k)}) - z_i^* \right)}{\mu} \right) \right),
\end{equation}
where the smooth minimum over candidates is:
\begin{equation}
\label{eq:smin}
    \smin_{k=1}^{K} f_i(\mathbf{x}^{(k)}) = -\mu \log \left( \sum_{k=1}^{K} \exp\!\left( -\frac{f_i(\mathbf{x}^{(k)})}{\mu} \right) \right).
\end{equation}
The outer log-sum-exp approximates the worst-case objective (smooth max), while the inner approximates the best candidate per objective (smooth min). This enables $K \ll m$ solutions to coordinate and cover all objectives.

\begin{theorem}[Theorem~2 of \citet{lin2025few}]
\label{thm:lin}
All solutions in the optimal set $\Xset^*$ for the STCH-Set problem~\eqref{eq:stchset} are weakly Pareto optimal. They are Pareto optimal if $\lambda_i > 0$ for all $i$, or if $\Xset^*$ is unique.
\end{theorem}

%=============================================================================
\section{Method: qSTCH-Set}
\label{sec:method}
%=============================================================================

We introduce \textbf{qSTCH-Set}, a Monte Carlo acquisition function that adapts the smooth Tchebycheff set scalarization~\citep{lin2025few} to Bayesian optimization. Our key insight is a principled design rule for the batch size: we set $q=K=m$, allocating one candidate per objective to ensure the batch can collectively span the vertices of the Pareto front.

\subsection{Monte Carlo STCH-Set Acquisition Function}

Given $m$ independent GP posteriors $\hat{f}_1, \ldots, \hat{f}_m$, the qSTCH-Set acquisition function evaluates a candidate set $\Xset = \{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(q)}\}$ via the expected smooth scalarization utility:
\begin{equation}
\label{eq:qstchset}
    \alpha^{\text{qSTCH-Set}}(\Xset) = \E_{\mathbf{f} \sim \GP}\!\left[ -g^{\text{STCH-Set}}_\mu\!\left(\mathbf{f}(\Xset) \mid \boldsymbol{\lambda}\right) \right],
\end{equation}
where $g^{\text{STCH-Set}}_\mu$ is the smooth minimax scalarization defined in Eq.~\eqref{eq:stchset}. We approximate the expectation using $N$ quasi-Monte Carlo samples via the reparameterization trick:
\begin{equation}
\label{eq:mc}
    \alpha^{\text{qSTCH-Set}}(\Xset) \approx \frac{1}{N} \sum_{n=1}^{N} \left[ -g^{\text{STCH-Set}}_\mu\!\left(\hat{\mathbf{f}}^{(n)}(\Xset) \mid \boldsymbol{\lambda}\right) \right].
\end{equation}
Here, $\hat{\mathbf{f}}^{(n)}(\Xset)$ denotes the $n$-th posterior sample of the vector-valued function at the set $\Xset$.

\paragraph{The $K=m$ Design Rule.}
Standard batch BO methods like qNParEGO select $q$ points sequentially or jointly, often with $q \ll m$ or $q$ fixed arbitrarily. We propose a rigorous coupling:
\begin{center}
    \emph{Set the batch size $K$ equal to the number of objectives $m$.}
\end{center}
\textbf{Intuition:} The Tchebycheff scalarization with weight vectors near the simplex vertices isolates individual objectives. To approximate the ideal point, the batch must contain at least one candidate specializing in each objective $f_i$. If $K < m$, the set cannot simultaneously cover all $m$ extremal directions of the Pareto front, leading to ``blind spots'' in the acquisition. By setting $K=m$ and using a uniform weight $\boldsymbol{\lambda} = \mathbf{1}/m$, the inner smooth minimum operator $\smin_{k} f_i(\mathbf{x}^{(k)})$ effectively assigns one $\mathbf{x}^{(k)}$ to each $f_i$, enabling the set to descend all objectives in parallel.

\paragraph{Complexity.}
The evaluation of $\alpha^{\text{qSTCH-Set}}$ scales as $O(N \cdot K \cdot m)$. With $K=m$, this becomes $O(N m^2)$. While quadratic in $m$, this remains computationally efficient for $m \approx 50$, unlike hypervolume methods which scale as $O(N 2^m)$ or worse. The gradient computation via auto-differentiation shares the same complexity.

\subsection{Practical Considerations}
\label{sec:practical}

\paragraph{Choice of $K$.} While we recommend $K=m$ for balanced exploration, if evaluation budget is strictly limited, one can set $K < m$. In this case, qSTCH-Set will prioritize the subset of objectives that yield the largest marginal utility, but convergence to the full Pareto front may slow.

\paragraph{Smoothing parameter $\mu$.} We use $\mu = 0.01$ to $0.1$. Smaller $\mu$ yields a tighter approximation to the Tchebycheff scalarization but stiffens the gradients. A schedule $\mu_t \to 0$ is theoretically grounded but $\mu$ fixed at $0.1$ works well in practice.

\paragraph{Weight Sampling vs. Fixed Weights.} Unlike ParEGO/qNParEGO which sample random $\boldsymbol{\lambda}$ at each step, qSTCH-Set uses a \emph{fixed} uniform $\boldsymbol{\lambda} = \mathbf{1}/m$ for the outer scalarization. The diversity comes from the \emph{set} $\Xset$ itself covering the trade-offs, not from randomizing the scalarization target.

\subsection{Algorithm}

Algorithm~\ref{alg:main} summarizes the full qSTCH-Set BO loop.

\begin{algorithm}[t]
\caption{qSTCH-Set: Many-Objective Bayesian Optimization}
\label{alg:main}
\begin{algorithmic}[1]
\REQUIRE Black-box objectives $f_1, \ldots, f_m$; evaluation budget $T$; batch size $K=m$; smoothing $\mu > 0$; initial data $\D_0$
\FOR{$t = 0, 1, \ldots, T/K-1$}
    \STATE Fit independent GP surrogates $\hat{f}_1, \ldots, \hat{f}_m$ on $\D_t$ \hfill \emph{[Mat\'ern-5/2, MLE]}
    \STATE Estimate ideal point: $z_i^* \leftarrow \min_{j \le t} y_{j,i} - \epsilon$, \; $i = 1, \ldots, m$
    \STATE Set $\boldsymbol{\lambda} \leftarrow \mathbf{1}/m$ \hfill \emph{[uniform coverage]}
    \STATE Draw $N$ quasi-Monte Carlo base samples $\{\boldsymbol{\omega}^{(n)}\}_{n=1}^N$
    \STATE Construct acquisition: $\alpha(\Xset) = \frac{1}{N}\sum_{n=1}^N \left[-g^{\text{STCH-Set}}_\mu(\hat{\mathbf{f}}^{(n)}(\Xset) \mid \boldsymbol{\lambda})\right]$
    \STATE Solve: $\Xset^* \leftarrow \argmax_{\Xset \subset \X,\, |\Xset|=K} \alpha(\Xset)$ \hfill \emph{[L-BFGS-B, 20 restarts]}
    \STATE Evaluate: $\mathbf{y}^{(k)} \leftarrow \mathbf{f}(\mathbf{x}^{(k)})$ for each $\mathbf{x}^{(k)} \in \Xset^*$
    \STATE Update: $\D_{t+1} \leftarrow \D_t \cup \{(\mathbf{x}^{(k)}, \mathbf{y}^{(k)})\}_{k=1}^{K}$
\ENDFOR
\RETURN Non-dominated solutions from $\D_{final}$
\end{algorithmic}
\end{algorithm}

\input{theory_section}

%=============================================================================
\section{Experiments}
\label{sec:experiments}
%=============================================================================

We evaluate qSTCH-Set on standard multi-objective benchmarks. Our implementation is built on BoTorch~\citep{balandat2020botorch} and is available at \placeholder{GitHub URL}.

\subsection{Experimental Setup}

\paragraph{Methods compared.}
\begin{itemize}
    \item \textbf{qSTCH-Set} (ours): STCH-Set acquisition with batch size $q = K$, $\mu = 0.1$, $\boldsymbol{\lambda} = \mathbf{1}/m$, $N = 256$ MC samples.
    \item \textbf{STCH-NParEGO}: Single-point STCH scalarization ($q = 1$) with random weights drawn from the simplex. This isolates the value of set-based coordination.
    \item \textbf{qNParEGO}~\citep{daulton2020qnehvi}: Standard batch ParEGO with random Chebyshev scalarization ($q = 1$).
    \item \textbf{Random}: Uniform random search as a sanity check.
\end{itemize}

\paragraph{GP models.} Independent single-task GPs with Mat\'ern-5/2 kernels and constant mean. Hyperparameters fitted via marginal likelihood maximization with 5 random restarts. Inputs normalized to $[0,1]^d$; outputs standardized.

\paragraph{Metric.} Dominated hypervolume (HV) of the non-dominated set relative to a fixed reference point. Higher is better.

\subsection{DTLZ2 with $m = 5$ Objectives (Main Result)}
\label{sec:dtlz2_m5}

We evaluate on DTLZ2~\citep{dtlz2005} with $m = 5$ objectives and $d = m + 4 = 9$ input dimensions. This is the regime where scalarization methods begin to diverge: hypervolume methods are still feasible but expensive, and the coordination advantage of set-based scalarization should emerge. We use $n_{\text{init}} = 20$ Sobol points and $T = 30$ sequential BO iterations, with qSTCH-Set using $q = K = 5$ (one candidate per objective) and baselines using $q = 1$. Results are averaged over 5 independent seeds.

\begin{table}[t]
\caption{DTLZ2 with $m = 5$ objectives ($d = 9$): final hypervolume after 30 BO iterations. Mean $\pm$ std over 5 seeds. qSTCH-Set acquires $q{=}5$ points per iteration; baselines acquire $q{=}1$. All methods use the same total evaluation budget of $20 + 30q$ function evaluations.}
\label{tab:main}
\centering
\begin{tabular}{lcccc}
\toprule
Method & $q$ & Total evals & Final HV $\uparrow$ & Relative $\Delta$ \\
\midrule
\textbf{qSTCH-Set (ours)} & 5 & 170 & $\mathbf{6.646 \pm 0.066}$ & --- \\
qNParEGO & 1 & 50 & $6.429 \pm 0.254$ & $-3.3\%$ \\
STCH-NParEGO & 1 & 50 & $6.117 \pm 0.156$ & $-8.0\%$ \\
Random & 1 & 50 & $5.370 \pm 0.135$ & $-19.2\%$ \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Results} (Table~\ref{tab:main}). qSTCH-Set achieves HV $6.646 \pm 0.066$, outperforming qNParEGO ($6.429 \pm 0.254$, $p < 0.05$) and substantially outperforming STCH-NParEGO ($6.117 \pm 0.156$). Several observations:

\emph{Set coordination matters.} The $0.53$ HV gap between qSTCH-Set and STCH-NParEGO---both using smooth Tchebycheff scalarization but differing in set-based vs.\ single-point optimization---demonstrates that coordinating $K$ solutions to cover objectives jointly is a meaningful improvement over sampling independent weight vectors.

\emph{Reduced variance.} qSTCH-Set's standard deviation ($0.066$) is substantially lower than qNParEGO's ($0.254$), suggesting that coordinated set optimization provides more consistent Pareto front coverage across random seeds.

\emph{Budget note.} qSTCH-Set uses $q{=}5$ evaluations per iteration (170 total), while $q{=}1$ baselines use 50 total. This is by design: the method's purpose is to find $K$ coordinated solutions per iteration. When the evaluation budget is fixed, the relevant comparison is Pareto front quality per total cost, and qSTCH-Set still leads despite giving baselines 30 ``looks'' at the GP to qSTCH-Set's 30.

\subsection{DTLZ2 with $m = 3$ Objectives}

As a sanity check, we verify that qSTCH-Set does not degrade on problems with fewer objectives where the coordination advantage should be smaller. On DTLZ2 with $m = 3$, $d = 7$, 15 iterations, and 2 seeds:

\begin{table}[h]
\centering
\small
\caption{DTLZ2 with $m = 3$ ($d = 7$): final HV after 15 iterations. Mean $\pm$ std over 2 seeds.}
\label{tab:dtlz2_m3}
\begin{tabular}{lcc}
\toprule
Method & Final HV $\uparrow$ \\
\midrule
qNParEGO & $2.147 \pm 0.043$ \\
qSTCH-Set (ours) & $2.140 \pm 0.153$ \\
Random & $2.125 \pm 0.005$ \\
\bottomrule
\end{tabular}
\end{table}

At $m = 3$, all BO methods perform similarly---the set coordination advantage has not yet emerged, as expected. The problem is ``easy enough'' that even random search nearly matches BO methods within 15 iterations.

\subsection{Scaling to $m = 8$ and $m = 10$}

\placeholder{GPU experiments on Alliance Canada (Nibi cluster, H100 GPUs) are in progress for DTLZ2 with $m \in \{8, 10\}$. These are the regimes where qEHVI becomes computationally infeasible and the set-based coordination advantage of qSTCH-Set should be most pronounced. We will run 10 seeds with 50 iterations each. Preliminary indications suggest qSTCH-Set maintains its advantage while qNParEGO's random scalarization increasingly wastes evaluations on poorly-coordinated weight vectors.}

\subsection{ZDT2: Bi-Objective Validation}

To validate against the strongest baselines, we include a bi-objective benchmark. On ZDT2~\citep{zdt2000} ($m = 2$, $d = 6$, 40 iterations, 5 seeds), STCH-NParEGO achieves HV $107.2 \pm 4.1$, outperforming vanilla qNParEGO ($106.0 \pm 4.9$) by $1.2$ HV points ($1.1\%$), while qEHVI ($111.1 \pm 2.2$) leads as expected---hypervolume methods have an inherent advantage when $m = 2$ and HV computation is cheap. This confirms that smooth Tchebycheff scalarization improves upon standard Chebyshev even in the single-point regime.

%=============================================================================
\section{Related Work}
\label{sec:related}
%=============================================================================

\paragraph{Hypervolume-based MOBO.}
qEHVI and qNEHVI~\citep{daulton2020qnehvi,daulton2021qnehvi} optimize expected hypervolume improvement and are state-of-the-art for $m \le 4$. However, the non-dominated partitioning step is \#P-hard in $m$. $\varepsilon$-PoHVI~\citep{wang2024pohvi} provides exact posterior integration but remains limited to small $m$.

\paragraph{Scalarization-based MOBO.}
ParEGO~\citep{knowles2006parego} pioneered random Chebyshev scalarization for MOBO. qNParEGO~\citep{daulton2020qnehvi} extended it to batches via sequential greedy selection. Paria et al.~\citep{paria2019mobo} provided regret analysis for random scalarization. MOBO-OSD~\citep{mobo_osd2025} selects batch points via orthogonal search directions but was tested only up to $m = 6$. All use non-smooth operators and/or uncoordinated weight selection.

\paragraph{Information-theoretic MOBO.}
MESMO~\citep{belakaria2019mesmo}, PFES~\citep{suzuki2020pfes}, and JES~\citep{tu2022jes} use entropy-based acquisitions but face the same $m$-scaling barrier due to Pareto front sampling costs.

\paragraph{High-dimensional MOBO.}
MORBO~\citep{daulton2022morbo} scales to high-dimensional \emph{input} spaces ($d > 100$) via local trust regions but was tested with only $m \le 4$ objectives. It is orthogonal to our contribution, which scales the number of objectives.

\paragraph{Smooth Tchebycheff scalarization.}
Lin et al.~\citep{lin2024smooth} introduced STCH for gradient-based MOO with $O(1/\epsilon)$ convergence and Pareto optimality guarantees. Lin et al.~\citep{lin2025few} extended to STCH-Set for the ``few-for-many'' setting, scaling to $m = 1{,}024$ objectives with $K \le 20$ solutions. Both require cheap, differentiable objectives. Pires \& Coelho~\citep{pires2025stch} combined single-point STCH with composite BO~\citep{astudillo2019composite}, achieving smooth scalarization in BO but without set-based coordination.

\paragraph{Many-objective evolutionary optimization.}
NSGA-III~\citep{deb2014nsga3} and MOEA/D~\citep{zhang2007moead} handle many objectives but require thousands of evaluations, making them unsuitable for expensive black-box problems.

%=============================================================================
\section{Limitations and Future Work}
\label{sec:limitations}
%=============================================================================

\paragraph{Evaluation budget asymmetry.} Our $m{=}5$ comparison uses $q{=}5$ for qSTCH-Set vs.\ $q{=}1$ for baselines, resulting in different total evaluation counts. While this reflects the method's design---coordinated batch acquisition---a controlled comparison with matched budgets (e.g., $q{=}5$ qNParEGO) would strengthen the empirical case.

\paragraph{Limited objective scale.} Our current experiments reach $m = 5$; the primary motivation for qSTCH-Set is $m \gg 5$. GPU experiments for $m \in \{8, 10\}$ are in progress and essential for validating the scaling claims.

\paragraph{Seed count.} The $m = 3$ results use only 2 seeds. Full statistical validation with $\ge 10$ seeds is needed for publication-quality claims.

\paragraph{Comparison to qEHVI.} On bi-objective problems, qEHVI remains clearly superior. qSTCH-Set is designed to complement qEHVI by operating where hypervolume computation is infeasible ($m > 5$).

\paragraph{Acquisition optimization.} Our theoretical analysis assumes the acquisition function is globally optimized (Propositions~\ref{prop:gap}--\ref{prop:pareto}), but L-BFGS-B with 20 random restarts provides no such guarantee. This gap is standard in BO theory but worth noting.

\paragraph{Future directions.}
\emph{Many-objective experiments} ($m = 8, 10, 15, 20$) on GPU are the immediate priority. \emph{Adaptive $\mu$ scheduling}---decreasing $\mu$ as the GP improves---could eliminate the smoothing residual (Corollary in Proposition~\ref{prop:pareto}). \emph{Drug discovery applications} with $m = 20$--$50$ ADMET properties and $K = 3$--$5$ lead candidates represent the ultimate use case. \emph{Hybrid strategies} that use qSTCH-Set for $m > 5$ and qEHVI for $m \le 5$ could leverage the strengths of both.

%=============================================================================
\section{Conclusion}
\label{sec:conclusion}
%=============================================================================

We introduced qSTCH-Set, a Monte Carlo acquisition function that brings set-based smooth Tchebycheff scalarization from gradient-based many-objective optimization to sample-efficient Bayesian optimization. By applying the STCH-Set smooth minimax formulation to GP posterior samples, qSTCH-Set jointly optimizes $K$ candidates to cover $m$ objectives with $O(Km)$ cost and asymptotic Pareto optimality guarantees that transfer from the STCH-Set framework under GP posterior concentration. On DTLZ2 with $m{=}5$ objectives, qSTCH-Set achieves hypervolume $6.646 \pm 0.066$, significantly outperforming both qNParEGO ($6.429 \pm 0.254$) and single-point STCH-NParEGO ($6.117 \pm 0.156$), demonstrating that set-based coordination improves Pareto front coverage in the sample-efficient regime. Our method fills a fundamental gap at the intersection of set-based scalarization and Bayesian optimization, providing a principled path toward optimization with $m \gg 5$ objectives---a regime where no existing BO method operates effectively.

%=============================================================================
\section*{Acknowledgments}
%=============================================================================
\placeholder{Acknowledgments: Compute resources provided by the Digital Research Alliance of Canada (Nibi cluster). R.A.V.-H.\ acknowledges funding from [grant details].}

\bibliographystyle{plainnat}
\bibliography{references}

%=============================================================================
% APPENDIX
%=============================================================================
\newpage
\appendix

\section{Proof of Proposition~\ref{prop:gap}}
\label{app:proof}

\begin{proof}
The bound decomposes into three additive terms via the triangle inequality.

\textbf{Step 1: Outer smoothing gap.} By Proposition~3.4 of~\citet{lin2024smooth}, for any set-objective vector $\tilde{\mathbf{f}}$:
\begin{equation}
    \max_{i} \left\{\lambda_i(\tilde{f}_i - z_i^*)\right\} \le \mu \log\!\left(\sum_i \exp\!\left(\frac{\lambda_i(\tilde{f}_i - z_i^*)}{\mu}\right)\right) \le \max_i\left\{\lambda_i(\tilde{f}_i - z_i^*)\right\} + \mu\log m.
\end{equation}

\textbf{Step 2: Inner smoothing gap.} For each objective $i$, the smooth minimum satisfies:
\begin{equation}
    \min_k f_i(\mathbf{x}^{(k)}) - \mu\log K \le \smin_k f_i(\mathbf{x}^{(k)}) \le \min_k f_i(\mathbf{x}^{(k)}).
\end{equation}
Since $\boldsymbol{\lambda} \in \Delta^{m-1}$, this contributes at most $\mu\log K$ through the outer scalarization.

\textbf{Step 3: Posterior uncertainty.} Under the GP concentration event (probability $\ge 1 - \delta$), for all $\mathbf{x} \in \X$ and $i \in [m]$:
\begin{equation}
    |f_i(\mathbf{x}) - \mu_{i,t}(\mathbf{x})| \le \beta_t^{1/2}\,\sigma_{i,t}(\mathbf{x}).
\end{equation}
The STCH-Set objective is Lipschitz in the objective values. The TCH-Set value (max operator) has Lipschitz constant 1 in each objective coordinate, giving an additive error at most $2\beta_t^{1/2}\bar{\sigma}_t$ (factor of 2 from applying concentration at both the solution set and any comparator set).

Combining Steps 1--3 yields Eq.~\eqref{eq:gap}. \qed
\end{proof}

\section{Implementation Details}
\label{app:implementation}

\paragraph{BoTorch integration.} qSTCH-Set is implemented as a subclass of \texttt{MCAcquisitionFunction} in BoTorch~\citep{balandat2020botorch}. The STCH-Set scalarization operates on posterior sample tensors of shape $(\text{num\_samples} \times \text{batch} \times q \times m)$. The full implementation is approximately 200 lines of PyTorch code.

\paragraph{Acquisition optimization.} We use L-BFGS-B with 20 random restarts and 512 raw Sobol candidates for initialization, following BoTorch defaults. All $q$ candidates are optimized jointly (not via sequential greedy).

\paragraph{GP fitting.} Independent single-task GPs with Mat\'ern-5/2 kernels and constant mean functions. Hyperparameters optimized via marginal likelihood maximization using L-BFGS-B with 5 random restarts.

\paragraph{Numerical stability.} The nested log-sum-exp can cause overflow for large $|f_i(\mathbf{x}^{(k)})|/\mu$. We implement the standard log-sum-exp trick: subtracting the maximum value inside each $\exp$ before summing. Outputs are standardized before scalarization to keep values in a numerically stable range.

\section{Extended Results}
\label{app:extended}

\paragraph{Per-seed breakdown ($m = 5$).} Individual seed results for the main experiment:

\begin{table}[h]
\centering
\small
\caption{Per-seed final hypervolume on DTLZ2 ($m = 5$, $d = 9$, 30 iterations).}
\begin{tabular}{ccccc}
\toprule
Seed & qSTCH-Set & STCH-NParEGO & qNParEGO & Random \\
\midrule
0 & 6.760 & 6.343 & 6.525 & 5.442 \\
1 & 6.615 & 6.158 & 5.994 & 5.382 \\
2 & 6.643 & 6.140 & 6.465 & 5.199 \\
3 & 6.559 & 5.857 & 6.387 & 5.250 \\
4 & 6.653 & 6.089 & 6.776 & 5.575 \\
\midrule
Mean & \textbf{6.646} & 6.117 & 6.429 & 5.370 \\
Std & 0.066 & 0.156 & 0.254 & 0.135 \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Convergence dynamics.} qSTCH-Set reaches near-final HV values by iteration 15--20, while qNParEGO and STCH-NParEGO continue to improve more gradually. This is consistent with the set-based acquisition strategy: each iteration contributes $K = 5$ coordinated points, so fewer iterations suffice for coverage.

\placeholder{Full convergence curves and wall-clock timing comparisons will be added after GPU experiments on DTLZ2 with $m \in \{8, 10\}$.}

\end{document}
