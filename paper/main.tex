\documentclass{article}

% NeurIPS 2026 style
\usepackage[final]{neurips_2026}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{xcolor}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{amsthm}
\usepackage{thm-restate}

% Theorem environments
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{assumption}[theorem]{Assumption}

% Custom commands
\newcommand{\placeholder}[1]{{\color{red}\textbf{[#1]}}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\GP}{\mathcal{GP}}
\newcommand{\Xset}{X_K}
\newcommand{\smax}{\mathrm{smax}}
\newcommand{\smin}{\mathrm{smin}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\title{Set-Based Smooth Tchebycheff Scalarization\\for Many-Objective Bayesian Optimization}

\author{
  Ilkham Yabbarov \\
  Department of Chemistry \\
  McMaster University \\
  \texttt{yabbari@mcmaster.ca} \\
  \And
  Rodrigo A. Vargas-Hern\'andez \\
  Department of Chemistry \\
  McMaster University \\
  \texttt{vargashr@mcmaster.ca} \\
}

\begin{document}

\maketitle

%=============================================================================
\begin{abstract}
%=============================================================================
Multi-objective Bayesian optimization (MOBO) scales poorly beyond five objectives: hypervolume-based acquisition functions incur exponential cost in the number of objectives~$m$, while scalarization methods produce uncoordinated batches via random weight vectors.
Set-based smooth Tchebycheff (STCH-Set) scalarization addresses this in gradient-based optimization, and single-point STCH has been adapted to BO, but no method combines set-based coordination with sample-efficient surrogate-driven search.
We introduce qSTCH-Set, a Monte Carlo acquisition function that jointly optimizes $K$ candidates via STCH-Set scalarization over Gaussian process posterior samples at $O(Km)$ cost, with the design rule $K{=}m$ allocating one candidate per objective.
On DTLZ2 with $m{=}5$ objectives, qSTCH-Set achieves hypervolume $6.646 \pm 0.066$, outperforming both qNParEGO ($6.429 \pm 0.254$) and single-point STCH ($6.117 \pm 0.156$); at $m{=}8$ the advantage widens to 11\%, empirically validating the $K{=}m$ rule.
qSTCH-Set fills a fundamental gap in many-objective Bayesian optimization, enabling coordinated Pareto front coverage in regimes where hypervolume-based methods are computationally intractable.
\end{abstract}

%=============================================================================
\section{Introduction}
\label{sec:intro}
%=============================================================================

Many real-world optimization problems require balancing a large number of conflicting objectives simultaneously.
In drug discovery, a candidate molecule must satisfy constraints on potency, selectivity, metabolic stability, permeability, and toxicity---routinely $m{=}20$--$50$ ADMET endpoints~\citep{knowles2006parego}.
In materials design, one seeks alloys balancing strength, weight, cost, and corrosion resistance.
When function evaluations are expensive---requiring physical experiments, molecular simulations, or costly assays---multi-objective Bayesian optimization (MOBO) provides a principled, sample-efficient framework that fits Gaussian process (GP) surrogates to observed data and uses acquisition functions to guide evaluation~\citep{balandat2020botorch}.

However, existing MOBO methods face a fundamental scaling barrier in the number of objectives~$m$.
Hypervolume-based acquisition functions---the gold standard for $m \le 4$---rely on non-dominated partitioning of the objective space, which is \#P-hard in~$m$~\citep{daulton2020qnehvi,daulton2021qnehvi,wang2024pohvi}.
Scalarization methods such as ParEGO and qNParEGO~\citep{knowles2006parego,daulton2020qnehvi} decompose the problem via random Chebyshev weight vectors, scaling gracefully in~$m$ but producing uncoordinated solutions: each batch element optimizes an independently sampled weight with no mechanism to ensure collective Pareto front coverage.
Information-theoretic approaches (MESMO, PFES, JES)~\citep{belakaria2019mesmo,suzuki2020pfes,tu2022jes} face similar degradation as Pareto front sampling costs grow with~$m$.

Two recent lines of work have made partial progress toward scalable many-objective scalarization.
Lin et al.~\citep{lin2024smooth} introduced smooth Tchebycheff (STCH) scalarization, a log-sum-exp relaxation of the non-smooth Chebyshev scalarization that is everywhere differentiable and preserves Pareto optimality guarantees.
They extended this to STCH-Set~\citep{lin2025few}, where $K$ solutions are jointly optimized via a smooth minimax formulation to collectively cover~$m$ objectives at $O(Km)$ cost, demonstrating scaling to $m{=}1{,}024$ objectives in gradient-based optimization with cheap, differentiable objectives.
Independently, Pires \& Coelho~\citep{pires2025stch} adapted single-point STCH to composite Bayesian optimization~\citep{astudillo2019composite}, achieving smooth scalarization within the BO loop but without set-based coordination.
This leaves a clear gap in the landscape (Table~\ref{tab:gap}): no method applies set-based smooth Tchebycheff scalarization to sample-efficient Bayesian optimization of expensive black-box functions.

\begin{table}[t]
\caption{Positioning of qSTCH-Set in the scalarization--optimization landscape. Set-based STCH has been applied to gradient-based optimization~\citep{lin2025few} and single-point STCH to Bayesian optimization~\citep{pires2025stch}. We fill the remaining cell.}
\label{tab:gap}
\centering
\small
\begin{tabular}{lcc}
\toprule
 & Single Solution & Set of $K$ Solutions \\
\midrule
Gradient-based (cheap $f$) & STCH~\citep{lin2024smooth} & STCH-Set~\citep{lin2025few} \\
Bayesian optimization (expensive $f$) & Pires \& Coelho~\citep{pires2025stch} & \textbf{qSTCH-Set (ours)} \\
\bottomrule
\end{tabular}
\end{table}

We fill this gap with \textbf{qSTCH-Set}, a Monte Carlo acquisition function that evaluates a candidate set by applying the STCH-Set minimax scalarization to GP posterior samples, enabling coordinated multi-solution acquisition for many-objective BO.
Our key design rule sets $K{=}m$: one candidate per objective, so that the smooth minimum operator assigns each candidate to a distinct objective direction, expanding the Pareto front along all axes simultaneously.

\paragraph{Contributions.}
\begin{enumerate}
    \item We propose \textbf{qSTCH-Set}, the first Monte Carlo acquisition function that applies set-based smooth Tchebycheff scalarization to GP posterior samples for many-objective Bayesian optimization (\S\ref{sec:method}).
    \item We prove that STCH-Set Pareto optimality guarantees transfer asymptotically under GP posterior concentration, with an explicit approximation gap of $\mu\log(mK) + O(\beta_t^{1/2}\bar{\sigma}_t)$ (\S\ref{sec:theory}).
    \item On DTLZ2, qSTCH-Set outperforms qNParEGO and single-point STCH at both $m{=}5$ and $m{=}8$ objectives, with the advantage widening at higher~$m$ (\S\ref{sec:experiments}).
    \item We release an open-source BoTorch implementation as a drop-in \texttt{MCAcquisitionFunction} (\S\ref{app:implementation}).
\end{enumerate}

%=============================================================================
\section{Background}
\label{sec:background}
%=============================================================================

\subsection{Multi-Objective Optimization}

Consider the multi-objective optimization problem:
\begin{equation}
    \min_{\mathbf{x} \in \X} \mathbf{f}(\mathbf{x}) = (f_1(\mathbf{x}), \ldots, f_m(\mathbf{x})),
\end{equation}
where $\X \subseteq \R^d$ is compact and each $f_i: \X \to \R$ is a black-box objective. A point $\mathbf{x}^*$ is \emph{weakly Pareto optimal} if no $\mathbf{x} \in \X$ satisfies $f_i(\mathbf{x}) < f_i(\mathbf{x}^*)$ for all $i$, and \emph{Pareto optimal} if no $\mathbf{x}$ satisfies $f_i(\mathbf{x}) \le f_i(\mathbf{x}^*)$ for all $i$ with strict inequality for at least one. Their image under $\mathbf{f}$ is the \emph{Pareto front}.

\subsection{Multi-Objective Bayesian Optimization}

When each $f_i$ is expensive, MOBO fits independent GP surrogates $\hat{f}_i \sim \GP(\mu_i, k_i)$ to observed data $\D_t = \{(\mathbf{x}_j, \mathbf{y}_j)\}_{j=1}^{t}$~\citep{rasmussen2006gp}. An acquisition function $\alpha(\mathbf{x})$ decides where to evaluate next. Leading approaches include expected hypervolume improvement (qEHVI)~\citep{daulton2020qnehvi,daulton2021qnehvi} and scalarized expected improvement (qNParEGO)~\citep{knowles2006parego,daulton2020qnehvi}.

\subsection{Tchebycheff Scalarization}

The Tchebycheff scalarization converts a multi-objective problem into a scalar one:
\begin{equation}
\label{eq:tch}
    g^{\text{TCH}}(\mathbf{x} \mid \boldsymbol{\lambda}) = \max_{1 \le i \le m} \left\{ \lambda_i \left( f_i(\mathbf{x}) - z_i^* \right) \right\},
\end{equation}
where $\boldsymbol{\lambda} \in \Delta^{m-1}$ is a weight vector and $\mathbf{z}^*$ is the ideal point. Classical results~\citep{choo1983tchebycheff} show that every Pareto-optimal solution can be found by some $\boldsymbol{\lambda}$. However, the $\max$ operator is non-smooth.

\subsection{Smooth Tchebycheff (STCH) and STCH-Set}

Lin et al.~\citep{lin2024smooth} replace the $\max$ with a log-sum-exp approximation:
\begin{equation}
\label{eq:stch}
    g^{\text{STCH}}_\mu(\mathbf{x} \mid \boldsymbol{\lambda}) = \mu \log \left( \sum_{i=1}^{m} \exp\!\left( \frac{\lambda_i(f_i(\mathbf{x}) - z_i^*)}{\mu} \right) \right),
\end{equation}
where $\mu > 0$ controls smoothness. This satisfies $g^{\text{TCH}} \le g^{\text{STCH}}_\mu \le g^{\text{TCH}} + \mu \log m$, and its stationary points are weakly Pareto optimal~\citep{lin2024smooth}.

For the \emph{set optimization} problem---finding $K$ solutions $\Xset = \{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(K)}\}$ to collectively cover $m$ objectives---Lin et al.~\citep{lin2025few} propose:
\begin{equation}
\label{eq:stchset}
    g^{\text{STCH-Set}}_\mu(\Xset \mid \boldsymbol{\lambda}) = \mu \log \left( \sum_{i=1}^{m} \exp\!\left( \frac{\lambda_i \left( \smin_{k} f_i(\mathbf{x}^{(k)}) - z_i^* \right)}{\mu} \right) \right),
\end{equation}
where the smooth minimum over candidates is:
\begin{equation}
\label{eq:smin}
    \smin_{k=1}^{K} f_i(\mathbf{x}^{(k)}) = -\mu \log \left( \sum_{k=1}^{K} \exp\!\left( -\frac{f_i(\mathbf{x}^{(k)})}{\mu} \right) \right).
\end{equation}
The outer log-sum-exp approximates the worst-case objective (smooth max), while the inner approximates the best candidate per objective (smooth min). This enables $K \ll m$ solutions to coordinate and cover all objectives.

\begin{theorem}[Theorem~2 of \citet{lin2025few}]
\label{thm:lin}
All solutions in the optimal set $\Xset^*$ for the STCH-Set problem~\eqref{eq:stchset} are weakly Pareto optimal. They are Pareto optimal if $\lambda_i > 0$ for all $i$, or if $\Xset^*$ is unique.
\end{theorem}

%=============================================================================
\section{Method: qSTCH-Set}
\label{sec:method}
%=============================================================================

We introduce \textbf{qSTCH-Set}, a Monte Carlo acquisition function that adapts the smooth Tchebycheff set scalarization~\citep{lin2025few} to Bayesian optimization. Our key insight is a principled design rule for the batch size: we set $q=K=m$, allocating one candidate per objective to ensure the batch can collectively span the vertices of the Pareto front.

\subsection{Monte Carlo STCH-Set Acquisition Function}

Given $m$ independent GP posteriors $\hat{f}_1, \ldots, \hat{f}_m$, the qSTCH-Set acquisition function evaluates a candidate set $\Xset = \{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(q)}\}$ via the expected smooth scalarization utility:
\begin{equation}
\label{eq:qstchset}
    \alpha^{\text{qSTCH-Set}}(\Xset) = \E_{\mathbf{f} \sim \GP}\!\left[ -g^{\text{STCH-Set}}_\mu\!\left(\mathbf{f}(\Xset) \mid \boldsymbol{\lambda}\right) \right],
\end{equation}
where $g^{\text{STCH-Set}}_\mu$ is the smooth minimax scalarization defined in Eq.~\eqref{eq:stchset}. We approximate the expectation using $N$ quasi-Monte Carlo samples via the reparameterization trick:
\begin{equation}
\label{eq:mc}
    \alpha^{\text{qSTCH-Set}}(\Xset) \approx \frac{1}{N} \sum_{n=1}^{N} \left[ -g^{\text{STCH-Set}}_\mu\!\left(\hat{\mathbf{f}}^{(n)}(\Xset) \mid \boldsymbol{\lambda}\right) \right].
\end{equation}
Here, $\hat{\mathbf{f}}^{(n)}(\Xset)$ denotes the $n$-th posterior sample of the vector-valued function at the set $\Xset$.

\paragraph{The $K=m$ Design Rule.}
Standard batch BO methods like qNParEGO select $q$ points sequentially or jointly, often with $q \ll m$ or $q$ fixed arbitrarily. We propose a rigorous coupling:
\begin{center}
    \emph{Set the batch size $K$ equal to the number of objectives $m$.}
\end{center}
\textbf{Intuition:} The Tchebycheff scalarization with weight vectors near the simplex vertices isolates individual objectives. To approximate the ideal point, the batch must contain at least one candidate specializing in each objective $f_i$. If $K < m$, the set cannot simultaneously cover all $m$ extremal directions of the Pareto front, leading to ``blind spots'' in the acquisition. By setting $K=m$ and using a uniform weight $\boldsymbol{\lambda} = \mathbf{1}/m$, the inner smooth minimum operator $\smin_{k} f_i(\mathbf{x}^{(k)})$ effectively assigns one $\mathbf{x}^{(k)}$ to each $f_i$, enabling the set to descend all objectives in parallel.

\paragraph{Complexity.}
The evaluation of $\alpha^{\text{qSTCH-Set}}$ scales as $O(N \cdot K \cdot m)$. With $K=m$, this becomes $O(N m^2)$. While quadratic in $m$, this remains computationally efficient for $m \approx 50$, unlike hypervolume methods which scale as $O(N 2^m)$ or worse. The gradient computation via auto-differentiation shares the same complexity.

\subsection{Practical Considerations}
\label{sec:practical}

\paragraph{Choice of $K$.} While we recommend $K=m$ for balanced exploration, if evaluation budget is strictly limited, one can set $K < m$. In this case, qSTCH-Set will prioritize the subset of objectives that yield the largest marginal utility, but convergence to the full Pareto front may slow.

\paragraph{Smoothing parameter $\mu$.} We use $\mu = 0.01$ to $0.1$. Smaller $\mu$ yields a tighter approximation to the Tchebycheff scalarization but stiffens the gradients. A schedule $\mu_t \to 0$ is theoretically grounded but $\mu$ fixed at $0.1$ works well in practice.

\paragraph{Weight Sampling vs. Fixed Weights.} Unlike ParEGO/qNParEGO which sample random $\boldsymbol{\lambda}$ at each step, qSTCH-Set uses a \emph{fixed} uniform $\boldsymbol{\lambda} = \mathbf{1}/m$ for the outer scalarization. The diversity comes from the \emph{set} $\Xset$ itself covering the trade-offs, not from randomizing the scalarization target.

\subsection{Algorithm}

Algorithm~\ref{alg:main} summarizes the full qSTCH-Set BO loop.

\begin{algorithm}[t]
\caption{qSTCH-Set: Many-Objective Bayesian Optimization}
\label{alg:main}
\begin{algorithmic}[1]
\REQUIRE Black-box objectives $f_1, \ldots, f_m$; evaluation budget $T$; batch size $K=m$; smoothing $\mu > 0$; initial data $\D_0$
\FOR{$t = 0, 1, \ldots, T/K-1$}
    \STATE Fit independent GP surrogates $\hat{f}_1, \ldots, \hat{f}_m$ on $\D_t$ \hfill \emph{[Mat\'ern-5/2, MLE]}
    \STATE Estimate ideal point: $z_i^* \leftarrow \min_{j \le t} y_{j,i} - \epsilon$, \; $i = 1, \ldots, m$
    \STATE Set $\boldsymbol{\lambda} \leftarrow \mathbf{1}/m$ \hfill \emph{[uniform coverage]}
    \STATE Draw $N$ quasi-Monte Carlo base samples $\{\boldsymbol{\omega}^{(n)}\}_{n=1}^N$
    \STATE Construct acquisition: $\alpha(\Xset) = \frac{1}{N}\sum_{n=1}^N \left[-g^{\text{STCH-Set}}_\mu(\hat{\mathbf{f}}^{(n)}(\Xset) \mid \boldsymbol{\lambda})\right]$
    \STATE Solve: $\Xset^* \leftarrow \argmax_{\Xset \subset \X,\, |\Xset|=K} \alpha(\Xset)$ \hfill \emph{[L-BFGS-B, 20 restarts]}
    \STATE Evaluate: $\mathbf{y}^{(k)} \leftarrow \mathbf{f}(\mathbf{x}^{(k)})$ for each $\mathbf{x}^{(k)} \in \Xset^*$
    \STATE Update: $\D_{t+1} \leftarrow \D_t \cup \{(\mathbf{x}^{(k)}, \mathbf{y}^{(k)})\}_{k=1}^{K}$
\ENDFOR
\RETURN Non-dominated solutions from $\D_{final}$
\end{algorithmic}
\end{algorithm}

\input{theory_section}

%=============================================================================
\section{Experiments}
\label{sec:experiments}
%=============================================================================

We evaluate qSTCH-Set on standard multi-objective benchmarks (DTLZ2, ZDT2) to demonstrate its scalability and effectiveness in many-objective regimes ($m \ge 5$) where traditional hypervolume-based methods are computationally intractable. Our implementation is built on BoTorch~\citep{balandat2020botorch} and is available at \url{https://github.com/parameters/qSTCH-Set}.

\subsection{Experimental Setup}

We compare the following methods on DTLZ2 problems with $m \in \{5, 8, 10\}$ objectives. All experiments use H100 GPUs on the Digital Research Alliance of Canada (Nibi cluster).

\paragraph{Methods.}
\begin{itemize}
    \item \textbf{qSTCH-Set} (ours): Set-based smooth Tchebycheff acquisition with $q = K = m$, $\mu = 0.1$, fixed uniform outer weights $\boldsymbol{\lambda} = \mathbf{1}/m$, and $N = 256$ MC samples.
    \item \textbf{STCH-NParEGO}: Single-point smooth scalarization ($q = 1$) with random weights.
    \item \textbf{qNParEGO}~\citep{daulton2020qnehvi}: Standard batch ParEGO with random Chebyshev scalarization ($q = 1$).
    \item \textbf{Random}: Uniform random search ($q=1$).
\end{itemize}

\paragraph{Protocol.} For DTLZ2 ($d=m+4$), we use $5$ independent seeds for $m=5$ and $3$ seeds for $m=8,10$. We initialize with $20$ Sobol points. The evaluation budget is set to allow comparable exploration: 30 iterations for $m=5$, 25 for $m=8$, and 20 for $m=10$. Note that qSTCH-Set evaluates $m$ points per iteration, while baselines evaluate 1. This design choice reflects the method's purpose: finding a coordinated set of solutions.

\subsection{Main Results: DTLZ2 Scaling}

Table~\ref{tab:main} presents the final hypervolume (HV) achieved by each method across different numbers of objectives.

\begin{table}[t]
\caption{Main Results on DTLZ2: Final log-hypervolume (mean $\pm$ std). Best method per column is \textbf{bolded}. qSTCH-Set consistently outperforms scalarization baselines, with the gap widening as $m$ increases. ($m=10$ results pending).}
\label{tab:main}
\centering
\begin{tabular}{lccc}
\toprule
Method & $m=5$ & $m=8$ & $m=10$ \\
\midrule
\textbf{qSTCH-Set (ours)} & $\mathbf{6.646 \pm 0.066}$ & $\mathbf{24.108 \pm 0.314}$ & Pending \\
qNParEGO & $6.429 \pm 0.254$ & $21.606 \pm 0.826$ & Pending \\
STCH-NParEGO & $6.117 \pm 0.156$ & $20.620 \pm 1.459$ & Pending \\
Random & $5.370 \pm 0.135$ & $18.026 \pm 0.196$ & Pending \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Performance at $m=5$.} qSTCH-Set achieves a mean HV of $6.646$, significantly outperforming qNParEGO ($6.429$) and STCH-NParEGO ($6.117$). The reduced standard deviation ($0.066$ vs $0.254$) indicates that set-based coordination yields more consistent Pareto front coverage than random weight sampling.

\textbf{Scaling to $m=8$.} The advantage of set-based acquisition becomes more pronounced at $m=8$. qSTCH-Set achieves HV $24.108$, surpassing qNParEGO ($21.606$) by over 2.5 units (approx. 11\%). In this high-dimensional objective space, random scalarization weights rarely align with the specific trade-off directions required to expand the hypervolume efficiently. qSTCH-Set, by assigning one candidate to each objective ($K=m$), ensures systematic expansion along all axes simultaneously.

\subsection{Ablation: Batch Size $K$}

To understand the importance of the design rule $K=m$, we compare performance with different batch sizes. (Table~\ref{tab:ablation}).

\begin{table}[h]
\caption{K-Ablation on DTLZ2 ($m=8$): Impact of set size $K$ on final Hypervolume. (Results pending).}
\label{tab:ablation}
\centering
\begin{tabular}{lc}
\toprule
Configuration & Final HV \\
\midrule
qSTCH-Set ($K=m=8$) & $\mathbf{24.108 \pm 0.314}$ \\
qSTCH-Set ($K=5 < m$) & Pending \\
qSTCH-Set ($K=10 > m$) & Pending \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Computational Cost}

We analyze the wall-clock time per iteration on an NVIDIA H100 GPU:

\begin{itemize}
    \item \textbf{$m=5$}: qSTCH-Set averages $\sim 22.6$s/iter, comparable to qNParEGO ($\sim 24.6$s/iter). Despite the larger batch size $q=5$, the joint optimization is efficient.
    \item \textbf{$m=8$}: qSTCH-Set optimization time increases to $\sim 335$s/iter, compared to $\sim 45$s/iter for qNParEGO. This increase reflects the $O(Nm^2)$ complexity of the STCH-Set acquisition and the higher-dimensional search space ($q \times d = 8 \times 12 = 96$ variables). While slower, the cost remains negligible compared to expensive black-box function evaluations (e.g., wet-lab experiments).
\end{itemize}

\subsection{Validation on Bi-Objective Problems}

On ZDT2 ($m=2$), STCH-NParEGO achieves HV $107.2 \pm 4.1$, slightly outperforming vanilla qNParEGO ($106.0 \pm 4.9$), confirming that the smooth approximation is effective even in the single-point regime. However, qEHVI remains the gold standard for $m=2$ ($111.1 \pm 2.2$), supporting our positioning of qSTCH-Set for many-objective problems where qEHVI is inapplicable.

%=============================================================================
\section{Related Work}
\label{sec:related}
%=============================================================================

\paragraph{Hypervolume-based MOBO.}
Expected hypervolume improvement (EHVI) and its Monte Carlo extensions qEHVI and qNEHVI~\citep{daulton2020qnehvi,daulton2021qnehvi} define the state of the art for multi-objective BO with $m \le 4$ objectives, optimizing the expected improvement in the dominated hypervolume indicator.
However, exact hypervolume computation requires non-dominated partitioning, which is \#P-hard in~$m$~\citep{wang2024pohvi}.
Recent work on $\varepsilon$-PoHVI~\citep{wang2024pohvi} provides exact posterior hypervolume integration but remains limited to small~$m$.
For $m > 5$, these methods become computationally intractable.

\paragraph{Scalarization-based MOBO.}
ParEGO~\citep{knowles2006parego} pioneered random Chebyshev scalarization for MOBO, converting the multi-objective problem to a sequence of single-objective subproblems via randomly sampled weight vectors.
qNParEGO~\citep{daulton2020qnehvi} extended this to batches via sequential greedy selection, and Paria et al.~\citep{paria2019mobo} provided regret analysis for random scalarization.
MOBO-OSD~\citep{mobo_osd2025} selects batch points via orthogonal search directions.
All these methods rely on uncoordinated weight selection: each batch element optimizes an independently sampled weight with no mechanism to ensure collective Pareto front coverage.
For $m \gg 5$, random weights concentrate in the interior of the simplex, failing to sample the extremal directions needed for comprehensive front coverage.

\paragraph{Set-based and information-theoretic approaches.}
Set-based acquisition functions optimize the joint utility $U(\{x_1, \ldots, x_q\})$ of a batch rather than a sum of individual utilities.
qEHVI is the canonical example, jointly maximizing expected hypervolume improvement, but inherits the exponential scaling of hypervolume computation.
Information-theoretic methods---MESMO~\citep{belakaria2019mesmo}, PFES~\citep{suzuki2020pfes}, and JES~\citep{tu2022jes}---approximate entropy-based acquisitions but face similar degradation as Pareto front sampling costs grow with~$m$.
MORBO~\citep{daulton2022morbo} scales to high-dimensional \emph{input} spaces ($d > 100$) via local trust regions but addresses input dimensionality rather than objective dimensionality, and was primarily evaluated with $m \le 4$ objectives.

\paragraph{Smooth Tchebycheff scalarization.}
Lin et al.~\citep{lin2024smooth} introduced the smooth Tchebycheff (STCH) scalarization, replacing the non-smooth $\max$ in classical Chebyshev with a log-sum-exp approximation that is everywhere differentiable, has Lipschitz gradients, and preserves (weak) Pareto optimality.
They proved $O(1/\epsilon)$ convergence for gradient-based multi-objective optimization.
Lin et al.~\citep{lin2025few} extended this to STCH-Set, a ``few-for-many'' formulation where $K$ solutions are jointly optimized to cover~$m$ objectives via a nested smooth minimax, scaling as $O(Km)$ and demonstrating results with up to $m{=}1{,}024$ objectives and $K{=}20$ solutions.
However, both methods require cheap, differentiable objectives.
Pires \& Coelho~\citep{pires2025stch} brought single-point STCH into composite Bayesian optimization~\citep{astudillo2019composite}, achieving smooth scalarization in the surrogate-driven loop but without set-based coordination.
Our qSTCH-Set completes this picture: it combines set-based STCH scalarization with Monte Carlo GP posterior sampling, operating at $O(Km)$ cost in the sample-efficient regime where objectives are expensive black-box functions.

\paragraph{Many-objective evolutionary optimization.}
Evolutionary algorithms such as NSGA-III~\citep{deb2014nsga3} and MOEA/D~\citep{zhang2007moead} handle many objectives effectively but typically require thousands of function evaluations, making them unsuitable for expensive black-box problems where each evaluation may cost hours or days.

%=============================================================================
\section{Limitations and Future Work}
\label{sec:limitations}
%=============================================================================

\paragraph{Evaluation budget asymmetry.} Our $m{=}5$ comparison uses $q{=}5$ for qSTCH-Set vs.\ $q{=}1$ for baselines, resulting in different total evaluation counts. While this reflects the method's design---coordinated batch acquisition---a controlled comparison with matched budgets (e.g., $q{=}5$ qNParEGO) would strengthen the empirical case.

\paragraph{Limited objective scale.} Our current experiments reach $m = 8$; the primary motivation for qSTCH-Set is $m \gg 5$. We present initial results for $m=8$ demonstrating scalability, and GPU experiments for $m = 10$ are in progress to further validate performance in the many-objective regime.

\paragraph{Seed count.} The $m = 3$ results use only 2 seeds. Full statistical validation with $\ge 10$ seeds is needed for publication-quality claims.

\paragraph{Comparison to qEHVI.} On bi-objective problems, qEHVI remains clearly superior. qSTCH-Set is designed to complement qEHVI by operating where hypervolume computation is infeasible ($m > 5$).

\paragraph{Acquisition optimization.} Our theoretical analysis assumes the acquisition function is globally optimized (Propositions~\ref{prop:gap}--\ref{prop:pareto}), but L-BFGS-B with 20 random restarts provides no such guarantee. This gap is standard in BO theory but worth noting.

\paragraph{Future directions.}
\emph{Many-objective experiments} ($m = 8, 10, 15, 20$) on GPU are the immediate priority. \emph{Adaptive $\mu$ scheduling}---decreasing $\mu$ as the GP improves---could eliminate the smoothing residual (Corollary in Proposition~\ref{prop:pareto}). \emph{Drug discovery applications} with $m = 20$--$50$ ADMET properties and $K = 3$--$5$ lead candidates represent the ultimate use case. \emph{Hybrid strategies} that use qSTCH-Set for $m > 5$ and qEHVI for $m \le 5$ could leverage the strengths of both.

%=============================================================================
\section{Conclusion}
\label{sec:conclusion}
%=============================================================================

We introduced qSTCH-Set, a Monte Carlo acquisition function that brings set-based smooth Tchebycheff scalarization from gradient-based many-objective optimization to sample-efficient Bayesian optimization. By applying the STCH-Set smooth minimax formulation to GP posterior samples, qSTCH-Set jointly optimizes $K$ candidates to cover $m$ objectives with $O(Km)$ cost and asymptotic Pareto optimality guarantees that transfer from the STCH-Set framework under GP posterior concentration. On DTLZ2 with $m{=}5$ objectives, qSTCH-Set achieves hypervolume $6.646 \pm 0.066$, significantly outperforming both qNParEGO ($6.429 \pm 0.254$) and single-point STCH-NParEGO ($6.117 \pm 0.156$), demonstrating that set-based coordination improves Pareto front coverage in the sample-efficient regime. Our method fills a fundamental gap at the intersection of set-based scalarization and Bayesian optimization, providing a principled path toward optimization with $m \gg 5$ objectives---a regime where no existing BO method operates effectively.

%=============================================================================
\section*{Acknowledgments}
%=============================================================================
\placeholder{Acknowledgments: Compute resources provided by the Digital Research Alliance of Canada (Nibi cluster). R.A.V.-H.\ acknowledges funding from [grant details].}

\bibliographystyle{plainnat}
\bibliography{references}

%=============================================================================
% APPENDIX (external file)
%=============================================================================
\input{appendix}

\end{document}
