{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STCH-BoTorch Demo\n",
        "\n",
        "This notebook demonstrates the Smooth Tchebycheff (STCH) scalarization methods for multi-objective Bayesian optimization.\n",
        "\n",
        "## Overview\n",
        "\n",
        "- **Visual comparison**: TCH vs STCH (showing smoothness)\n",
        "- **Interactive demo**: Synthetic multi-objective problem\n",
        "- **BoTorch integration**: Using with acquisition functions\n",
        "- **Convergence visualization**: How STCH approaches TCH as μ → 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Import STCH functions\n",
        "from stch_botorch import smooth_chebyshev, smooth_chebyshev_set\n",
        "from stch_botorch import SmoothChebyshevObjective, SmoothChebyshevSetObjective\n",
        "\n",
        "print(\"STCH-BoTorch Demo\")\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Visual Comparison: TCH vs STCH\n",
        "\n",
        "Let's visualize how STCH smooths the non-differentiable \"kinks\" in TCH.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a 2D grid of objective values\n",
        "y1_range = np.linspace(-2, 2, 100)\n",
        "y2_range = np.linspace(-2, 2, 100)\n",
        "Y1, Y2 = np.meshgrid(y1_range, y2_range)\n",
        "\n",
        "# Convert to torch tensors\n",
        "Y = torch.tensor(np.stack([Y1, Y2], axis=-1), dtype=torch.float32)\n",
        "weights = torch.tensor([0.5, 0.5])\n",
        "ref_point = torch.tensor([0.0, 0.0])\n",
        "\n",
        "# Compute TCH (hard max)\n",
        "weighted_distances = weights * (ref_point - Y)\n",
        "tch_values = -weighted_distances.max(dim=-1)[0].numpy()\n",
        "\n",
        "# Compute STCH with different mu values\n",
        "mu_values = [1.0, 0.5, 0.1, 0.01]\n",
        "stch_results = {}\n",
        "for mu in mu_values:\n",
        "    stch_vals = smooth_chebyshev(Y, weights, ref_point, mu=mu)\n",
        "    stch_results[mu] = stch_vals.numpy()\n",
        "\n",
        "# Plot comparison\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "# TCH\n",
        "ax = axes[0]\n",
        "contour = ax.contourf(Y1, Y2, tch_values, levels=20, cmap='viridis')\n",
        "ax.set_title('Standard TCH (Hard Max)', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Objective 1')\n",
        "ax.set_ylabel('Objective 2')\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.colorbar(contour, ax=ax)\n",
        "\n",
        "# STCH with different mu\n",
        "for idx, mu in enumerate(mu_values, 1):\n",
        "    ax = axes[idx]\n",
        "    contour = ax.contourf(Y1, Y2, stch_results[mu], levels=20, cmap='viridis')\n",
        "    ax.set_title(f'STCH (μ = {mu})', fontsize=14, fontweight='bold')\n",
        "    ax.set_xlabel('Objective 1')\n",
        "    ax.set_ylabel('Objective 2')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.colorbar(contour, ax=ax)\n",
        "\n",
        "# Remove extra subplot\n",
        "fig.delaxes(axes[5])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('TCH vs STCH: Smoothness Comparison', fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.show()\n",
        "\n",
        "print(\"Notice how STCH smooths the sharp 'kinks' in TCH, making it differentiable.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Convergence: STCH → TCH as μ → 0\n",
        "\n",
        "Let's verify that STCH converges to TCH as the smoothing parameter approaches zero.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test points\n",
        "test_points = torch.tensor([\n",
        "    [1.0, 2.0],\n",
        "    [2.0, 1.0],\n",
        "    [1.5, 1.5],\n",
        "    [0.5, 3.0],\n",
        "])\n",
        "\n",
        "weights = torch.tensor([0.5, 0.5])\n",
        "ref_point = torch.tensor([0.0, 0.0])\n",
        "\n",
        "# Compute TCH values\n",
        "weighted_distances = weights * (ref_point - test_points)\n",
        "tch_values = -weighted_distances.max(dim=-1)[0]\n",
        "\n",
        "# Compute STCH with decreasing mu\n",
        "mu_values = np.logspace(0, -3, 20)  # From 1.0 to 0.001\n",
        "errors = []\n",
        "\n",
        "for mu in mu_values:\n",
        "    stch_values = smooth_chebyshev(test_points, weights, ref_point, mu=float(mu))\n",
        "    error = torch.abs(stch_values - tch_values).mean().item()\n",
        "    errors.append(error)\n",
        "\n",
        "# Plot convergence\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.semilogx(mu_values, errors, 'o-', linewidth=2, markersize=8)\n",
        "plt.xlabel('Smoothing Parameter μ', fontsize=12)\n",
        "plt.ylabel('Mean Absolute Error |STCH - TCH|', fontsize=12)\n",
        "plt.title('Convergence: STCH → TCH as μ → 0', fontsize=14, fontweight='bold')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.axhline(y=0, color='r', linestyle='--', alpha=0.5, label='Perfect convergence')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Final error (μ = {mu_values[-1]:.6f}): {errors[-1]:.6f}\")\n",
        "print(\"As μ → 0, STCH converges to TCH!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Gradient Comparison: TCH vs STCH\n",
        "\n",
        "One key advantage of STCH is that it provides gradients for all objectives, not just the worst one.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a point where objectives are close (near the \"kink\")\n",
        "Y = torch.tensor([[1.0, 1.1]], requires_grad=True)\n",
        "weights = torch.tensor([0.5, 0.5])\n",
        "ref_point = torch.tensor([0.0, 0.0])\n",
        "\n",
        "# TCH gradient (hard max - only one objective has gradient)\n",
        "Y_tch = Y.clone().detach().requires_grad_(True)\n",
        "weighted_dist_tch = weights * (ref_point - Y_tch)\n",
        "tch_val = -weighted_dist_tch.max(dim=-1)[0]\n",
        "tch_val.backward()\n",
        "tch_grad = Y_tch.grad.clone()\n",
        "\n",
        "# STCH gradient (smooth - all objectives have gradients)\n",
        "Y_stch = Y.clone().detach().requires_grad_(True)\n",
        "stch_val = smooth_chebyshev(Y_stch, weights, ref_point, mu=0.1)\n",
        "stch_val.backward()\n",
        "stch_grad = Y_stch.grad.clone()\n",
        "\n",
        "# Visualize gradients\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# TCH gradients\n",
        "ax1.bar(['Objective 1', 'Objective 2'], tch_grad[0].numpy(), color=['red', 'blue'], alpha=0.7)\n",
        "ax1.set_title('TCH Gradients (Hard Max)', fontsize=14, fontweight='bold')\n",
        "ax1.set_ylabel('Gradient Value')\n",
        "ax1.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "ax1.text(0.5, -0.15, 'Only worst objective\\nhas non-zero gradient', \n",
        "         ha='center', transform=ax1.transAxes, fontsize=10, style='italic')\n",
        "\n",
        "# STCH gradients\n",
        "ax2.bar(['Objective 1', 'Objective 2'], stch_grad[0].numpy(), color=['red', 'blue'], alpha=0.7)\n",
        "ax2.set_title('STCH Gradients (Smooth)', fontsize=14, fontweight='bold')\n",
        "ax2.set_ylabel('Gradient Value')\n",
        "ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "ax2.text(0.5, -0.15, 'All objectives have\\nnon-zero gradients', \n",
        "         ha='center', transform=ax2.transAxes, fontsize=10, style='italic')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"TCH Gradients:\", tch_grad[0].numpy())\n",
        "print(\"STCH Gradients:\", stch_grad[0].numpy())\n",
        "print(\"\\nSTCH provides gradients for all objectives, enabling better optimization!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. STCH-Set: Batch Optimization\n",
        "\n",
        "STCH-Set optimizes a batch of candidates to collectively cover all objectives.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a batch of candidates\n",
        "# Each candidate excels at different objectives\n",
        "Y_batch = torch.tensor([\n",
        "    [[1.0, 10.0],   # Candidate 1: good at obj1, bad at obj2\n",
        "     [10.0, 1.0],   # Candidate 2: bad at obj1, good at obj2\n",
        "     [5.0, 5.0]]    # Candidate 3: balanced\n",
        "])  # Shape: (1, 3, 2) = (batch, q, m)\n",
        "\n",
        "weights = torch.tensor([0.5, 0.5])\n",
        "ref_point = torch.tensor([0.0, 0.0])\n",
        "\n",
        "# Standard STCH (per candidate)\n",
        "stch_per_candidate = smooth_chebyshev(Y_batch.squeeze(0), weights, ref_point, mu=0.1)\n",
        "print(\"STCH (per candidate):\")\n",
        "for i, val in enumerate(stch_per_candidate):\n",
        "    print(f\"  Candidate {i+1}: {val.item():.4f}\")\n",
        "\n",
        "# STCH-Set (aggregated over batch)\n",
        "stch_set = smooth_chebyshev_set(Y_batch, weights, ref_point, mu=0.1)\n",
        "print(f\"\\nSTCH-Set (aggregated): {stch_set.item():.4f}\")\n",
        "\n",
        "# Visualize\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "candidates = ['Candidate 1\\n(good at obj1)', 'Candidate 2\\n(good at obj2)', 'Candidate 3\\n(balanced)']\n",
        "stch_vals = stch_per_candidate.numpy()\n",
        "\n",
        "bars = ax.bar(candidates, stch_vals, alpha=0.7, color=['red', 'blue', 'green'])\n",
        "ax.axhline(y=stch_set.item(), color='purple', linestyle='--', linewidth=2, \n",
        "           label=f'STCH-Set (aggregated) = {stch_set.item():.4f}')\n",
        "ax.set_ylabel('Utility Value', fontsize=12)\n",
        "ax.set_title('STCH vs STCH-Set: Batch Optimization', fontsize=14, fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nSTCH-Set aggregates over the batch, optimizing for collective coverage!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. BoTorch Integration Example\n",
        "\n",
        "Here's how to use STCH objectives with BoTorch acquisition functions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Using SmoothChebyshevObjective with BoTorch\n",
        "# (This is a conceptual example - you would need a trained model in practice)\n",
        "\n",
        "print(\"Example BoTorch Integration:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Create objective\n",
        "objective = SmoothChebyshevObjective(\n",
        "    weights=torch.tensor([0.5, 0.5]),\n",
        "    ref_point=torch.tensor([0.0, 0.0]),\n",
        "    mu=0.1\n",
        ")\n",
        "\n",
        "print(f\"Objective created: {type(objective).__name__}\")\n",
        "print(f\"  Weights: {objective.weights}\")\n",
        "print(f\"  Reference point: {objective.ref_point}\")\n",
        "print(f\"  Smoothing parameter μ: {objective.mu}\")\n",
        "\n",
        "# Simulate MC samples (what BoTorch would pass)\n",
        "# Shape: (sample_shape x batch_shape x q x m)\n",
        "mc_samples = torch.randn(10, 1, 4, 2)  # 10 MC samples, 1 batch, 4 candidates, 2 objectives\n",
        "\n",
        "# Forward pass\n",
        "utilities = objective.forward(mc_samples)\n",
        "print(f\"\\nInput shape: {mc_samples.shape}\")\n",
        "print(f\"Output shape: {utilities.shape}\")\n",
        "print(f\"  ✓ Correctly maps (..., q, m) → (..., q)\")\n",
        "\n",
        "# Example with STCH-Set\n",
        "objective_set = SmoothChebyshevSetObjective(\n",
        "    weights=torch.tensor([0.5, 0.5]),\n",
        "    ref_point=torch.tensor([0.0, 0.0]),\n",
        "    mu=0.1\n",
        ")\n",
        "\n",
        "utilities_set = objective_set.forward(mc_samples)\n",
        "print(f\"\\nSTCH-Set Input shape: {mc_samples.shape}\")\n",
        "print(f\"STCH-Set Output shape: {utilities_set.shape}\")\n",
        "print(f\"  ✓ Correctly maps (..., q, m) → (...) [q dimension removed]\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Ready to use with:\")\n",
        "print(\"  - qLogNParEGO (with SmoothChebyshevObjective)\")\n",
        "print(\"  - qSimpleRegret (with SmoothChebyshevSetObjective)\")\n",
        "print(\"  - And other BoTorch acquisition functions!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Effect of Smoothing Parameter μ\n",
        "\n",
        "Let's see how different values of μ affect the smoothness and approximation quality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a 1D slice through the objective space\n",
        "y1_vals = np.linspace(-2, 2, 200)\n",
        "y2_vals = 1.0 - 0.5 * y1_vals  # Linear relationship\n",
        "\n",
        "Y_slice = torch.tensor(np.stack([y1_vals, y2_vals], axis=1), dtype=torch.float32)\n",
        "weights = torch.tensor([0.5, 0.5])\n",
        "ref_point = torch.tensor([0.0, 0.0])\n",
        "\n",
        "# Compute TCH\n",
        "weighted_dist = weights * (ref_point - Y_slice)\n",
        "tch_slice = -weighted_dist.max(dim=-1)[0].numpy()\n",
        "\n",
        "# Compute STCH with different mu\n",
        "mu_list = [2.0, 1.0, 0.5, 0.1, 0.01]\n",
        "stch_slices = {}\n",
        "for mu in mu_list:\n",
        "    stch_slice = smooth_chebyshev(Y_slice, weights, ref_point, mu=mu)\n",
        "    stch_slices[mu] = stch_slice.numpy()\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(y1_vals, tch_slice, 'k-', linewidth=3, label='TCH (Hard Max)', alpha=0.8)\n",
        "\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, len(mu_list)))\n",
        "for mu, color in zip(mu_list, colors):\n",
        "    plt.plot(y1_vals, stch_slices[mu], '--', linewidth=2, \n",
        "             label=f'STCH (μ = {mu})', color=color, alpha=0.8)\n",
        "\n",
        "plt.xlabel('Objective 1', fontsize=12)\n",
        "plt.ylabel('Utility Value', fontsize=12)\n",
        "plt.title('Effect of Smoothing Parameter μ', fontsize=14, fontweight='bold')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Observations:\")\n",
        "print(\"  - Larger μ: Smoother, but less accurate approximation\")\n",
        "print(\"  - Smaller μ: Tighter approximation to TCH, but less smooth\")\n",
        "print(\"  - Default μ = 0.1: Good balance between smoothness and accuracy\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. SmoothChebyshevSetObjective: Batch Optimization Example\n",
        "\n",
        "Let's see how `SmoothChebyshevSetObjective` can be used for batch optimization scenarios.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Using SmoothChebyshevSetObjective for batch optimization\n",
        "# This objective aggregates over the q dimension, optimizing for collective coverage\n",
        "\n",
        "print(\"SmoothChebyshevSetObjective Batch Optimization Example\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create a batch of candidates with different trade-offs\n",
        "# Each candidate excels at different objectives\n",
        "candidates_batch = torch.tensor([\n",
        "    [0.5, 2.0],   # Candidate 1: good at obj1, worse at obj2\n",
        "    [2.0, 0.5],   # Candidate 2: worse at obj1, good at obj2\n",
        "    [1.0, 1.0],   # Candidate 3: balanced\n",
        "    [0.8, 1.5],   # Candidate 4: slightly better at obj1\n",
        "])  # Shape: (4, 2) = (q, m)\n",
        "\n",
        "weights = torch.tensor([0.5, 0.5])\n",
        "ref_point = torch.tensor([0.0, 0.0])\n",
        "\n",
        "# Standard STCH (per candidate)\n",
        "print(\"\\nStandard STCH (evaluates each candidate separately):\")\n",
        "stch_per_candidate = smooth_chebyshev(candidates_batch, weights, ref_point, mu=0.1)\n",
        "for i, val in enumerate(stch_per_candidate, 1):\n",
        "    print(f\"  Candidate {i}: utility = {val.item():.4f}\")\n",
        "\n",
        "# STCH-Set (aggregates over batch - optimizes for collective coverage)\n",
        "print(\"\\nSTCH-Set (aggregates over batch for collective optimization):\")\n",
        "# Need to add batch dimension: (q, m) -> (1, q, m)\n",
        "candidates_batch_expanded = candidates_batch.unsqueeze(0)\n",
        "stch_set = smooth_chebyshev_set(candidates_batch_expanded, weights, ref_point, mu=0.1)\n",
        "print(f\"  Batch utility: {stch_set.item():.4f}\")\n",
        "\n",
        "# Visualize the difference\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Left: Individual candidate utilities\n",
        "ax1.bar(range(1, 5), stch_per_candidate.numpy(), alpha=0.7, color=['red', 'blue', 'green', 'orange'])\n",
        "ax1.axhline(y=stch_set.item(), color='purple', linestyle='--', linewidth=2, \n",
        "           label=f'STCH-Set (aggregated) = {stch_set.item():.4f}')\n",
        "ax1.set_xlabel('Candidate', fontsize=12)\n",
        "ax1.set_ylabel('Utility Value', fontsize=12)\n",
        "ax1.set_title('STCH: Individual Candidate Utilities', fontsize=14, fontweight='bold')\n",
        "ax1.set_xticks(range(1, 5))\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Right: Objective space visualization\n",
        "ax2.scatter(candidates_batch[:, 0], candidates_batch[:, 1], \n",
        "           s=200, alpha=0.7, c=['red', 'blue', 'green', 'orange'], \n",
        "           edgecolors='black', linewidths=2)\n",
        "ax2.set_xlabel('Objective 1', fontsize=12)\n",
        "ax2.set_ylabel('Objective 2', fontsize=12)\n",
        "ax2.set_title('Candidates in Objective Space', fontsize=14, fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Add labels\n",
        "for i, (x, y) in enumerate(candidates_batch, 1):\n",
        "    ax2.annotate(f'C{i}', (x, y), xytext=(5, 5), textcoords='offset points', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Key Insight:\")\n",
        "print(\"  - STCH evaluates each candidate independently\")\n",
        "print(\"  - STCH-Set optimizes the batch collectively for diverse coverage\")\n",
        "print(\"  - Use STCH-Set when you want the batch to collectively cover all objectives\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
